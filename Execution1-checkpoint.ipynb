{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4eba663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.__version__:  2.2.3\n",
      "np.__version__:  1.26.4\n",
      "keras.__version__:  3.7.0\n",
      "tf.__version__:  2.18.0\n",
      "matplotlib.__version__:  3.9.2\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "# import sys\n",
    "# sys.modules.clear()\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout, Attention, BatchNormalization\n",
    "from tensorflow.keras import optimizers, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from joblib import dump, load\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# import sklearn\n",
    "import math\n",
    "from numpy.random import seed\n",
    "\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "import warnings\n",
    "\n",
    "# warnings.resetwarnings()\n",
    "# warnings.filterwarnings('always')\n",
    "\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "seed_value = 10\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "print('pd.__version__: ',pd.__version__)\n",
    "print('np.__version__: ',np.__version__)\n",
    "print('keras.__version__: ',keras.__version__)\n",
    "print('tf.__version__: ',tf.__version__)\n",
    "print('matplotlib.__version__: ',matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ae1e731b-5f67-4505-858f-f49a86a5af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-index pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "92695538-8470-4a07-8b60-8f8d63d29c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-index matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "1eafe8a9-aed4-43f5-8e28-45cabf9d49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-index scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "38681be2-f013-4cf3-bae0-4ab5b8feb72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6b5d4a18-bf58-417d-acb6-abe6af534077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example computation\n",
    "with tf.device('/GPU:0'):  # Use '/CPU:0' to force CPU\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "8355e8ab-11dd-42ed-ab74-5860c2d67207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\msalmaniaran\\\\Documents\\\\Python Scripts - Secondary\\\\Reconfigurable-Antenna'"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8a574f5e-dca8-4787-b154-d64762be8ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllDiode-OFF-Alpha sweep.csv\n",
      "AllDiode-OFF-fx sweep.csv\n",
      "AllDiode-OFF-fy sweep.csv\n",
      "AllDiode-OFF-l sweep.csv\n",
      "AllDiode-OFF-lextention sweep.csv\n",
      "AllDiode-OFF-lh sweep.csv\n",
      "AllDiode-OFF-lr sweep.csv\n",
      "AllDiode-OFF-lv sweep.csv\n",
      "AllDiode-OFF-offset1 sweep.csv\n",
      "AllDiode-OFF-pr sweep.csv\n",
      "AllDiode-OFF-pr2 sweep.csv\n",
      "AllDiode-OFF-w sweep.csv\n",
      "AllDiode-OFF-wr sweep.csv\n",
      "AllDiode-OFF-wu sweep.csv\n",
      "AllDiode-ON-Alpha sweep.csv\n",
      "AllDiode-ON-fx sweep.csv\n",
      "AllDiode-ON-fy sweep.csv\n",
      "AllDiode-ON-l sweep.csv\n",
      "AllDiode-ON-lextention sweep.csv\n",
      "AllDiode-ON-lh sweep.csv\n",
      "AllDiode-ON-lr sweep.csv\n",
      "AllDiode-ON-lv sweep.csv\n",
      "AllDiode-ON-offset1 sweep.csv\n",
      "AllDiode-ON-pr sweep.csv\n",
      "AllDiode-ON-pr2 sweep.csv\n",
      "AllDiode-ON-w sweep.csv\n",
      "AllDiode-ON-wr sweep.csv\n",
      "AllDiode-ON-wu sweep.csv\n",
      "lowerDiode-ON-Alpha sweep.csv\n",
      "lowerDiode-ON-fx sweep.csv\n",
      "lowerDiode-ON-fy sweep.csv\n",
      "lowerDiode-ON-l sweep.csv\n",
      "lowerDiode-ON-lextention sweep.csv\n",
      "lowerDiode-ON-lh sweep.csv\n",
      "lowerDiode-ON-lr sweep.csv\n",
      "lowerDiode-ON-lv sweep.csv\n",
      "lowerDiode-ON-offset1 sweep.csv\n",
      "lowerDiode-ON-pr sweep.csv\n",
      "lowerDiode-ON-pr2 sweep.csv\n",
      "lowerDiode-ON-w sweep.csv\n",
      "lowerDiode-ON-wr sweep.csv\n",
      "lowerDiode-ON-wu sweep.csv\n",
      "upperDiode-ON-Alpha sweep.csv\n",
      "upperDiode-ON-fx sweep.csv\n",
      "upperDiode-ON-fy sweep.csv\n",
      "upperDiode-ON-l sweep.csv\n",
      "upperDiode-ON-lextention sweep.csv\n",
      "upperDiode-ON-lh sweep.csv\n",
      "upperDiode-ON-lr sweep.csv\n",
      "upperDiode-ON-lv sweep.csv\n",
      "upperDiode-ON-offset1 sweep.csv\n",
      "upperDiode-ON-pr sweep.csv\n",
      "upperDiode-ON-pr2 sweep.csv\n",
      "upperDiode-ON-w sweep.csv\n",
      "upperDiode-ON-wr sweep.csv\n",
      "upperDiode-ON-wu sweep.csv\n",
      "{0: 'AllDiode-OFF-Alpha sweep.csv', 1: 'AllDiode-OFF-fx sweep.csv', 2: 'AllDiode-OFF-fy sweep.csv', 3: 'AllDiode-OFF-l sweep.csv', 4: 'AllDiode-OFF-lextention sweep.csv', 5: 'AllDiode-OFF-lh sweep.csv', 6: 'AllDiode-OFF-lr sweep.csv', 7: 'AllDiode-OFF-lv sweep.csv', 8: 'AllDiode-OFF-offset1 sweep.csv', 9: 'AllDiode-OFF-pr sweep.csv', 10: 'AllDiode-OFF-pr2 sweep.csv', 11: 'AllDiode-OFF-w sweep.csv', 12: 'AllDiode-OFF-wr sweep.csv', 13: 'AllDiode-OFF-wu sweep.csv', 14: 'AllDiode-ON-Alpha sweep.csv', 15: 'AllDiode-ON-fx sweep.csv', 16: 'AllDiode-ON-fy sweep.csv', 17: 'AllDiode-ON-l sweep.csv', 18: 'AllDiode-ON-lextention sweep.csv', 19: 'AllDiode-ON-lh sweep.csv', 20: 'AllDiode-ON-lr sweep.csv', 21: 'AllDiode-ON-lv sweep.csv', 22: 'AllDiode-ON-offset1 sweep.csv', 23: 'AllDiode-ON-pr sweep.csv', 24: 'AllDiode-ON-pr2 sweep.csv', 25: 'AllDiode-ON-w sweep.csv', 26: 'AllDiode-ON-wr sweep.csv', 27: 'AllDiode-ON-wu sweep.csv', 28: 'lowerDiode-ON-Alpha sweep.csv', 29: 'lowerDiode-ON-fx sweep.csv', 30: 'lowerDiode-ON-fy sweep.csv', 31: 'lowerDiode-ON-l sweep.csv', 32: 'lowerDiode-ON-lextention sweep.csv', 33: 'lowerDiode-ON-lh sweep.csv', 34: 'lowerDiode-ON-lr sweep.csv', 35: 'lowerDiode-ON-lv sweep.csv', 36: 'lowerDiode-ON-offset1 sweep.csv', 37: 'lowerDiode-ON-pr sweep.csv', 38: 'lowerDiode-ON-pr2 sweep.csv', 39: 'lowerDiode-ON-w sweep.csv', 40: 'lowerDiode-ON-wr sweep.csv', 41: 'lowerDiode-ON-wu sweep.csv', 42: 'upperDiode-ON-Alpha sweep.csv', 43: 'upperDiode-ON-fx sweep.csv', 44: 'upperDiode-ON-fy sweep.csv', 45: 'upperDiode-ON-l sweep.csv', 46: 'upperDiode-ON-lextention sweep.csv', 47: 'upperDiode-ON-lh sweep.csv', 48: 'upperDiode-ON-lr sweep.csv', 49: 'upperDiode-ON-lv sweep.csv', 50: 'upperDiode-ON-offset1 sweep.csv', 51: 'upperDiode-ON-pr sweep.csv', 52: 'upperDiode-ON-pr2 sweep.csv', 53: 'upperDiode-ON-w sweep.csv', 54: 'upperDiode-ON-wr sweep.csv', 55: 'upperDiode-ON-wu sweep.csv'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory you want to list\n",
    "directory = 'C:/Backup - Oct 2024/Oct-2023 Backup/Users/msalmaniaran/PhD/Results-data/Reconfigurable-patch - Copy/'\n",
    "\n",
    "\n",
    "# List all files and directories in the specified directory\n",
    "all_files = os.listdir(directory)\n",
    "\n",
    "# Filter out only the files\n",
    "files = [f for f in all_files if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "# Print the list of files\n",
    "for file in files:\n",
    "    print(file)\n",
    "\n",
    "dict_files = {i: files[i] for i in range(len(files))}\n",
    "print(dict_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d6974bca-0c5e-4716-963e-43db1ccf69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dfs = 14\n",
    "n = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_dfs*(n-1), n*num_dfs):\n",
    "    # Creating a sample DataFrame with random data\n",
    "    df_new = pd.read_csv('C:/Backup - Oct 2024/Oct-2023 Backup/Users/msalmaniaran/PhD/Results-data/Reconfigurable-patch - Copy/'+str(dict_files[i])) \n",
    "    df = pd.concat([df, df_new], ignore_index=True)\n",
    "\n",
    "# for i in range(4*num_dfs):\n",
    "#     # Creating a sample DataFrame with random data\n",
    "#     df_new = pd.read_csv(\"D:/Oct-2023 Backup/Users/msalmaniaran/PhD/Results-data/Reconfigurable-patch/\"+str(dict_files[i])) \n",
    "#     df = pd.concat([df, df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ac941-8faa-4a9b-a88a-ae441d79bc6b",
   "metadata": {},
   "source": [
    "# Frequency Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "10cd7bfd-a601-4f5a-b4e6-2f0bb7f4ce8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ys = df.drop(['alpha [mm]','fx [mm]', 'fy [mm]', 'l [mm]', 'lextension1 [mm]', 'lh [mm]', 'lr [mm]', 'lv [mm]', 'offset1 [mm]', 'pr [mm]', 'pr2 [mm]', 'w [mm]', 'wr [mm]', 'wu [mm]', 'Diode 1 state', 'Diode 2 state', 'Freq [GHz]'],axis=1)\n",
    "ys_data = df_ys.values\n",
    "df_yf = df.drop(['alpha [mm]','fx [mm]', 'fy [mm]', 'l [mm]', 'lextension1 [mm]', 'lh [mm]', 'lr [mm]', 'lv [mm]', 'offset1 [mm]', 'pr [mm]', 'pr2 [mm]', 'w [mm]', 'wr [mm]', 'wu [mm]', 'Diode 1 state', 'Diode 2 state', 'dB(S(1,1)) []'],axis=1)\n",
    "yf_data = df_yf.values\n",
    "df_y = df.drop(['alpha [mm]','fx [mm]', 'fy [mm]', 'l [mm]', 'lextension1 [mm]', 'lh [mm]', 'lr [mm]', 'lv [mm]', 'offset1 [mm]', 'pr [mm]', 'pr2 [mm]', 'w [mm]', 'wr [mm]', 'wu [mm]', 'Diode 1 state', 'Diode 2 state'],axis=1)\n",
    "array = df_ys.values\n",
    "\n",
    "a = len(df)\n",
    "b = int(a/250) # 250 is the number of sampling points in a single graph of S11 parameter\n",
    "reshaped_array = array.reshape(b, 250)   #250 is the number of sample points within 1-4 GHz.\n",
    "df_yst = pd.DataFrame(reshaped_array)\n",
    "\n",
    "\n",
    "# crob the frequency as needed\n",
    "df_yst = df_yst.iloc[:, 40:-80] \n",
    "freq = df_yf.iloc[40:170].values\n",
    "freq = np.squeeze(freq).tolist()\n",
    "Frequency = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e91b5-e3d7-4f4f-ac3b-9cf588294437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "9d9050ef-e5d8-4c0a-95f5-2f8141dfe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = np.squeeze(yf_data[:len(df_yst.columns)]).tolist()\n",
    "# freq = freq[40:-40]\n",
    "# print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f024a30-3fe3-41dd-bc3c-3366891de0da",
   "metadata": {},
   "source": [
    "# Reload Surrogate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "26d8dc60-a844-4009-81d4-89d87a8b9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "C:\\Users\\msalmaniaran\\AppData\\Local\\anaconda3\\envs\\RL_Test\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "Surrogate1 = load_model('ANN_decoder1.keras')\n",
    "Surrogate2 = load_model('ANN_decoder2.keras')\n",
    "Surrogate3 = load_model('ANN_decoder3.keras')\n",
    "Surrogate4 = load_model('ANN_decoder4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "decaca11-927d-44b7-9a82-de120e5d2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([-0.53543137,  0.0548655 ,  0.21073547,  0.06276533, -0.01123407,\n",
    "        0.06335771,  0.02316934,  0.15493   ,  0.18526412, -0.23269195,\n",
    "        0.17344425, -0.17463979,  0.12431098,  0.02725491])\n",
    "x2 = np.array([ 1.15259188,  0.03169584,  0.22498164, -0.04767922, -0.02699029,\n",
    "        0.16014375,  0.02720018,  0.13337159,  0.24500376, -0.18947647,\n",
    "        0.18151366, -0.07039868,  0.02787709, -0.02957473])\n",
    "x3 = np.array([ 0.00044023,  0.06098977,  0.19923226, -0.09232034, -0.06310218,\n",
    "        0.19543453,  0.02711807,  0.07759908,  0.26911374, -0.22341645,\n",
    "        0.17709264, -0.00698893,  0.04785898,  0.02822875])\n",
    "x4 = np.array([ 1.89700401e-01,  7.11254240e-02,  6.21724894e-14, -3.26849658e-13,\n",
    "       -3.55251967e-02,  1.55942229e-01,  4.45846614e-03,  1.64994670e-01,\n",
    "        2.57905182e-01, -2.29323307e-01,  1.39949736e-01, -5.30677029e-02,\n",
    "        6.49566527e-02,  3.63311905e-02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "f3fb26ab-8c90-49ab-aeed-09eeb7682e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y1=load('scaler_y1.bin')\n",
    "scaler_y2=load('scaler_y2.bin')\n",
    "scaler_y3=load('scaler_y3.bin')\n",
    "scaler_y4=load('scaler_y4.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "99c0d8d8-589c-4cac-8f63-3f4f00ff8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x1=load('scaler_x1.bin')\n",
    "scaler_x2=load('scaler_x2.bin')\n",
    "scaler_x3=load('scaler_x3.bin')\n",
    "scaler_x4=load('scaler_x4.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "87f414d7-9625-413d-a73f-d9320b182866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.336       7.408      47.664      ... 56.16        4.952\n",
      "   4.704     ]\n",
      " [18.4506      7.4543     47.9619     ... 56.511       4.98295\n",
      "   4.7334    ]\n",
      " [18.5652      7.5006     48.2598     ... 56.862       5.0139\n",
      "   4.7628    ]\n",
      " ...\n",
      " [22.53        9.1        58.56       ... 69.          6.08\n",
      "   9.53846154]\n",
      " [22.53        9.1        58.56       ... 69.          6.08\n",
      "   9.76923077]\n",
      " [22.53        9.1        58.56       ... 69.          6.08\n",
      "  10.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_data1 = np.load('x_data1.npy')\n",
    "print(x_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d7f0cc13-96b9-4cf8-87bf-6db8e621b72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.53,  9.1 , 58.56, 26.04, 51.03,  2.7 , 25.91, 35.38, -2.8 ,\n",
       "       24.41, 69.  ,  6.08, 10.  ])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data1[503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "a0511c88-936b-4305-b66e-a2979cfb5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_x1.transform([np.array([ 0.983     , 22.53      ,  9.1       , 58.56      , 26.04      ,\n",
    "#        51.03      ,  2.7       , 25.91      , 35.38      , -2.8       ,\n",
    "#        24.41      , 69.        ,  6.08      ,  10])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "24652a4f-a006-47d5-934d-022a47155e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data1_trans = scaler_x1.transform(.997*x_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "4b702bd8-53e3-4ee2-87bf-44570dd97988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/GPU:1'):  # Use '/CPU:0' to force CPU   \n",
    "pr1 = Surrogate1.predict(x_data1_trans)\n",
    "pr2 = Surrogate2.predict(x_data1_trans)\n",
    "pr3 = Surrogate3.predict(x_data1_trans)\n",
    "pr4 = Surrogate4.predict(x_data1_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "f8a89013-6ec3-4e80-9d02-7ba538cbf49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randint(1,len(pr1))\n",
    "i = 394\n",
    "print(i)\n",
    "prr1 = scaler_y1.inverse_transform(pr1)\n",
    "prr2 = scaler_y2.inverse_transform(pr2)\n",
    "prr3 = scaler_y3.inverse_transform(pr3)\n",
    "prr4 = scaler_y4.inverse_transform(pr4)\n",
    "# print(np.shape(prr4[508]))\n",
    "plt.plot(freq, prr1[i],'--', label = 'Right')\n",
    "plt.plot(freq, prr2[i], label = 'Left')\n",
    "plt.plot(freq, prr3[i], label = 'None')\n",
    "plt.plot(freq, prr4[i], label = 'Dual')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('S11')\n",
    "plt.title('Line Graph of Reconstructed S11')\n",
    "plt.legend()  # Show legend\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b41c66-411a-4611-83a8-dc9f8852b387",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f0d10864-49e5-4140-a7b3-39b8354a1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to find resonant frequencies and calculate bandwidth\n",
    "# def process_prr(prr, key):\n",
    "#     peaks, _ = find_peaks(-prr, height=-threshold)  # Peaks of -S11 correspond to dips in S11\n",
    "#     resonant_frequencies = Frequency[peaks]  # Use your `Frequency` array\n",
    "#     resonant_s11 = prr[peaks]\n",
    "#     within_range = (resonant_frequencies >= min_f) & (resonant_frequencies <= max_f)\n",
    "#     resonant_frequencies = resonant_frequencies[within_range]\n",
    "#     resonant_s11 = resonant_s11[within_range]\n",
    "#     # extr_inf[1] = np.concatenate((resonant_frequencies, resonant_s11))\n",
    "#     bandwidths = []\n",
    "#     for i, rf in enumerate(resonant_frequencies):\n",
    "#         try:\n",
    "#             # print(f\"Resonant Frequency: {rf}\")\n",
    "            \n",
    "#             # Use logical operators for filtering\n",
    "#             left_mask = (0.9 * rf < Frequency) & (Frequency < rf)\n",
    "#             right_mask = (1.1 * rf > Frequency) & (Frequency > rf)\n",
    "    \n",
    "#             # Interpolation functions for frequencies around -10 dB crossing points\n",
    "#             left_part = interp1d(prr[left_mask], Frequency[left_mask], bounds_error=False, fill_value=\"extrapolate\")\n",
    "#             F1 = left_part(-10)  # Frequency on the left of rf where S11 crosses -10 dB\n",
    "#             # print(f\"F1: {F1}\")\n",
    "    \n",
    "#             right_part = interp1d(prr[right_mask], Frequency[right_mask], bounds_error=False, fill_value=\"extrapolate\")\n",
    "#             F2 = right_part(-10)  # Frequency on the right of rf where S11 crosses -10 dB\n",
    "#             # print(f\"F2: {F2}\")\n",
    "    \n",
    "#             # Calculate bandwidth\n",
    "#             bandwidth = F2 - F1\n",
    "#             bandwidths.append((rf, resonant_s11[i], bandwidth))\n",
    "\n",
    "#         except (ValueError, IndexError):\n",
    "#             # Skip if crossing points are not found\n",
    "#             continue\n",
    "    \n",
    "#     # Store resonant frequencies, S11 values, and bandwidths in extr_inf\n",
    "#     # if bandwidths:\n",
    "#     extr_inf[key] = np.array(bandwidths).flatten()  # Flatten for concatenation               \n",
    "    \n",
    "#     # extr_inf[key] = np.concatenate((resonant_frequencies, resonant_s11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "5407333e-b2b7-40b4-a1f5-cbb62484c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def process_prr(prr, key):\n",
    "    # Find peaks in the negative PRR (dips in S11)\n",
    "    peaks, _ = find_peaks(-prr, height=-threshold)\n",
    "    \n",
    "    # Convert `Frequency` to NumPy array for indexing\n",
    "    Frequency_array = np.array(Frequency)\n",
    "    \n",
    "    # Extract resonant frequencies and S11 values\n",
    "    resonant_frequencies = Frequency_array[peaks]\n",
    "    resonant_s11 = prr[peaks]\n",
    "    # print('Resonant Frequencies:', resonant_frequencies)\n",
    "\n",
    "    # Filter frequencies within the desired range\n",
    "    valid_range = (resonant_frequencies >= min_f) & (resonant_frequencies <= max_f)\n",
    "    resonant_frequencies = resonant_frequencies[valid_range]\n",
    "    resonant_s11 = resonant_s11[valid_range]\n",
    "\n",
    "    bandwidths = []\n",
    "\n",
    "    for i, rf in enumerate(resonant_frequencies):\n",
    "        try:\n",
    "            # Define the frequency window for search\n",
    "            lower_bound = 0.96 * rf\n",
    "            upper_bound = 1.04 * rf\n",
    "\n",
    "            # Create a mask for the limited frequency window\n",
    "            window_mask = (Frequency_array >= lower_bound) & (Frequency_array <= upper_bound)\n",
    "\n",
    "            # Get the data within the window\n",
    "            freq_window = Frequency_array[window_mask]\n",
    "            prr_window = prr[window_mask]\n",
    "\n",
    "            # Find the crossing points around -10 dB\n",
    "            F1, F2 = None, None\n",
    "            \n",
    "            for j in range(len(prr_window) - 1):\n",
    "                # Check for crossings near -10 dB\n",
    "                if prr_window[j] > -10 and prr_window[j + 1] <= -10:\n",
    "                    # Linear interpolation for F1\n",
    "                    F1 = freq_window[j] + (freq_window[j + 1] - freq_window[j]) * (-10 - prr_window[j]) / (prr_window[j + 1] - prr_window[j])\n",
    "                elif prr_window[j] < -10 and prr_window[j + 1] >= -10:\n",
    "                    # Linear interpolation for F2\n",
    "                    F2 = freq_window[j] + (freq_window[j + 1] - freq_window[j]) * (-10 - prr_window[j]) / (prr_window[j + 1] - prr_window[j])\n",
    "\n",
    "            # Calculate bandwidth only if both crossings are valid\n",
    "            if F1 is not None and F2 is not None:\n",
    "                bandwidth = F2 - F1\n",
    "                bandwidths.append((rf, resonant_s11[i], bandwidth))\n",
    "                # print(f\"Resonant Frequency: {rf}, F1: {F1}, F2: {F2}, Bandwidth: {bandwidth}\")\n",
    "            else:\n",
    "                continue\n",
    "                # print(f\"Bandwidth could not be determined for resonant frequency {rf}, {key}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle unexpected errors gracefully\n",
    "            print(f\"Error processing resonant frequency {rf}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Store results in extr_inf\n",
    "    extr_inf[key] = np.array(bandwidths).reshape(-1, 3) if bandwidths else np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4e0c6fbb-4184-43d7-a72a-5fdebd46ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -10  # Example threshold; adjust as needed\n",
    "min_f = 1.85\n",
    "max_f = 2.5\n",
    "extr_inf = {}\n",
    "def big_model(data):\n",
    "    # extr_inf = {}\n",
    "    # threshold = -10  # Example threshold; adjust as needed\n",
    "    # min_f = 1.85\n",
    "    # max_f = 2.5\n",
    "    # data_trs = scaler_x1.transform(data.reshape(1,-1))\n",
    "    data_trs = data\n",
    "    extr_inf.clear()  # Reset after every prediction if needed\n",
    "    # print(\"Data shape for Surrogate1:\", data_trs.shape)\n",
    "    # with tf.device('/GPU:1'):\n",
    "    pr1 = Surrogate1.predict(data_trs)\n",
    "    pr2 = Surrogate2.predict(data_trs)\n",
    "    pr3 = Surrogate3.predict(data_trs)\n",
    "    pr4 = Surrogate4.predict(data_trs)\n",
    "\n",
    "    prr1 = np.squeeze(scaler_y1.inverse_transform(pr1))\n",
    "    prr2 = np.squeeze(scaler_y2.inverse_transform(pr2))\n",
    "    prr3 = np.squeeze(scaler_y3.inverse_transform(pr3))\n",
    "    prr4 = np.squeeze(scaler_y4.inverse_transform(pr4))\n",
    "\n",
    "    process_prr(prr1, 1)\n",
    "    process_prr(prr2, 2)\n",
    "    process_prr(prr3, 3)\n",
    "    process_prr(prr4, 4)\n",
    "\n",
    "#     plt.plot(freq, prr1,'--', label = 'Right')\n",
    "#     plt.plot(freq, prr2, label = 'Left')\n",
    "#     plt.plot(freq, prr3, label = 'None')\n",
    "#     plt.plot(freq, prr4, label = 'Dual')\n",
    "#     plt.xlabel('Frequency')\n",
    "#     plt.ylabel('S11')\n",
    "#     plt.title('Line Graph of Reconstructed and Actual S11')\n",
    "#     plt.legend()  # Show legend\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    return extr_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "94eaf33f-a048-4d4f-a832-e4f1e569db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.53      ,  9.1       , 58.56      , 26.04      , 51.03      ,\n",
       "        2.7       , 25.91      , 35.38      , -2.8       , 23.94871795,\n",
       "       69.        ,  6.08      ,  5.78      ])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data1[394]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "9343ee33-f206-482b-9b8c-6642a5c5ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab =  [1.15666647, 29.09164395,7.21767381,68.9956505 ,25.08535916, 36.70777354,\n",
    "#   1.83798008, 22.80516019, 18.00688073, -3.17394591, 25.5074841,  77.54383241,\n",
    "#   8.63545438,  2.36937321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "824525dc-74b1-4f61-a58f-7791be519206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_model(np.array(ab))\n",
    "# big_model(x_data1[508])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "c172d073-aa25-42d3-b193-6c1d7b4344c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01987417  0.198154   -0.0198154  -0.0320067   0.01610405  0.05185217\n",
      "   0.13362442  0.15055952 -0.39383351 -0.28568549 -0.12025187  0.07421394\n",
      "   0.01415108]]\n"
     ]
    }
   ],
   "source": [
    "a = scaler_x1.transform([x_data1[394]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "d79cc957-11fb-4022-9128-3d8ce61f38a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "# a = big_model(x_data1[508])\n",
    "x = big_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "027d639d-923f-478a-87cc-401b1fda1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: array([[  2.43373494, -18.83282471,   0.03913758]]), 2: array([[  1.87951807, -15.92254734,   0.0387442 ]]), 3: array([], dtype=float64), 4: array([[  1.89156627, -21.3922863 ,   0.03461724],\n",
      "       [  2.43373494, -19.07114983,   0.03968869]])}\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc5ec4-95f5-43fc-9fe2-31211d672eac",
   "metadata": {},
   "source": [
    "# RL envorinment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d0befa2c-4df9-4465-bb69-1050c49816c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x[4][0][0])==np.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f736a1-06b1-40b5-97dc-62a7e3cf5581",
   "metadata": {},
   "source": [
    "## Environment Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "70ba9f0f-abf4-46c4-ae16-6af5fc73197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_low = 0.8\n",
    "# fx_low = 10\n",
    "# fy_low = 0\n",
    "# l_low = 50\n",
    "# lextension_low = 15\n",
    "# lh_low = 5\n",
    "# lr_low = 0.1\n",
    "# lv_low = 1\n",
    "# offset1_low = 15\n",
    "# pr_low = -3.3\n",
    "# pr2_low = 18\n",
    "# w_low = 60\n",
    "# wr_low = 1\n",
    "# wu_low = 1\n",
    "\n",
    "# alpha_high = 1\n",
    "# fx_high = 40\n",
    "# fy_high = 10\n",
    "# l_high = 70\n",
    "# lextension_high = 40\n",
    "# lh_high = 55\n",
    "# lr_high = 5\n",
    "# lv_high = 40\n",
    "# offset1_high = 40\n",
    "# pr_high = 3.3\n",
    "# pr2_high = 26\n",
    "# w_high = 80\n",
    "# wr_high = 10\n",
    "# wu_high = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a6857776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_low = 0.9\n",
    "# fx_low = 15\n",
    "# fy_low = 6\n",
    "# l_low = 50\n",
    "# lextension_low = 20\n",
    "# lh_low = 45\n",
    "# lr_low = 1\n",
    "# lv_low = 20\n",
    "# offset1_low = 30\n",
    "# pr_low = -3.3\n",
    "# pr2_low = 20\n",
    "# w_low = 60\n",
    "# wr_low = 4\n",
    "# wu_low = 4\n",
    "\n",
    "# alpha_high = 1\n",
    "# fx_high = 24\n",
    "# fy_high = 9.5\n",
    "# l_high = 60\n",
    "# lextension_high = 28\n",
    "# lh_high = 53\n",
    "# lr_high = 2.8\n",
    "# lv_high = 27\n",
    "# offset1_high = 36\n",
    "# pr_high = -2.7\n",
    "# pr2_high = 25\n",
    "# w_high = 70\n",
    "# wr_high = 7\n",
    "# wu_high = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0c6eabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Environment ###########################################\n",
    "fx_low = 20\n",
    "fy_low = 8.5\n",
    "l_low = 55\n",
    "lextension_low = 25\n",
    "lh_low = 50\n",
    "lr_low = 2.5\n",
    "lv_low = 25\n",
    "offset1_low = 34\n",
    "pr_low = -3\n",
    "pr2_low = 23\n",
    "w_low = 68\n",
    "wr_low = 5.5\n",
    "wu_low = 5\n",
    "\n",
    "fx_high = 24\n",
    "fy_high = 9.5\n",
    "l_high = 60\n",
    "lextension_high = 28\n",
    "lh_high = 53\n",
    "lr_high = 2.8\n",
    "lv_high = 27\n",
    "offset1_high = 36\n",
    "pr_high = -2.7\n",
    "pr2_high = 25\n",
    "w_high = 70\n",
    "wr_high = 7\n",
    "wu_high = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8ff204ae-3114-4761-a720-bc2ce1321b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden_Neurons = 256\n",
    "buffer_capacity = 5000\n",
    "batch_size = 256\n",
    "\n",
    "intended_frequency = np.array([1.9, 2.45])           #  [GHz]\n",
    "max_reward = 0\n",
    "relative_frequency_tolerance = 0.02\n",
    "\n",
    "num_states = 13\n",
    "num_actions = 13\n",
    "\n",
    "upper_bound_state = np.array([fx_high, fy_high,\n",
    "                             l_high, lextension_high, lh_high,\n",
    "                             lr_high, lv_high, offset1_high,\n",
    "                             pr_high, pr2_high, w_high, wr_high, wu_high])\n",
    "\n",
    "lower_bound_state = np.array([fx_low, fy_low,\n",
    "                             l_low, lextension_low, lh_low,\n",
    "                             lr_low, lv_low, offset1_low,\n",
    "                             pr_low, pr2_low, w_low, wr_low, wu_low])\n",
    "\n",
    "\n",
    "\n",
    "# data = [upper_bound_state, lower_bound_state]\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# data_minmax = min_max_scaler.fit_transform(data)\n",
    "\n",
    "step_action_ = 1\n",
    "upper_bound_act = []\n",
    "lower_bound_act = []\n",
    "for i in range(num_actions):\n",
    "    upper_bound_act.append((upper_bound_state[i]-lower_bound_state[i])/2)\n",
    "    \n",
    "lower_bound_act = [-x for x in upper_bound_act]\n",
    "    \n",
    "    \n",
    "# for i in range(num_actions):\n",
    "#     upper_bound_act.append(step_action_/25)\n",
    "#     lower_bound_act.append(-step_action_/25)\n",
    "\n",
    "upper_bound_action = np.array(upper_bound_act)\n",
    "lower_bound_action = np.array(lower_bound_act)   \n",
    "\n",
    "# upper_bound_action = np.array([+step_action_/25, +0.1, +0.1])\n",
    "# lower_bound_action = np.array([-0.1, -0.1, -0.1])\n",
    "\n",
    "lower_bound_state_scaled = scaler_x1.transform([lower_bound_state])\n",
    "upper_bound_state_scaled = scaler_x1.transform([upper_bound_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "300ddf11-a64f-4130-a764-e1bbcba3715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(upper_bound_state_scaled)\n",
    "# print(lower_bound_state_scaled)\n",
    "# print(upper_bound_act)\n",
    "# print(lower_bound_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "fe1f69e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.22, 2.55])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.array([1.2155,2.5494]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "335575cc-3f71-4865-8cc7-8635033f6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class env_hfss:\n",
    "    def __init__(self, data):\n",
    "        # Initialize environment parameters\n",
    "        self.center_frequency = intended_frequency\n",
    "        self.bandwidth = [0.034, 0.034]\n",
    "        self.s11_threshold = -10\n",
    "        self.reward = 0\n",
    "        self.done = True  # Indicates if target has been reached\n",
    "        self.designs_scores = {}\n",
    "        self.objectives_scores = {}\n",
    "        self.outputs = {}\n",
    "        \n",
    "        # Design parameters extracted from input data\n",
    "        (self.fx, self.fy, self.l, self.lextension, \n",
    "         self.lh, self.lr, self.lv, self.offset1, self.pr, \n",
    "         self.pr2, self.w, self.wr, self.wu) = data\n",
    "\n",
    "        # Initial state\n",
    "        self.state = data\n",
    "        print(\"Initial state: \", self.state)\n",
    "\n",
    "        # Define state and action space boundaries\n",
    "        self.state_low = lower_bound_state_scaled\n",
    "        self.state_high = upper_bound_state_scaled\n",
    "        self.action_low = lower_bound_action\n",
    "        self.action_high = upper_bound_action\n",
    "\n",
    "    def step(self, action):\n",
    "        # Clip and apply the action to the current state\n",
    "        clipped_action = np.clip(np.squeeze(action), self.action_low, self.action_high)\n",
    "#         new_state = np.round(np.squeeze(self.state) + clipped_action, 3)\n",
    "        new_state = np.squeeze(self.state) + clipped_action\n",
    "        print('new_state:',new_state)\n",
    "        new_state = new_state.reshape(1,-1)\n",
    "        # Ensure the new state remains within valid bounds\n",
    "        if not self._is_valid_state(new_state):\n",
    "            new_state = np.clip(new_state, self.state_low, self.state_high)\n",
    "\n",
    "        if np.array_equal(new_state, self.state):\n",
    "            self.reward = -5  # No state change penalty\n",
    "            self.done = False\n",
    "            return self.state, self.reward, self.done\n",
    "        else:\n",
    "            self.state = new_state\n",
    "            # print(self.state)\n",
    "            self.outputs = big_model(self.state)\n",
    "#             print(self.outputs)\n",
    "            self.reward, self.done = self._check_objective()\n",
    "            return self.state, self.reward, self.done\n",
    "\n",
    "    def _is_valid_state(self, state):\n",
    "        return np.all(self.state_low <= state) and np.all(state <= self.state_high)\n",
    "\n",
    "    def _check_objective(self):\n",
    "        reward_threshold = -0.40\n",
    "        \n",
    "        # Band checks\n",
    "        right_band_check = len(np.squeeze(self.outputs[1])) == 3 and type(np.squeeze(self.outputs[1])[0])==np.float64\n",
    "\n",
    "        left_band_check = len(np.squeeze(self.outputs[2])) == 3 and type(np.squeeze(self.outputs[2])[0])==np.float64\n",
    "        none_band_check = len(self.outputs[3]) == 0\n",
    "        dual_band_check = len(self.outputs[4]) == 2\n",
    "        \n",
    "        # Evaluate each band based on intended frequencies\n",
    "        fitness_score_right = self._evaluate_band(right_band_check, self.outputs[1], intended_frequency[1])\n",
    "        fitness_score_left = self._evaluate_band(left_band_check, self.outputs[2], intended_frequency[0])\n",
    "        fitness_score_none = 1 if none_band_check else 0\n",
    "        fitness_score_dual1, fitness_score_dual2 = self._evaluate_dual_band(dual_band_check)\n",
    "        \n",
    "#         print(fitness_score_right)\n",
    "#         print(fitness_score_left)\n",
    "#         print(fitness_score_none)\n",
    "#         print(fitness_score_dual1)\n",
    "#         print(fitness_score_dual2)\n",
    "        \n",
    "        # Calculate the overall reward\n",
    "        self.reward = float((fitness_score_right + fitness_score_left + fitness_score_none + fitness_score_dual1 + fitness_score_dual2) / 5 - 1)\n",
    "#         print('self.reward:', self.reward)\n",
    "        self.done = self.reward > reward_threshold\n",
    "\n",
    "        \n",
    "        if self.done:\n",
    "            self.designs_scores[tuple(self.state.flatten())] = self.reward\n",
    "        return self.reward, self.done\n",
    "\n",
    "    def _evaluate_band(self, band_check, output, frequency):\n",
    "        if band_check:\n",
    "            # print(output[0])\n",
    "            # output_value0  = np.squeeze(output)\n",
    "            if math.isclose(np.squeeze(output)[0], frequency, rel_tol=relative_frequency_tolerance):\n",
    "                if np.squeeze(output)[2]<0.07:\n",
    "                    self.s11 = np.squeeze(output)[1]\n",
    "                    self.bandwidth = np.squeeze(output)[2]\n",
    "                    # print(self._calculate_fitness())\n",
    "                    return self._calculate_fitness()\n",
    "                else:\n",
    "#                     print(\"BW too big!\")\n",
    "                    return 0\n",
    "            else:\n",
    "#                 print(f\"Band centered at {frequency} is out of range.\")\n",
    "                return 0\n",
    "        else:\n",
    "#             print(f\"Band for frequency {frequency} does not fit.\")\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def _evaluate_dual_band(self, dual_band_check):\n",
    "        if dual_band_check:\n",
    "            output_value_1 = self.outputs[4][0]\n",
    "            output_value_2 = self.outputs[4][1]\n",
    "            if (math.isclose(output_value_1[0], intended_frequency[0], rel_tol=relative_frequency_tolerance) and\n",
    "                math.isclose(output_value_2[0], intended_frequency[1], rel_tol=relative_frequency_tolerance)):\n",
    "\n",
    "                if (output_value_1[2]<0.07 and output_value_2[2]<0.07):\n",
    "                    self.s11, self.bandwidth = output_value_1[1], output_value_1[2]\n",
    "                    fitness_score_dual1 = self._calculate_fitness()\n",
    "\n",
    "                    self.s11, self.bandwidth = output_value_2[1], output_value_2[2]\n",
    "                    fitness_score_dual2 = self._calculate_fitness()\n",
    "\n",
    "                    return fitness_score_dual1, fitness_score_dual2\n",
    "                else:\n",
    "                    return 0, 0\n",
    "            else:\n",
    "                # print(\"Dual bands are out of range.\")\n",
    "                return 0, 0\n",
    "        else:\n",
    "            # print(\"Dual band configuration does not fit.\")\n",
    "            return 0, 0\n",
    "\n",
    "    def _calculate_fitness(self):\n",
    "        s11_min, s11_max = -40, 0\n",
    "        bandwidth_min, bandwidth_max = 0, 0.07  # GHz\n",
    "        weights = [0.5, 0.5]\n",
    "        \n",
    "        normalized_s11 = (s11_max - self.s11) / (s11_max - s11_min)\n",
    "        normalized_bandwidth = (self.bandwidth - bandwidth_min) / (bandwidth_max - bandwidth_min)\n",
    "        \n",
    "        return weights[0] * normalized_s11 + weights[1] * normalized_bandwidth\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.array([random.uniform(*bounds) for bounds in [\n",
    "            (fx_low, fx_high), (fy_low, fy_high), \n",
    "            (l_low, l_high), (lextension_low, lextension_high), (lh_low, lh_high),\n",
    "            (lr_low, lr_high), (lv_low, lv_high), (offset1_low, offset1_high), \n",
    "            (pr_low, pr_high), (pr2_low, pr2_high), (w_low, w_high), \n",
    "            (wr_low, wr_high), (wu_low, wu_high)\n",
    "        ]])\n",
    "        return scaler_x1.transform([self.state])\n",
    "    \n",
    "#     def reset(self):\n",
    "#         self.state = x_data1[508]\n",
    "#         return scaler_x1.transform([self.state])\n",
    "    \n",
    "    \n",
    "    def final_validation(self):\n",
    "        if right_band_check and left_band_check and none_band_check and dual_band_check:\n",
    "            return 'valid'\n",
    "        else:\n",
    "            return 'non-valid'\n",
    "    def get_scores(self):\n",
    "        return self.designs_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7254ce5-dac5-47ec-b7c7-afbe01388818",
   "metadata": {},
   "source": [
    "## Ornstein-Uhlenbeck noise process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "e82bccc8-44bf-4a6b-8b10-eb7ba6dd478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Ornstein-Uhlenbeck noise process\n",
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, decay, theta=0.5, dt=1e-0, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.decay = decay\n",
    "        self.alpha = 1\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "        self._counter = 0\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = self.alpha * (\n",
    "                self.x_prev\n",
    "                + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "                + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        self.alpha = math.exp(self.decay * -self._counter)\n",
    "        self._counter += 1\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)\n",
    "\n",
    "\n",
    "# Define a replay buffer to store experiences\n",
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity = buffer_capacity, batch_size = batch_size):\n",
    "        # Number of \"experiences\" to store at max\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        # Num of tuples to train on.\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        # Instead of list of tuples as the exp.replay concept go\n",
    "        # We use different np.arrays for each tuple element\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "    # Takes (s,a,r,s') observation tuple as input\n",
    "    def record(self, obs_tuple):\n",
    "        # Set index to zero if buffer_capacity is exceeded,\n",
    "        # replacing old records\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "        self.state_buffer[index] = np.squeeze(obs_tuple[0])\n",
    "        self.action_buffer[index] = np.squeeze(obs_tuple[1])\n",
    "        self.reward_buffer[index] = np.squeeze(obs_tuple[2])\n",
    "        self.next_state_buffer[index] = np.squeeze(obs_tuple[3])\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "        # print(self.buffer_counter)\n",
    "    @tf.function\n",
    "    def update(\n",
    "        self, state_batch, action_batch, reward_batch, next_state_batch,\n",
    "    ):\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            # tf.print(\"target_actions: \", target_actions)\n",
    "            y = reward_batch + gamma * target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            # tf.print(\"y: \", y)\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            # tf.print(\"critic_value: \", critic_value)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "            # tf.print(\"critic_loss: \", critic_loss)\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            # tf.print(\"actions: \", actions)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "            # tf.print(\"critic_value: \", critic_value)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    # We compute the loss and update parameters\n",
    "    def learn(self):\n",
    "        # Get sampling range\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        # Randomly sample indices\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "        \n",
    "        # print('self.state_buffer[batch_indices]:',self.state_buffer[batch_indices])\n",
    "        # print('self.reward_buffer[batch_indices]:',self.reward_buffer[batch_indices])\n",
    "        \n",
    "        # Convert to tensors\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This update target parameters slowly based on rate `tau`, which is much less than one.\n",
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for target_weight, weight in zip(target_weights, weights):\n",
    "        target_weight.assign(tau * weight + (1 - tau) * target_weight)\n",
    "\n",
    "# # Setup Multi-GPU Strategy\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "def get_actor():\n",
    "    # with strategy.scope():\n",
    "    # Initialize weights between -3e-3 and 3-e3\n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_states,))\n",
    "    out = layers.Dense(Hidden_Neurons, activation=\"relu\")(inputs)               # use sigmoid function for hidden layers instead relu >>> Stuck in local extermum\n",
    "#     drop = keras.layers.Dropout(0.4)(out) #remove the drop-out layer\n",
    "#     out = layers.Dense(Hidden_Neurons*2, activation=\"sigmoid\")(out)\n",
    "    out = layers.Dense(2*Hidden_Neurons, activation=\"relu\")(out)\n",
    "    out = layers.Dense(2*Hidden_Neurons, activation=\"relu\")(out)\n",
    "    out = layers.Dense(Hidden_Neurons, activation=\"relu\")(out)\n",
    "\n",
    "#     outputs = layers.Dense(num_actions, kernel_initializer=last_init)(out)\n",
    "    outputs = layers.Dense(num_actions, activation=\"tanh\", kernel_initializer=last_init)(out) #no activation function is needed.\n",
    "    outputs = outputs * tf.convert_to_tensor(upper_bound_action.astype(np.float32))\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_critic():\n",
    "    # with strategy.scope():\n",
    "# State as input\n",
    "    state_input = layers.Input(shape=(num_states,))\n",
    "    state_out = layers.Dense(Hidden_Neurons, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.Dense(Hidden_Neurons*2, activation=\"sigmoid\")(state_out)\n",
    "#     drop = keras.layers.Dropout(0.4)(state_out)\n",
    "    state_out = layers.Dense(Hidden_Neurons, activation=\"relu\")(state_out)\n",
    "\n",
    "\n",
    "    # Action as input\n",
    "    action_input = layers.Input(shape=(num_actions,))\n",
    "    action_out = layers.Dense(Hidden_Neurons, activation=\"relu\")(action_input)\n",
    "\n",
    "    # Both are passed through separate layer before concatenating\n",
    "    concat = layers.Concatenate()([state_out, action_out])\n",
    "\n",
    "    out = layers.Dense(Hidden_Neurons, activation=\"relu\")(concat)\n",
    "#     out = layers.Dense(Hidden_Neurons, activation=\"sigmoid\")(out)\n",
    "    out = layers.Dense(Hidden_Neurons, activation=\"relu\")(out)\n",
    "    out = layers.Dense(Hidden_Neurons, activation=\"relu\")(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "\n",
    "    # Outputs single value for give state-action\n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    # Adding noise to action\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    # We make sure action is within bounds\n",
    "    legal_action = np.clip(sampled_actions, lower_bound_action, upper_bound_action)\n",
    "\n",
    "    return [np.squeeze(legal_action)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f2736-6622-4733-afd6-9d805e69ab11",
   "metadata": {},
   "source": [
    "## Execution Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "93f774e1-1148-45f7-a8c6-5abe9fa02bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.01  #  Standard deviation\n",
    "decay = 0.2e-2\n",
    "\n",
    "ou_noise = OUActionNoise(mean=np.zeros(num_actions), std_deviation=float(std_dev) * np.ones(num_actions), decay=decay)\n",
    "# print(\"ou_noise: \", ou_noise)\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "# Making the weights equal initially\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "# Learning rate for actor-critic models\n",
    "critic_lr = 0.003\n",
    "actor_lr = 0.001\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "max_timesteps_episode = 30\n",
    "total_episodes = 300\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "# Used to update target networks\n",
    "tau = 0.003\n",
    "\n",
    "buffer = Buffer(buffer_capacity, batch_size)\n",
    "learn_freq = 1\n",
    "target_update_freq = 1\n",
    "\n",
    "learn_counter = 0\n",
    "target_update_counter = 0\n",
    "timestep_counter = 0\n",
    "\n",
    "# To store reward history of each episode\n",
    "ep_reward_list = []\n",
    "# To store average reward history of last few episodes\n",
    "avg_reward_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a3eac-7d74-40ea-9518-7750fc7951c2",
   "metadata": {},
   "source": [
    "## Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "2d38393f-5338-4d5a-920b-d8a25d2174fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:10\n",
      "Reset state: [[-0.20655737  0.3634531  -0.99606486  0.73448982 -0.20018505 -0.2054534\n",
      "   0.37395053  0.20033768 -0.39384808 -0.21678604 -0.34706597 -0.73137396\n",
      "  -0.46377462]]\n",
      "time step:  6678\n",
      "new_state: [22.19852417  9.79125859 55.71107609 26.56740782 51.46264538  2.73054205\n",
      " 25.84732786 35.39022409 -3.01975414 23.60672258 68.39940392  5.0209316\n",
      "  5.26969537]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6679\n",
      "new_state: [ 1.9816939   0.4980668  -0.12480749  0.09620753  1.99742011  0.42903114\n",
      " -0.49869871  1.30704269 -0.5438746  -0.40485878 -0.80512978  0.73366404\n",
      "  0.53440624]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.35347867106206876\n",
      "state: [[24.          9.5        58.23263176 26.25280284 53.          2.8\n",
      "  25.         36.         -3.         23.78106636 68.          6.53571279\n",
      "   6.2027589 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 0 * Reward is ==> -1.0534174863421057\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:11\n",
      "Reset state: [[-0.51664065  0.4511012  -1.11717523 -0.18896298 -0.15387461 -0.32209542\n",
      "   0.42979333 -0.10576857 -0.39387446 -0.82901312 -0.16322579  0.54742341\n",
      "   0.44414379]]\n",
      "time step:  6680\n",
      "new_state: [22.04962316  9.45726362 55.72729152 25.72162705 51.12915175  2.54183914\n",
      " 26.3811028  34.80552918 -3.13677499 23.56835953 68.33073857  6.15968142\n",
      "  5.61224051]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6681\n",
      "new_state: [ 1.98381972  0.47058287 -0.11883957  0.08018673  1.99846279  0.42926891\n",
      " -0.5008019   1.30732778 -0.54387461 -0.41652985 -0.80361641  0.72993061\n",
      "  0.53404167]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.356786729320166\n",
      "state: [[24.          9.5        58.25123991 26.22621241 53.          2.8\n",
      "  25.         36.         -3.         23.76464762 68.          6.5331328\n",
      "   6.20246265]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 1 * Reward is ==> -1.0567255446002028\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:12\n",
      "Reset state: [[-0.91907394  0.36009349 -0.53033579  0.4291054   0.25086894 -0.23847832\n",
      "   0.40677272 -0.17663884 -0.39382032 -0.75611756 -0.09794185  0.82830126\n",
      "   0.70554606]]\n",
      "time step:  6682\n",
      "new_state: [21.44060243  9.20995112 57.71385766 26.95034706 53.09336924  2.6552118\n",
      " 26.7523754  34.9080948  -2.88420962 23.10420537 68.57070929  6.28727571\n",
      "  5.71671964]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6683\n",
      "new_state: [ 1.98781958  0.44498312 -0.11186117  0.06695046  1.99921976  0.42942275\n",
      " -0.50247774  1.30755588 -0.54387463 -0.42447228 -0.80293457  0.7266553\n",
      "  0.53357265]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.35899893598852395\n",
      "state: [[24.          9.46719955 58.27299875 26.20424359 53.          2.8\n",
      "  25.         36.         -3.         23.7534743  68.          6.5308694\n",
      "   6.20208153]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 2 * Reward is ==> -1.058937751268561\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:13\n",
      "Reset state: [[ 0.60264574  0.14669283  0.10988095  0.64627292  0.20279003 -0.0493189\n",
      "   0.22274273  0.0790878  -0.39387352 -0.92327196 -0.1449295   1.25233864\n",
      "  -0.63553939]]\n",
      "time step:  6684\n",
      "new_state: [24.09881429  8.94139581 59.50292325 27.19570125 52.53214759  2.58910901\n",
      " 26.06200826 35.82286614 -3.13462493 23.72138497 67.99271338  6.60796324\n",
      "  4.56842361]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6685\n",
      "new_state: [ 1.98836875  0.42508369 -0.09346774  0.06704891  1.99912285  0.42940607\n",
      " -0.50231689  1.30758625 -0.54387462 -0.42270955 -0.80258851  0.72623551\n",
      "  0.53371641]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.36209620871946746\n",
      "state: [[24.          9.43759583 58.33034997 26.20440699 53.          2.8\n",
      "  25.         36.         -3.         23.7559541  68.          6.5305793\n",
      "   6.20219835]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 3 * Reward is ==> -1.0620350239995044\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:14\n",
      "Reset state: [[-0.14265309  0.25624218  0.41311142 -0.36841861  0.10364669  0.16115283\n",
      "   0.28156439 -0.03906098 -0.3938178  -0.39617532 -0.19785058  1.34597809\n",
      "  -0.42946663]]\n",
      "time step:  6686\n",
      "new_state: [22.58868691  9.10224092 60.45288848 25.51625878 52.10868054  2.68241947\n",
      " 26.26660511 35.33889762 -2.86295837 24.45269493 67.80432277  6.66575808\n",
      "  4.74736374]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6687\n",
      "new_state: [ 1.98651211  0.40818889 -0.05814041  0.08441533  1.99795306  0.42917526\n",
      " -0.49947872  1.30735947 -0.5438746  -0.40822793 -0.80231669  0.72945852\n",
      "  0.53472219]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.3689703033223838\n",
      "state: [[24.          9.41246199 58.44050155 26.23323081 53.          2.8\n",
      "  25.         36.         -3.         23.77632667 68.          6.53280656\n",
      "   6.20301564]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 4 * Reward is ==> -1.0689091186024207\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:14\n",
      "Reset state: [[-1.11745046 -0.08520832  0.26051832  0.57619995 -0.0594427  -0.17091555\n",
      "   0.3889927   0.24902706 -0.39385565 -0.01787881 -0.29994216  1.17777667\n",
      "  -0.32766659]]\n",
      "time step:  6688\n",
      "new_state: [21.36177356  9.17269468 59.06217118 26.00652841 51.84815317  2.61802257\n",
      " 25.75894314 36.40982738 -3.05038049 24.68439593 68.73207966  7.37518396\n",
      "  5.41062505]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6689\n",
      "new_state: [ 1.97655215  0.39122551 -0.00236834  0.11914815  1.99540299  0.42863521\n",
      " -0.49328763  1.30678741 -0.54387455 -0.37793671 -0.80176032  0.73654258\n",
      "  0.5368897 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.38294353786432\n",
      "state: [[24.          9.38722612 58.61440041 26.29087841 53.          2.8\n",
      "  25.         36.         -3.         23.81894001 68.          6.537702\n",
      "   6.20477696]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 5 * Reward is ==> -1.082882353144357\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:15\n",
      "Reset state: [[-0.28680179  0.23606662 -0.47581509 -0.05098365 -0.0152886   0.18199583\n",
      "   0.38641599  0.05905321 -0.39382128 -0.42509102 -0.05648166 -0.14719314\n",
      "  -0.83614639]]\n",
      "time step:  6690\n",
      "new_state: [22.26264765  9.0776239  57.65794495 25.98151337 51.57322235  2.72836451\n",
      " 26.49889766 35.53116589 -2.86545575 24.17713704 68.54013667  5.71934011\n",
      "  4.57022701]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6691\n",
      "new_state: [ 1.95644199  0.37292444  0.06585963  0.16372374  1.99129745  0.42767488\n",
      " -0.48355751  1.30580802 -0.54387444 -0.33254427 -0.80052906  0.74661123\n",
      "  0.54023786]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.4127898897501876\n",
      "state: [[24.          9.36000022 58.82713709 26.3648625  53.          2.8\n",
      "  25.         36.         -3.         23.88279756 68.          6.54465994\n",
      "   6.20749767]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6692\n",
      "new_state: [ 1.2588497   0.21929548  0.75636277  0.32099686  1.34071203  0.20669517\n",
      " -0.33343918  1.08399978 -0.53845842  0.42277618 -1.33630696  0.37678277\n",
      " -0.21042179]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6862782471904557\n",
      "state: [[24.          9.13145148 60.         26.62589568 53.          2.7677525\n",
      "  25.         36.         -3.         24.94537363 68.          6.2890901\n",
      "   5.59751228]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6693\n",
      "new_state: [ 1.1855925   0.10109654  1.04549755  0.37458212  1.26591126  0.15794723\n",
      " -0.40435428  0.93582954 -0.53123825  0.99500074 -1.21739995  0.0948444\n",
      " -0.85524816]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.6914712146396562\n",
      "state: [[24.          8.9556108  60.         26.71483351 53.          2.74642254\n",
      "  25.         36.         -3.         25.         68.          6.09425667\n",
      "   5.07352692]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6694\n",
      "new_state: [ 0.93090535  0.47806827  0.7436137  -0.17906922  1.66423855  0.29153028\n",
      " -0.82383177  0.19989709 -0.54066929  0.1994236  -0.27243035 -0.36595937\n",
      " -0.81901935]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6909635092128222\n",
      "state: [[24.          9.5        60.         25.7959138  53.          2.8\n",
      "  25.         35.57259468 -3.         24.6311638  68.43650271  5.77581837\n",
      "   5.10296642]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6695\n",
      "new_state: [ 0.98669659  0.54364138  0.84695868 -0.33185377  1.31404687  0.34956567\n",
      " -0.63109595  0.63858139 -0.52667274  0.19009654 -0.47733191 -0.59459611\n",
      " -1.11904993]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.5091511790892262\n",
      "state: [[24.          9.5        60.         25.54233049 53.          2.8\n",
      "  25.         36.         -3.         24.61804261 68.          5.61781902\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6696\n",
      "new_state: [ 0.92504586  0.73102137  0.49796055 -0.35629943  1.46618188  0.39960221\n",
      " -0.81368586  0.73249655 -0.53976584 -0.10494501 -0.4905447  -0.93743965\n",
      " -1.09705705]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.5560855876988035\n",
      "state: [[24.          9.5        60.         25.50175696 53.          2.8\n",
      "  25.         36.         -3.         24.20298157 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6697\n",
      "new_state: [ 0.98335824  0.7059895   0.49646809 -0.40229435  1.42958363  0.38381106\n",
      " -0.81690726  0.74677128 -0.53759818 -0.28722342 -0.50551738 -1.07463923\n",
      " -1.1662212 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.5585307394123674\n",
      "state: [[24.          9.5        60.         25.42541714 53.          2.8\n",
      "  25.         36.         -3.         23.94655441 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6698\n",
      "new_state: [ 1.053853    0.65991303  0.53550974 -0.49889437  1.35824248  0.3528978\n",
      " -0.79491404  0.72424293 -0.53279636 -0.35600792 -0.50772795 -1.02675487\n",
      " -1.2609481 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.5611394207297886\n",
      "state: [[24.          9.5        60.         25.26508581 53.          2.8\n",
      "  25.         36.         -3.         23.84978917 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6699\n",
      "new_state: [ 1.06242673  0.66500509  0.47445454 -0.51148854  1.36206166  0.35487436\n",
      " -0.79550907  0.73304287 -0.53468592 -0.41332178 -0.54094452 -1.05307471\n",
      " -1.24808497]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.5629449601062406\n",
      "state: [[24.         9.5       60.        25.2441827 53.         2.8\n",
      "  25.        36.        -3.        23.7691607 68.         5.5\n",
      "   5.       ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6700\n",
      "new_state: [ 1.07361483  0.6534455   0.48420581 -0.56150739  1.34221098  0.34449493\n",
      " -0.79133124  0.73655969 -0.53331976 -0.4374673  -0.55444259 -1.03984158\n",
      " -1.27450196]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.5647193520959373\n",
      "state: [[24.          9.5        60.         25.16116419 53.          2.8\n",
      "  25.         36.         -3.         23.73519307 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6701\n",
      "new_state: [ 1.06101507  0.65814062  0.45593412 -0.57271302  1.34743114  0.34901893\n",
      " -0.790494    0.74598167 -0.53440767 -0.46975725 -0.56775646 -1.0536972\n",
      " -1.25859395]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.5659330547225105\n",
      "state: [[24.          9.5        60.         25.14256571 53.          2.8\n",
      "  25.         36.         -3.         23.68976793 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6702\n",
      "new_state: [ 1.05829206  0.64890501  0.47203146 -0.60415696  1.33360525  0.34381431\n",
      " -0.78544707  0.74822424 -0.53350892 -0.48896394 -0.57536376 -1.04451215\n",
      " -1.27158813]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.5674838990156148\n",
      "state: [[24.          9.5        60.         25.09037681 53.          2.8\n",
      "  25.         36.         -3.         23.66274819 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6703\n",
      "new_state: [ 1.05085802  0.64393653  0.47377845 -0.61399746  1.33214744  0.3447712\n",
      " -0.78155347  0.75238792 -0.53375874 -0.50808361 -0.58560053 -1.04849125\n",
      " -1.26885246]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.5681971773084158\n",
      "state: [[24.          9.5        60.         25.0740441  53.          2.8\n",
      "  25.         36.         -3.         23.63585086 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6704\n",
      "new_state: [ 1.05147762  0.63027736  0.49864903 -0.63084877  1.32265356  0.34011937\n",
      " -0.77497628  0.75291027 -0.53296896 -0.51401667 -0.59492656 -1.04151454\n",
      " -1.28249378]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.5688032117967776\n",
      "state: [[24.          9.5        60.         25.04607522 53.          2.8\n",
      "  25.         36.         -3.         23.6275043  68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6705\n",
      "new_state: [ 1.04560609  0.62086245  0.51362834 -0.63584021  1.31896358  0.33968294\n",
      " -0.76969387  0.75611917 -0.53278615 -0.51862854 -0.6027601  -1.04061913\n",
      " -1.28535165]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.5690082405630343\n",
      "state: [[24.          9.5        60.         25.03779071 53.          2.8\n",
      "  25.         36.         -3.         23.62101637 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6706\n",
      "new_state: [ 1.0445605   0.60610761  0.54076659 -0.64433362  1.31359238  0.33562143\n",
      " -0.76490196  0.76152286 -0.53209428 -0.51190199 -0.61405408 -1.03427584\n",
      " -1.30007369]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.569268511572232\n",
      "state: [[24.          9.5        60.         25.02369382 53.          2.8\n",
      "  25.         36.         -3.         23.6304792  68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6707\n",
      "new_state: [ 1.03511435  0.59808577  0.55768185 -0.64646492  1.31205958  0.33591715\n",
      " -0.7634795   0.76715586 -0.5319763  -0.50847277 -0.61920021 -1.03274038\n",
      " -1.30313398]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.5693298507314108\n",
      "state: [[24.          9.5        60.         25.02015641 53.          2.8\n",
      "  25.         36.         -3.         23.63530339 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6708\n",
      "new_state: [ 1.0286389   0.58698418  0.57904217 -0.65155117  1.30583678  0.33380381\n",
      " -0.76175409  0.77200482 -0.53139786 -0.50188717 -0.62565748 -1.02700769\n",
      " -1.31191114]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.5694964078039179\n",
      "state: [[24.          9.5        60.         25.01171454 53.          2.8\n",
      "  25.         36.         -3.         23.64456793 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6709\n",
      "new_state: [ 1.01884844  0.58021927  0.59098355 -0.65194991  1.30246461  0.33408906\n",
      " -0.76141101  0.77569053 -0.53122604 -0.49917054 -0.62951701 -1.02505903\n",
      " -1.31397015]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.5695034413573471\n",
      "state: [[24.          9.5        60.         25.01105272 53.          2.8\n",
      "  25.         36.         -3.         23.64838966 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6710\n",
      "new_state: [ 1.01606653  0.57182906  0.60525868 -0.65903346  1.29648313  0.33173992\n",
      " -0.76240588  0.78089408 -0.53057738 -0.4923905  -0.63439867 -1.0182081\n",
      " -1.32494641]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.5697544935314931\n",
      "state: [[24.          9.5        60.         25.         53.          2.8\n",
      "  25.         36.         -3.         23.65792774 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6711\n",
      "new_state: [ 1.0100878   0.56645852  0.6092723  -0.65781198  1.29750161  0.33270613\n",
      " -0.76318746  0.78694424 -0.53071608 -0.4879614  -0.64053017 -1.01890949\n",
      " -1.32704745]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.569706112401469\n",
      "state: [[24.          9.5        60.         25.00132318 53.          2.8\n",
      "  25.         36.         -3.         23.66415854 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6712\n",
      "new_state: [ 1.01008186  0.55833756  0.62065111 -0.66307266  1.29581642  0.33109818\n",
      " -0.76387752  0.79414648 -0.53026437 -0.47789869 -0.64601299 -1.01429893\n",
      " -1.3374833 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.5694858901585136\n",
      "state: [[24.          9.5        60.         25.         53.          2.8\n",
      "  25.         36.         -3.         23.67831465 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6713\n",
      "new_state: [ 1.00750759  0.55403767  0.62677409 -0.664705    1.29641475  0.33169692\n",
      " -0.76430482  0.79945985 -0.53012295 -0.46827686 -0.64833153 -1.01217823\n",
      " -1.34117122]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.5692362616565624\n",
      "state: [[24.          9.5        60.         25.         53.          2.8\n",
      "  25.         36.         -3.         23.69185053 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6714\n",
      "new_state: [ 1.00439452  0.54705529  0.63666864 -0.66273062  1.29621528  0.33243311\n",
      " -0.76057123  0.80591041 -0.53011132 -0.45860822 -0.65345827 -1.01296095\n",
      " -1.34019304]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.5689819300339656\n",
      "state: [[24.          9.5        60.         25.         53.          2.8\n",
      "  25.         36.         -3.         23.70545227 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6715\n",
      "new_state: [ 1.00312804  0.5402944   0.64329789 -0.6535937   1.29635311  0.33357332\n",
      " -0.75503325  0.8116456  -0.5301839  -0.44836262 -0.65766937 -1.01553908\n",
      " -1.3370988 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.5684728217698289\n",
      "state: [[24.          9.5        60.         25.00832445 53.          2.8\n",
      "  25.         36.         -3.         23.71986565 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6716\n",
      "new_state: [ 1.00159965  0.53646117  0.64894008 -0.64920318  1.29834126  0.33554022\n",
      " -0.74969354  0.81707158 -0.53013519 -0.43877307 -0.65682873 -1.01592368\n",
      " -1.33262064]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.5680106599274123\n",
      "state: [[24.          9.5        60.         25.01561159 53.          2.8\n",
      "  25.         36.         -3.         23.73335612 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6717\n",
      "new_state: [ 1.0034535   0.53316889  0.65262415 -0.64606306  1.29774019  0.33636488\n",
      " -0.74425846  0.82218752 -0.52991816 -0.4269908  -0.65576575 -1.01506141\n",
      " -1.33043298]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.5675456224686679\n",
      "state: [[24.          9.5        60.         25.0208234  53.          2.8\n",
      "  25.         36.         -3.         23.74993128 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6718\n",
      "new_state: [ 1.00377777  0.53498569  0.6451167  -0.64194981  1.29908842  0.33911232\n",
      " -0.74134656  0.82694803 -0.5300437  -0.41810111 -0.65143362 -1.0153881\n",
      " -1.32117644]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.5671151990640659\n",
      "state: [[24.          9.5        60.         25.02765033 53.          2.8\n",
      "  25.         36.         -3.         23.76243719 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6719\n",
      "new_state: [ 1.00536222  0.53721719  0.63232889 -0.63909275  1.29962775  0.34191481\n",
      " -0.73817816  0.83108044 -0.53034438 -0.41463828 -0.64974673 -1.01597411\n",
      " -1.30999521]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.5668923831359779\n",
      "state: [[24.          9.5        60.         25.03239232 53.          2.8\n",
      "  25.         36.         -3.         23.76730867 68.          5.5\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6720\n",
      "new_state: [ 1.00932027  0.53808361  0.62279161 -0.64263585  1.29252951  0.34193876\n",
      " -0.7362487   0.83583966 -0.53021157 -0.41002667 -0.6491655  -1.01307221\n",
      " -1.30464218]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.566921832914387\n",
      "state: [[24.          9.5        60.         25.02651168 53.          2.8\n",
      "  25.         36.         -3.         23.77379622 68.          5.5\n",
      "   5.        ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6721\n",
      "The timesteps per episode reached the max.....\n",
      "Episode * 6 * Reward is ==> -17.86315991713913\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:28\n",
      "Reset state: [[-0.64480634  0.4104769  -0.12487658 -0.63421584  0.4428879   0.09222381\n",
      "   0.23357137 -0.09201864 -0.3938346   0.11109177  0.12772582 -0.67501138\n",
      "  -0.49319632]]\n",
      "time step:  6722\n",
      "new_state: [21.8437008   9.7815429  58.08313845 24.69887397 53.6641423   2.75702492\n",
      " 25.38334275 34.92193142 -2.93934411 24.68003279 69.97324246  5.75171956\n",
      "  4.92254845]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6723\n",
      "new_state: [ 2.1062316   0.09688955  0.05992508 -0.10718951  2.00161447  0.4287421\n",
      " -0.49499699  1.3088052  -0.54387471 -0.26669662 -0.84032414  0.70245791\n",
      "  0.52422815]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.41021332193030213\n",
      "state: [[24.          8.9493522  58.80863299 25.91521575 53.          2.8\n",
      "  25.         36.         -3.         23.97543127 68.          6.5141478\n",
      "   6.1944882 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6724\n",
      "new_state: [ 1.26221137 -0.05117028  0.77773302  0.04522916  1.43152544  0.18077636\n",
      " -0.28832007  1.18493793 -0.54216648  0.6020059  -1.3684737   0.23709241\n",
      " -0.30980835]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.467878356082145\n",
      "state: [[24.          8.72908847 60.         26.16819178 53.          2.75641157\n",
      "  25.         36.         -3.         25.         68.          6.19255712\n",
      "   5.51675085]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6725\n",
      "new_state: [ 1.18268398 -0.16204722  1.03789235  0.09519703  1.36880515  0.09015857\n",
      " -0.35863839  1.12436663 -0.54016968  1.236996   -1.33744156 -0.15731742\n",
      " -1.0848032 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.46389431970888584\n",
      "state: [[24.          8.5641405  60.         26.25112568 53.          2.7167612\n",
      "  25.         36.         -3.         25.         68.          5.92000033\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6726\n",
      "new_state: [ 0.81581989  0.06210619  0.70814177 -0.29444936  1.41297778  0.20335663\n",
      " -0.70285444  0.6843006  -0.53776541  0.22965507 -0.45506885 -0.45470247\n",
      " -0.97018623]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3664269122843363\n",
      "state: [[24.          8.89760614 60.         25.60441225 53.          2.7662917\n",
      "  25.         36.         -3.         24.67369308 68.          5.71449248\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 7 * Reward is ==> -2.408351725285706\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:30\n",
      "Reset state: [[ 0.05701986  0.26851571 -0.81494682  1.00348053 -0.11332258 -0.33063402\n",
      "   0.0686906   0.0593274  -0.39385265  0.39616831 -0.01922436  0.61316765\n",
      "  -0.6115478 ]]\n",
      "time step:  6727\n",
      "new_state: [22.27387814  9.69374182 55.99695244 27.14582984 51.82131791  2.68177251\n",
      " 24.89931543 34.22689068 -3.04270088 24.27092399 69.28239347  5.84192994\n",
      "  5.72887131]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6728\n",
      "new_state: [ 2.09196592  0.08548048  0.07567026 -0.11470398  1.99976393  0.42702701\n",
      " -0.48745989  1.30879643 -0.54387471 -0.15935256 -0.84276769  0.70514161\n",
      "  0.52391506]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.4213743637637176\n",
      "state: [[24.          8.93237931 58.85772691 25.90274364 53.          2.8\n",
      "  25.         36.         -3.         24.12644165 68.          6.51600237\n",
      "   6.19423378]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6729\n",
      "new_state: [ 1.24510147 -0.04000639  0.74300375 -0.06315752  1.41820282  0.16749958\n",
      " -0.32194955  1.20922804 -0.54246385  0.71940701 -1.37058873  0.24071476\n",
      " -0.32192079]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.47298154950995097\n",
      "state: [[24.          8.74569663 60.         25.98829759 53.          2.75060223\n",
      "  25.         36.         -3.         25.         68.          6.19506034\n",
      "   5.50690829]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6730\n",
      "new_state: [ 1.18017231 -0.13404709  1.00635075 -0.07617895  1.36615587  0.06560888\n",
      " -0.39732061  1.15375598 -0.54087749  1.25401721 -1.34264218 -0.16261573\n",
      " -1.11492658]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "reward: -0.4716149495589036\n",
      "state: [[24.          8.60579537 60.         25.96668535 53.          2.70601933\n",
      "  25.         36.         -3.         25.         68.          5.91633893\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6731\n",
      "new_state: [ 0.78248895  0.01050041  0.72766336 -0.36175603  1.3945079   0.17143599\n",
      " -0.68235965  0.78173056 -0.53727664  0.25111691 -0.50558812 -0.44651655\n",
      " -1.07039894]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.3693985409466908\n",
      "state: [[24.          8.82083393 60.         25.49270038 53.          2.75232463\n",
      "  25.         36.         -3.         24.70388535 68.          5.72014936\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 8 * Reward is ==> -2.4353082190593\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:32\n",
      "Reset state: [[ 0.6193297  -0.10624978 -0.89628121  0.20301517  0.24983538  0.14253602\n",
      "   0.37064062  0.14206542 -0.39382254 -0.76596253  0.00560171  0.73790843\n",
      "  -0.16517848]]\n",
      "time step:  6732\n",
      "new_state: [24.19785061  8.53008154 56.40286201 26.44551698 52.72106229  2.69073756\n",
      " 26.38861782 36.05584432 -2.88632439 23.88863698 68.65029827  6.22805154\n",
      "  4.97422701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6733\n",
      "new_state: [ 2.0441933   0.06151201  0.06987446 -0.16270455  2.00209913  0.42812606\n",
      " -0.49432707  1.30902935 -0.5438747  -0.17262226 -0.84447566  0.69410776\n",
      "  0.52248639]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.4171115900233263\n",
      "state: [[24.          8.8967222  58.83965544 25.82307496 53.          2.8\n",
      "  25.         36.         -3.         24.107774   68.          6.50837743\n",
      "   6.19307285]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6734\n",
      "new_state: [ 1.24212241 -0.05840469  0.7563302  -0.13985696  1.42891563  0.16288077\n",
      " -0.34663591  1.22151719 -0.54269825  0.71483686 -1.37200273  0.21747837\n",
      " -0.33874113]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "reward: -0.6738565106128029\n",
      "state: [[24.          8.71832608 60.         25.86099613 53.          2.74858124\n",
      "  25.         36.         -3.         25.         68.          6.17900284\n",
      "   5.4932401 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6735\n",
      "new_state: [ 1.16978444 -0.15660734  1.01157715 -0.16867649  1.35033311  0.06418046\n",
      " -0.41354824  1.14701601 -0.54041964  1.23905965 -1.33368354 -0.17900801\n",
      " -1.12246761]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "reward: -0.4772261773932628\n",
      "state: [[24.          8.57223324 60.         25.81316308 53.          2.70539432\n",
      "  25.         36.         -3.         25.         68.          5.90501105\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6736\n",
      "new_state: [ 0.77243122 -0.00690325  0.74641105 -0.43389829  1.43304454  0.18030441\n",
      " -0.66639514  0.74194428 -0.53768443  0.19489655 -0.47635258 -0.48972542\n",
      " -1.06461725]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.35969507150681324\n",
      "state: [[24.          8.79494307 60.         25.37296268 53.          2.75620506\n",
      "  25.         36.         -3.         24.6247952  68.          5.69028988\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 9 * Reward is ==> -2.627828164816242\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:34\n",
      "Reset state: [[ 0.72830706  0.3024316  -0.98537598  0.68367095 -0.09355627  0.14520616\n",
      "   0.46538352  0.20387279 -0.3938544   0.04397132  0.05863541 -0.25453196\n",
      "   1.06495928]]\n",
      "time step:  6737\n",
      "new_state: [24.42182393  9.12209728 56.16602142 27.24523434 51.3204975   2.71516034\n",
      " 26.62274698 36.23087479 -3.03727696 24.91984617 68.98589825  5.57147607\n",
      "  6.03820158]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6738\n",
      "new_state: [ 2.049405    0.03014859  0.0080978  -0.22281849  2.004887    0.42971476\n",
      " -0.50695197  1.30924331 -0.54387471 -0.28962994 -0.8456911   0.68075358\n",
      "  0.52043708]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "reward: -0.39565922559003586\n",
      "state: [[24.          8.85006388 58.64703412 25.72330119 53.          2.8\n",
      "  25.         36.         -3.         23.94316895 68.          6.49914903\n",
      "   6.19140758]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 10 * Reward is ==> -1.0955980408700727\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:35\n",
      "Reset state: [[ 0.13739411  0.2226798  -0.53621623  0.56709992  0.0072565  -0.33245537\n",
      "   0.14044782 -0.0860703  -0.39387018 -0.66680359  0.10071266 -0.74264486\n",
      "   0.00748176]]\n",
      "time step:  6739\n",
      "new_state: [24.48181686  9.6282317  56.94013406 26.03232684 52.29747915  2.67556735\n",
      " 24.93978655 35.37054759 -3.12779904 23.64598347 69.99247498  6.18366974\n",
      "  4.83966279]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6740\n",
      "new_state: [ 2.05641166  0.02336389 -0.03680492 -0.23852214  2.00536272  0.42992393\n",
      " -0.50968558  1.30927867 -0.54387471 -0.32125513 -0.8461105   0.67761489\n",
      "  0.51985061]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3779908705450763\n",
      "state: [[24.          8.83997051 58.5070262  25.69723715 53.          2.8\n",
      "  25.         36.         -3.         23.898679   68.          6.49698004\n",
      "   6.19093101]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 11 * Reward is ==> -1.0779296858251133\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:36\n",
      "Reset state: [[-0.84237578  0.37025943 -0.8856789   0.68323294  0.32351813  0.05056361\n",
      "   0.1830002   0.13362562 -0.39382213 -0.26123664  0.09601336 -0.69938216\n",
      "   1.0390539 ]]\n",
      "time step:  6741\n",
      "new_state: [21.39808652  9.00715467 57.15243904 27.61145768 53.7593281   2.8494104\n",
      " 26.1757478  36.30960467 -2.89473742 23.01668635 69.21942789  4.8235436\n",
      "  6.11736593]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6742\n",
      "new_state: [ 2.04529571  0.02235138 -0.01501224 -0.23384654  2.00513101  0.4297787\n",
      " -0.50609608  1.30926079 -0.54387471 -0.28806665 -0.84632625  0.67884894\n",
      "  0.52007031]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3898969063073092\n",
      "state: [[24.          8.83846423 58.57497638 25.70499745 53.          2.8\n",
      "  25.         36.         -3.         23.94536817 68.          6.49783283\n",
      "   6.19110954]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 12 * Reward is ==> -1.0898357215873462\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:37\n",
      "Reset state: [[-1.04250732 -0.0942388  -0.25415195  0.36802052  0.48931416  0.00323889\n",
      "   0.4582097   0.07304494 -0.39385401 -0.27203381 -0.15695091  0.30714367\n",
      "   0.31085158]]\n",
      "time step:  6743\n",
      "new_state: [20.83534455  8.72159375 58.36728769 26.58190508 53.72730905  2.65563962\n",
      " 26.47630174 35.67538946 -3.02993863 24.42852002 68.36593224  6.06789552\n",
      "  5.46006239]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6744\n",
      "new_state: [ 2.02431131  0.02455768  0.04162365 -0.21546992  2.00427545  0.42921283\n",
      " -0.49705912  1.30919665 -0.54387471 -0.20207649 -0.84643229  0.68310435\n",
      "  0.52082381]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.4019615456351311\n",
      "state: [[24.          8.84174647 58.75156865 25.73549794 53.          2.8\n",
      "  25.         36.         -3.         24.06633813 68.          6.50077353\n",
      "   6.19172183]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6745\n",
      "new_state: [ 1.30618099 -0.12288807  0.79431672 -0.12943195  1.41879509  0.17032748\n",
      " -0.33634444  1.2148366  -0.54252631  0.68150503 -1.36861598  0.22114732\n",
      " -0.33622321]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.4673144897148621\n",
      "state: [[24.          8.62239629 60.         25.87829898 53.          2.75183959\n",
      "  25.         36.         -3.         25.         68.          6.18153827\n",
      "   5.49528616]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6746\n",
      "new_state: [ 1.17138536 -0.24567767  1.02831864 -0.109227    1.27135159  0.09977417\n",
      " -0.37250363  1.07326352 -0.53609882  1.15466233 -1.28093889 -0.10854473\n",
      " -1.04550591]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.4723463868515\n",
      "state: [[24.          8.5        60.         25.91183404 53.          2.72096856\n",
      "  25.         36.         -3.         25.         68.          5.95370468\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6747\n",
      "new_state: [ 0.67017959  0.09065947  0.73208483 -0.51011802  1.50420475  0.23851203\n",
      " -0.55603707  0.28791047 -0.53819509  0.04269119 -0.37970532 -0.48353688\n",
      " -0.84765617]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.33700137678728515\n",
      "state: [[23.84095161  8.94008393 60.         25.24645741 53.          2.78167416\n",
      "  25.         35.91616465 -3.         24.41067447 68.03927734  5.69456646\n",
      "   5.07969617]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 13 * Reward is ==> -2.3785626142688154\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:38\n",
      "Reset state: [[-1.04902271 -0.19845817 -0.04435093  0.55563648  0.09062025 -0.30085137\n",
      "   0.00260511 -0.11622928 -0.39381901  0.43363633 -0.23761205  0.84464746\n",
      "   0.17812008]]\n",
      "time step:  6748\n",
      "new_state: [19.90588729  8.99830097 58.43520472 26.2145847  52.55644637  2.69508672\n",
      " 24.91029851 33.71555453 -2.87922349 24.22208773 68.47841625  6.07427352\n",
      "  6.53439842]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6749\n",
      "new_state: [ 1.97262134  0.02995114  0.07135362 -0.19118045  2.0025948   0.42783192\n",
      " -0.4814292   1.30905721 -0.54387471 -0.07038736 -0.84640805  0.68924829\n",
      "  0.52213063]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.41646152825139704\n",
      "state: [[24.          8.84977015 58.8442675  25.77581226 53.          2.8\n",
      "  25.         36.         -3.         24.25159687 68.          6.5050193\n",
      "   6.19278375]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6750\n",
      "new_state: [ 1.33237048 -0.11083378  0.8035652  -0.09481727  1.41265378  0.16911947\n",
      " -0.34423656  1.21408242 -0.54252925  0.81295352 -1.36873022  0.2350188\n",
      " -0.33802089]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "reward: -0.46687957816951564\n",
      "state: [[24.          8.64032905 60.         25.9357505  53.          2.75131102\n",
      "  25.         36.         -3.         25.         68.          6.19112415\n",
      "   5.49382536]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6751\n",
      "new_state: [ 1.1659099  -0.22136694  0.99864665 -0.07929001  1.25809606  0.09864295\n",
      " -0.38012324  1.05960287 -0.53541242  1.13599693 -1.27219696 -0.08015729\n",
      " -1.04003134]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.47070340045215153\n",
      "state: [[24.          8.5        60.         25.96152178 53.          2.72047359\n",
      "  25.         36.         -3.         25.         68.          5.97332181\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6752\n",
      "new_state: [ 0.67918583  0.06277656  0.76218589 -0.45141458  1.48420769  0.2341456\n",
      " -0.57538125  0.35302022 -0.5379746   0.09754008 -0.38491191 -0.44881518\n",
      " -0.91089105]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.3465401454204414\n",
      "state: [[23.85910729  8.89860344 60.         25.34389012 53.          2.7797636\n",
      "  25.         36.         -3.         24.48783525 68.019998    5.71856089\n",
      "   5.02831155]]\n",
      "Learning process is done....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating the target networks is done....\n",
      "Episode * 14 * Reward is ==> -2.4005234675735427\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:40\n",
      "Reset state: [[-0.41838125  0.23090732  0.11534245  1.0946057  -0.06566807  0.05027488\n",
      "   0.04095323  0.09338481 -0.39385748 -0.68352722 -0.1751539   0.46977952\n",
      "   1.31833759]]\n",
      "time step:  6753\n",
      "new_state: [23.38744936  8.66049993 60.49874924 28.25250698 52.19762991  2.84922074\n",
      " 26.34551073 36.15661375 -3.0663404  22.40429688 68.24107294  5.66565271\n",
      "  5.91257399]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6754\n",
      "new_state: [ 2.0371685   0.00998988 -0.18020456 -0.27331933  2.00615904  0.43024857\n",
      " -0.51576356  1.30933148 -0.54387471 -0.39533479 -0.84645174  0.67051561\n",
      "  0.51883692]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.3637187277173767\n",
      "state: [[24.          8.82007443 58.0599022  25.63948271 53.          2.8\n",
      "  25.         36.         -3.         23.79446459 68.          6.49207408\n",
      "   6.19010729]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 15 * Reward is ==> -1.0636575429974136\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:41\n",
      "Reset state: [[-0.7605677   0.14538575  0.38770097  0.39858938  0.40558456 -0.2668769\n",
      "   0.21950308 -0.19443867 -0.39384062  0.39518642 -0.36290183  1.38697815\n",
      "   1.35945644]]\n",
      "time step:  6755\n",
      "new_state: [21.38684616  9.12495541 60.23316699 26.59469233 53.50013192  2.52706484\n",
      " 25.55304323 34.76342828 -2.9687466  25.46256065 67.4753634   6.87352995\n",
      "  6.32738111]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6756\n",
      "new_state: [ 2.02332617  0.00785085 -0.20754986 -0.27871884  2.00628509  0.4302954\n",
      " -0.51740546  1.30934095 -0.54387471 -0.41853489 -0.84625327  0.6694772\n",
      "  0.51872185]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.37684897604773615\n",
      "state: [[24.          8.81689226 57.9746388  25.63052091 53.          2.8\n",
      "  25.         36.         -3.         23.76182696 68.          6.49135649\n",
      "   6.19001378]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 16 * Reward is ==> -1.076787791327773\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:42\n",
      "Reset state: [[-0.74028417 -0.10491614 -0.61729439 -0.09335939 -0.18120262  0.11050645\n",
      "   0.32621036 -0.15024544 -0.39383188 -0.89698801  0.08687037  0.95026552\n",
      "   0.43731993]]\n",
      "time step:  6757\n",
      "new_state: [21.45851362  8.56861469 57.29950523 25.99103307 51.01990953  2.68203435\n",
      " 26.2533268  34.88242815 -2.93102095 23.63530601 69.05226989  6.42038127\n",
      "  5.49420753]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6758\n",
      "new_state: [ 2.00043036  0.00848346 -0.20715464 -0.27770407  2.00629528  0.43030362\n",
      " -0.51686057  1.30933849 -0.54387471 -0.42338045 -0.8459163   0.66972188\n",
      "  0.51891273]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.379211360465329\n",
      "state: [[24.          8.81783338 57.97587108 25.63220516 53.          2.8\n",
      "  25.         36.         -3.         23.75501029 68.          6.49152558\n",
      "   6.19016889]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 17 * Reward is ==> -1.0791501757453659\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:43\n",
      "Reset state: [[ 0.45401515  0.32681933 -0.87695852  0.89000561 -0.19169068  0.05736556\n",
      "   0.3743637   0.13827026 -0.39384096 -0.82405249 -0.25576169  1.11869582\n",
      "   0.90020734]]\n",
      "time step:  6759\n",
      "new_state: [23.86991451  9.15636237 56.53518752 27.68923493 50.96294525  2.62806137\n",
      " 26.47011017 36.11549429 -2.97968229 23.9216302  67.59172365  6.47701769\n",
      "  5.76522005]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6760\n",
      "new_state: [ 1.96502307  0.01271296 -0.17574687 -0.26929601  2.00618268  0.43027698\n",
      " -0.51378217  1.3093206  -0.54387471 -0.40932712 -0.84535619  0.67139001\n",
      "  0.51948875]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.3660860960739787\n",
      "state: [[24.          8.82412547 58.07380137 25.64616039 53.          2.8\n",
      "  25.         36.         -3.         23.77478034 68.          6.49267834\n",
      "   6.19063696]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 18 * Reward is ==> -1.0660249113540154\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:43\n",
      "Reset state: [[ 0.21296741  0.308056    0.42904169  0.7790078   0.05682287 -0.37842133\n",
      "  -0.05728025  0.22521674 -0.39383321  0.26473502 -0.36792262  0.86947258\n",
      "  -0.81299477]]\n",
      "time step:  6761\n",
      "new_state: [22.62517157  9.74754469 59.99898502 26.52605326 52.51494593  2.66078271\n",
      " 24.7076045  34.95338023 -2.94820708 24.14246191 68.09442866  6.02209076\n",
      "  5.61248643]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6762\n",
      "new_state: [ 1.92350446  0.01801147 -0.15691114 -0.26173662  2.00605583  0.43024413\n",
      " -0.51044587  1.30929803 -0.54387471 -0.39492183 -0.84477343  0.67302779\n",
      "  0.52010637]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3676285822549399\n",
      "state: [[24.          8.83200788 58.1325317  25.65870705 53.          2.8\n",
      "  25.         36.         -3.         23.79504554 68.          6.49381013\n",
      "   6.19113884]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 19 * Reward is ==> -1.0675673975349769\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:44\n",
      "Reset state: [[ 0.06769887 -0.01111343 -0.36105405 -0.20367796  0.34268055  0.08688757\n",
      "   0.10737862  0.03365664 -0.39382196 -0.61583896 -0.31258257 -0.37997298\n",
      "   0.3871658 ]]\n",
      "time step:  6763\n",
      "new_state: [23.07654511  8.64940262 58.12422749 25.86661818 53.12076233  2.64961017\n",
      " 25.63183674 35.69295146 -2.88601188 24.19876413 67.39138262  5.44730902\n",
      "  5.37321653]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6764\n",
      "new_state: [ 1.87667134  0.0236463  -0.13592169 -0.25520883  2.00591921  0.43020608\n",
      " -0.50719332  1.30927162 -0.54387471 -0.37947632 -0.84419728  0.67450256\n",
      "  0.52074127]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3677493322644241\n",
      "state: [[24.          8.84039064 58.19797739 25.66954152 53.          2.8\n",
      "  25.         36.         -3.         23.81677411 68.          6.49482927\n",
      "   6.19165476]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 20 * Reward is ==> -1.067688147544461\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:45\n",
      "Reset state: [[-1.13551292  0.41111287 -0.75210539 -0.36086454  0.10485585  0.24701699\n",
      "   0.45638444 -0.08376387 -0.39382745 -0.2161235  -0.04565776 -0.22806848\n",
      "   1.21045404]]\n",
      "time step:  6765\n",
      "new_state: [20.89991238  9.11961    57.20784705 25.59019318 52.77723493  2.93228759\n",
      " 27.03420741 35.42324466 -2.92048682 23.24535527 69.07487513  5.33648405\n",
      "  6.30144217]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6766\n",
      "new_state: [ 1.82910217  0.02984073 -0.0902386  -0.24625467  2.0056939   0.43013323\n",
      " -0.50262995  1.30922916 -0.54387471 -0.35252399 -0.84363088  0.67649632\n",
      "  0.521546  ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.3739696596123505\n",
      "state: [[24.          8.84960589 58.34041852 25.68440313 53.          2.8\n",
      "  25.         36.         -3.         23.85469032 68.          6.49620705\n",
      "   6.19230869]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 21 * Reward is ==> -1.0739084748923875\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:46\n",
      "Reset state: [[-4.47541847e-01  1.00211106e-04  4.06827551e-01 -2.39126211e-01\n",
      "  -1.57706454e-01 -1.75734036e-01  3.96054999e-01  2.26322204e-01\n",
      "  -3.93851491e-01 -6.69576024e-01  1.88758245e-02 -5.43972729e-01\n",
      "   1.02313012e+00]]\n",
      "time step:  6767\n",
      "new_state: [23.47049494  9.3044234  59.49998106 24.64840572 51.28885772  2.67995993\n",
      " 25.77230057 36.54031397 -3.03610321 23.9655724  69.86778489  6.39695594\n",
      "  5.62859919]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6768\n",
      "new_state: [ 1.77892054  0.03629787 -0.02649884 -0.23583637  2.00537347  0.43001699\n",
      " -0.49701193  1.30916652 -0.54387471 -0.31678359 -0.84302776  0.67883361\n",
      "  0.52251536]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3889996949702782\n",
      "state: [[24.          8.85921197 58.53916085 25.70169485 53.          2.8\n",
      "  25.         36.         -3.         23.90496951 68.          6.49782224\n",
      "   6.19309639]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 22 * Reward is ==> -1.088938510250315\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:47\n",
      "Reset state: [[-0.47733246 -0.03687859 -0.36300594  0.06795099 -0.13621705 -0.09709547\n",
      "   0.21782289  0.2880118  -0.39386141 -0.45958128 -0.06526611  0.73388162\n",
      "  -0.67322035]]\n",
      "time step:  6769\n",
      "new_state: [21.82210707  8.76478999 57.89091346 26.08977588 51.00306776  2.64521697\n",
      " 25.96185211 36.26057228 -3.04522959 23.94472106 68.81381174  6.37474908\n",
      "  4.85486159]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6770\n",
      "new_state: [ 1.72887368  0.04376182  0.04330035 -0.22400815  2.00493333  0.42983124\n",
      " -0.49041978  1.30907621 -0.54387471 -0.27240018 -0.84245597  0.68147002\n",
      "  0.52361413]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.4076275072327784\n",
      "state: [[24.          8.87031584 58.75679664 25.72132667 53.          2.8\n",
      "  25.         36.         -3.         23.96740757 68.          6.49964413\n",
      "   6.19398925]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6771\n",
      "new_state: [ 1.34773028 -0.0544529   0.73701101 -0.18927746  1.44036966  0.16910075\n",
      " -0.3226152   1.18967196 -0.54193688  0.58261215 -1.36171522  0.24419909\n",
      " -0.33062032]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.46899881311862135\n",
      "state: [[24.          8.72420503 60.         25.77897073 53.          2.75130283\n",
      "  25.         36.         -3.         25.         68.          6.19746819\n",
      "   5.49983906]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6772\n",
      "new_state: [ 1.23643067 -0.14103724  1.02351146 -0.21903059  1.30772191  0.1006392\n",
      " -0.44188198  1.03080237 -0.53479864  1.0825011  -1.22560974 -0.06875364\n",
      " -1.03933443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.4785788875859499\n",
      "state: [[24.          8.59539636 60.         25.72958814 53.          2.72134706\n",
      "  25.         36.         -3.         25.         68.          5.9812023\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6773\n",
      "new_state: [ 0.66916169  0.1745555   0.7516804  -0.6290052   1.63498995  0.24190298\n",
      " -0.69626808  0.4212612  -0.54202104 -0.06068082 -0.33035337 -0.52103414\n",
      " -0.96409997]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "reward: -0.3449369387405218\n",
      "state: [[23.83889963  9.06489329 60.         25.04913509 53.          2.78315789\n",
      "  25.         36.         -3.         24.26525192 68.22202124  5.668654\n",
      "   5.        ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 23 * Reward is ==> -2.4000809619579084\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:49\n",
      "Reset state: [[ 0.45204355  0.3238156  -1.03524345  0.03797057 -0.19884229 -0.35004742\n",
      "   0.28199324 -0.05385271 -0.39381383  0.08736839 -0.27508927  0.87659996\n",
      "   1.06280312]]\n",
      "time step:  6774\n",
      "new_state: [23.81146611  9.63556337 55.66266715 25.84861074 51.12587734  2.63134558\n",
      " 25.75771778 34.62916783 -2.84887613 24.3810092  68.52814095  6.24392654\n",
      "  6.2753313 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6775\n",
      "new_state: [ 1.77032291  0.0525537  -0.02030036 -0.24211465  2.00540507  0.43000453\n",
      " -0.50083449  1.30914853 -0.54387471 -0.33034172 -0.84213667  0.67740966\n",
      "  0.52220536]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.38527619360337273\n",
      "state: [[24.          8.88339522 58.55848787 25.6912745  53.          2.8\n",
      "  25.         36.         -3.         23.8858961  68.          6.49683822\n",
      "   6.19284448]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 24 * Reward is ==> -1.0852150088834096\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:50\n",
      "Reset state: [[-0.3283011   0.24123264  0.03691344 -0.63407776 -0.08886818  0.27734486\n",
      "   0.34431209  0.02353484 -0.39385979  0.1050333   0.02086957  0.88189494\n",
      "   0.37271516]]\n",
      "time step:  6776\n",
      "new_state: [22.28813472  9.10555067 59.31295227 24.97197151 51.41476339  2.71515431\n",
      " 26.4159041  35.64267789 -3.07016648 25.19685666 68.61008919  6.28858816\n",
      "  5.32571516]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6777\n",
      "new_state: [ 1.80561815  0.05124758 -0.07091877 -0.2521423   2.00564769  0.43008494\n",
      " -0.50587119  1.3092023  -0.54387471 -0.36002117 -0.84245047  0.67542936\n",
      "  0.52135923]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.37908891230401365\n",
      "state: [[24.          8.88145216 58.40065827 25.67463117 53.          2.8\n",
      "  25.         36.         -3.         23.84414338 68.          6.49546973\n",
      "   6.19215691]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 25 * Reward is ==> -1.0790277275840505\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:51\n",
      "Reset state: [[-0.36167472  0.10455417  0.29328637  0.77659093 -0.23108346 -0.26689002\n",
      "   0.00135552  0.0477718  -0.39387037  0.34858738 -0.15843917  0.87451937\n",
      "   1.1324756 ]]\n",
      "time step:  6778\n",
      "new_state: [22.54312978  8.63058327 60.51522688 27.32912736 51.46674011  2.70886622\n",
      " 25.7543887  35.96419052 -3.12891653 23.91967459 68.63808275  6.1499482\n",
      "  6.044717  ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6779\n",
      "new_state: [ 1.82311773  0.05057478 -0.10659314 -0.25730858  2.00577106  0.43012787\n",
      " -0.50866489  1.30922907 -0.54387471 -0.37807336 -0.84254214  0.67439699\n",
      "  0.52096441]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.3724012923171214\n",
      "state: [[24.          8.88045125 58.28942463 25.66605646 53.          2.8\n",
      "  25.         36.         -3.         23.81874776 68.          6.49475631\n",
      "   6.19183608]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 26 * Reward is ==> -1.0723401075971584\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:52\n",
      "Reset state: [[ 0.72023549 -0.02680655  0.18139082  0.33831978 -0.06871314  0.14889025\n",
      "   0.45548484  0.29595041 -0.39385717 -0.23616115 -0.07046581  0.40216112\n",
      "  -0.85793216]]\n",
      "time step:  6780\n",
      "new_state: [24.28907516  8.80109323 59.58413722 26.49357782 51.35578596  2.67960263\n",
      " 26.68718431 36.47636032 -3.0471718  24.46158411 68.45166619  6.10470325\n",
      "  4.46588699]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6781\n",
      "new_state: [ 1.82565141  0.05070878 -0.12761896 -0.25819575  2.00580547  0.4301468\n",
      " -0.50948026  1.3092358  -0.54387471 -0.38801653 -0.84229364  0.67431929\n",
      "  0.52096472]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.36962873724097034\n",
      "state: [[24.          8.8806506  58.22386552 25.66458398 53.          2.8\n",
      "  25.         36.         -3.         23.80475984 68.          6.49470262\n",
      "   6.19183634]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 27 * Reward is ==> -1.0695675525210073\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:53\n",
      "Reset state: [[-1.18035731  0.1458786   0.12478908  0.89192375 -0.15512525 -0.18713719\n",
      "  -0.00865381 -0.10411636 -0.39386006 -0.93453466  0.08995327 -0.51152186\n",
      "  -0.05973192]]\n",
      "time step:  6782\n",
      "new_state: [21.91130715  9.51673394 59.26452757 26.29899146 51.83507818  2.7441057\n",
      " 24.44641638 35.38064607 -3.0788705  23.60839256 70.06284412  6.15835345\n",
      "  4.7364853 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6783\n",
      "new_state: [ 1.81634352  0.05089597 -0.13988983 -0.2562743   2.00578498  0.43015504\n",
      " -0.50875342  1.30922966 -0.54387471 -0.39304741 -0.84173543  0.67496488\n",
      "  0.52128189]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.3683111759107973\n",
      "state: [[24.          8.88092907 58.18560461 25.6677731  53.          2.8\n",
      "  25.         36.         -3.         23.79768245 68.          6.49514875\n",
      "   6.19209407]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 28 * Reward is ==> -1.068249991190834\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:53\n",
      "Reset state: [[ 0.29666875  0.4256324  -1.02156308 -0.12790919 -0.21227007 -0.3097997\n",
      "   0.20422737  0.16947909 -0.39387117 -0.24022791  0.06107286 -0.60125461\n",
      "   1.00714865]]\n",
      "time step:  6784\n",
      "new_state: [23.15569346  9.9066688  55.35139756 25.30488414 51.35751313  2.68718616\n",
      " 25.27083052 35.23370973 -3.13246816 23.43705025 69.73183778  4.99898487\n",
      "  6.33091883]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6785\n",
      "new_state: [ 1.79933717  0.05158197 -0.13895802 -0.25053332  2.0056698   0.43013873\n",
      " -0.50613048  1.3092048  -0.54387471 -0.39013135 -0.8408206   0.67660817\n",
      "  0.52198257]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.3678808414160525\n",
      "state: [[24.          8.88194962 58.18851004 25.67730166 53.          2.8\n",
      "  25.         36.         -3.         23.80178473 68.          6.49628435\n",
      "   6.19266344]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 29 * Reward is ==> -1.0678196566960894\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:54\n",
      "Reset state: [[-1.82602040e-01 -1.11248435e-01 -4.56267964e-01  1.10406373e+00\n",
      "  -2.03141330e-01 -2.33703349e-01  1.16360585e-01  2.73857154e-01\n",
      "  -3.93837099e-01 -3.02418353e-01 -1.23943118e-03  1.06918843e+00\n",
      "   1.35479832e+00]]\n",
      "time step:  6786\n",
      "new_state: [22.47026302  8.67599328 57.73785016 27.79735264 50.85715001  2.6115195\n",
      " 25.3851997  36.30749167 -2.94866451 24.03502098 69.24097024  6.53086832\n",
      "  6.40010666]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6787\n",
      "new_state: [ 1.77375473  0.05429142 -0.12516841 -0.24054396  2.00541696  0.43008506\n",
      " -0.50112029  1.30915206 -0.54387471 -0.37704802 -0.83966367  0.67941129\n",
      "  0.52312465]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.36892697189745616\n",
      "state: [[24.          8.88598037 58.23150643 25.69388144 53.          2.8\n",
      "  25.         36.         -3.         23.82019021 68.          6.49822144\n",
      "   6.19359149]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 30 * Reward is ==> -1.0688657871774931\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:55\n",
      "Reset state: [[-0.84188996  0.11151632 -0.94789708  0.14064556  0.46479071  0.2530117\n",
      "   0.19550746  0.12932674 -0.39383037  0.00159369  0.07154781  0.77018225\n",
      "   0.21912911]]\n",
      "time step:  6788\n",
      "new_state: [21.27755026  8.94410762 56.23933835 26.22637526 53.45341578  2.78517417\n",
      " 25.72154193 35.78043281 -2.9116963  24.64712108 69.37585649  6.34626884\n",
      "  5.47183532]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6789\n",
      "new_state: [ 1.74158064  0.05908916 -0.09854679 -0.22654161  2.0049877   0.42997887\n",
      " -0.49382031  1.30906262 -0.54387471 -0.35306079 -0.83839819  0.68315982\n",
      "  0.52466447]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.37211505088507624\n",
      "state: [[24.          8.89311782 58.31451337 25.71712177 53.          2.8\n",
      "  25.         36.         -3.         23.85393516 68.          6.50081187\n",
      "   6.19484275]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 31 * Reward is ==> -1.0720538661651131\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:56\n",
      "Reset state: [[-1.16167639e+00 -1.50029942e-02 -3.20340258e-01  2.37859121e-01\n",
      "   3.44928297e-01  1.87379580e-01 -1.25718016e-01  1.68934375e-01\n",
      "  -3.93857781e-01  1.02608492e-03 -6.40086547e-04 -1.22208601e-01\n",
      "   2.57830360e-01]]\n",
      "time step:  6790\n",
      "new_state: [21.66927638  8.31268223 59.14855039 26.69808166 53.84731393  2.90927515\n",
      " 25.89833992 36.45150311 -3.0678056  23.35889617 68.93097399  5.23321998\n",
      "  5.16104996]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6791\n",
      "new_state: [ 1.70485355  0.0662405  -0.05935073 -0.20782101  2.00428853  0.42978229\n",
      " -0.48361385  1.30891151 -0.54387468 -0.31601709 -0.83705904  0.687935\n",
      "  0.52669429]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.377462241844845\n",
      "state: [[24.          8.90375663 58.43672775 25.74819317 53.          2.8\n",
      "  25.         36.         -3.         23.90604782 68.          6.50411175\n",
      "   6.19649218]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 32 * Reward is ==> -1.0774010571248818\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:57\n",
      "Reset state: [[ 1.88746950e-01  2.85955335e-02 -3.13415376e-01  4.81422189e-01\n",
      "  -5.38066436e-02 -1.78120374e-01  6.91804401e-03  7.35995334e-04\n",
      "  -3.93814213e-01 -2.40714224e-01 -3.61009250e-01 -6.64541515e-01\n",
      "   9.51368929e-01]]\n",
      "time step:  6792\n",
      "new_state: [22.69808767  9.22977515 57.82096719 26.34435218 51.90605585  2.74469273\n",
      " 24.78099373 34.82951542 -2.8546253  23.64880901 67.92248597  5.05168612\n",
      "  6.3578771 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6793\n",
      "new_state: [ 1.67793208  0.07180687 -0.04091145 -0.19419807  2.00366926  0.42961016\n",
      " -0.47526278  1.30877515 -0.54387471 -0.28910447 -0.83608192  0.69180568\n",
      "  0.52837407]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.37741187121357345\n",
      "state: [[24.          8.91203753 58.49422193 25.77080377 53.          2.8\n",
      "  25.         36.         -3.         23.94390818 68.          6.50678658\n",
      "   6.19785717]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 33 * Reward is ==> -1.0773506864936104\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:58\n",
      "Reset state: [[-0.40596784  0.08658693 -0.08485892  0.4469258   0.29061639  0.27064462\n",
      "  -0.00766863 -0.10832454 -0.39384462 -0.34324288 -0.17747134  0.86725641\n",
      "   0.92081186]]\n",
      "time step:  6794\n",
      "new_state: [22.14692617  8.89577647 58.92807525 26.78145888 52.79441422  2.77477696\n",
      " 25.14756524 34.91058855 -2.98286702 24.23350118 68.31590744  6.42962523\n",
      "  5.9530072 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6795\n",
      "new_state: [ 1.66166843  0.07398384 -0.04784281 -0.18965323  2.00344491  0.42957637\n",
      " -0.47178974  1.30872187 -0.54387471 -0.2842957  -0.83547019  0.69368775\n",
      "  0.52927916]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.374348065424825\n",
      "state: [[24.          8.91527613 58.47260976 25.77834704 53.          2.8\n",
      "  25.         36.         -3.         23.95067309 68.          6.50808719\n",
      "   6.19859265]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 34 * Reward is ==> -1.0742868807048618\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:51:59\n",
      "Reset state: [[-0.53240879 -0.07687192 -0.15115715  0.85818677  0.43434822  0.24393814\n",
      "  -0.02160042  0.21652736 -0.39382281 -0.42883244 -0.22917959  0.78486987\n",
      "  -0.19062959]]\n",
      "time step:  6796\n",
      "new_state: [21.70067104  8.765705   58.47028081 27.25834916 53.43622211  2.82991781\n",
      " 24.96413312 36.18798111 -2.8683112  23.76208141 68.42856244  6.46696438\n",
      "  5.24918253]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6797\n",
      "new_state: [ 1.6352175   0.0772697  -0.04418766 -0.18185802  2.00311633  0.42952291\n",
      " -0.46710746  1.30862429 -0.54387471 -0.27700335 -0.83435573  0.69619012\n",
      "  0.53063514]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.373830662708599\n",
      "state: [[24.          8.92016441 58.48400662 25.79128511 53.          2.8\n",
      "  25.         36.         -3.         23.96093189 68.          6.50981645\n",
      "   6.19969451]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 35 * Reward is ==> -1.0737694779886358\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:00\n",
      "Reset state: [[ 0.33180794  0.34232244  0.27674016 -0.1598215   0.47427038 -0.40089427\n",
      "  -0.11326519  0.30247399 -0.39381842  0.22256266  0.10547315  1.24285025\n",
      "   0.08163425]]\n",
      "time step:  6798\n",
      "new_state: [23.16495048  9.58657737 59.75262245 25.47932004 53.59153063  2.61492475\n",
      " 24.71970182 35.99871805 -2.86083968 24.4553376  69.84915056  6.62145142\n",
      "  5.78426231]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6799\n",
      "new_state: [ 1.61053277  0.0813358  -0.05098262 -0.17834723  2.00304031  0.42956286\n",
      " -0.46525043  1.3085665  -0.54387471 -0.28280271 -0.83315803  0.69761297\n",
      "  0.53167297]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.37213366345422927\n",
      "state: [[24.          8.92621341 58.46281974 25.79711211 53.          2.8\n",
      "  25.         36.         -3.         23.95277342 68.          6.51079971\n",
      "   6.20053785]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 36 * Reward is ==> -1.0720724787342661\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:01\n",
      "Reset state: [[ 0.1127274   0.1446072   0.12918071  0.14389842  0.20817934  0.04555926\n",
      "   0.4167947   0.19006594 -0.39382672 -0.27167787 -0.37014581 -0.04284225\n",
      "   1.19152977]]\n",
      "time step:  6800\n",
      "new_state: [23.05221383  8.92929212 59.53648027 26.3116835  52.54496646  2.62929403\n",
      " 26.7361199  36.2212379  -2.90368003 24.58598289 67.2304009   5.70574901\n",
      "  6.09996486]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6801\n",
      "new_state: [ 1.60196985  0.08173258 -0.07046156 -0.18684192  2.00358151  0.42977835\n",
      " -0.4697785   1.30865566 -0.5438747  -0.31375474 -0.83239155  0.69585406\n",
      "  0.53149193]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3722227039240322\n",
      "state: [[24.          8.92680368 58.40208387 25.78301311 53.          2.8\n",
      "  25.         36.         -3.         23.90923045 68.          6.50958421\n",
      "   6.20039074]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 37 * Reward is ==> -1.072161519204069\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:02\n",
      "Reset state: [[-0.878181    0.02930234 -0.5844123   1.06814999  0.22178654 -0.35979101\n",
      "   0.38395226  0.12122959 -0.39386012 -0.02002168 -0.14306313  0.36748923\n",
      "   1.28753983]]\n",
      "time step:  6802\n",
      "new_state: [21.13581643  8.72548483 57.56750603 27.72046079 53.21272809  2.66593801\n",
      " 26.7394253  36.16090501 -3.0790374  23.52260354 68.84554961  5.80153538\n",
      "  6.38941292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6803\n",
      "new_state: [ 1.60730056  0.08463107 -0.10381994 -0.194939    2.00398303  0.42990667\n",
      " -0.47414092  1.30874193 -0.54387471 -0.33737339 -0.83226264  0.69414556\n",
      "  0.53089554]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.36904716731779086\n",
      "state: [[24.          8.93111568 58.29807154 25.76957401 53.          2.8\n",
      "  25.         36.         -3.         23.87600401 68.          6.50840356\n",
      "   6.19990611]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 38 * Reward is ==> -1.0689859825978276\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:03\n",
      "Reset state: [[-0.02550188  0.19442108 -0.37778859  1.06130407  0.15711837 -0.03792494\n",
      "   0.01019149  0.00195206 -0.39382707 -0.58488139 -0.08422193 -0.58961732\n",
      "   0.14371307]]\n",
      "time step:  6804\n",
      "new_state: [23.81991458  9.58358235 57.35957411 26.85692712 52.9821939   2.80783319\n",
      " 24.53708802 35.71127086 -2.91856295 23.92775734 68.87799246  6.06546539\n",
      "  4.97166834]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6805\n",
      "new_state: [ 1.62639427  0.08797897 -0.14398957 -0.20293589  2.00430226  0.42999149\n",
      " -0.47842728  1.3088258  -0.54387471 -0.35618445 -0.83262781  0.69238279\n",
      "  0.52996851]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "reward: -0.3653530888006914\n",
      "state: [[24.          8.93609624 58.17282151 25.75630122 53.          2.8\n",
      "  25.         36.         -3.         23.84954083 68.          6.50718539\n",
      "   6.19915281]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 39 * Reward is ==> -1.0652919040807283\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:03\n",
      "Reset state: [[ 0.74845106 -0.20253825 -1.03876559  0.058116    0.2617218  -0.2781778\n",
      "  -0.09580551  0.18904781 -0.39387379 -0.89547015 -0.31158406  0.23245182\n",
      "   0.16317224]]\n",
      "time step:  6806\n",
      "new_state: [24.10215749  8.92440467 55.46493949 25.76460992 52.90879821  2.69144499\n",
      " 24.47424599 35.35839053 -3.14347857 22.82941124 68.2951788   5.74073452\n",
      "  5.81952554]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6807\n",
      "new_state: [ 1.64494112  0.0923184  -0.18340957 -0.20991527  2.00454387  0.4300477\n",
      " -0.48208834  1.30889426 -0.54387471 -0.37008353 -0.83318914  0.69069634\n",
      "  0.52906666]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.36317114695266683\n",
      "state: [[24.          8.94255187 58.04990887 25.74471724 53.          2.8\n",
      "  25.         36.         -3.         23.82998777 68.          6.50601998\n",
      "   6.19841996]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 40 * Reward is ==> -1.0631099622327036\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:04\n",
      "Reset state: [[ 0.21025312  0.39365424 -0.43530846  0.47410134  0.22024211 -0.36837307\n",
      "  -0.1282178   0.15076465 -0.39384984 -0.60114959 -0.21658439  0.48554698\n",
      "   0.4461335 ]]\n",
      "time step:  6808\n",
      "new_state: [23.35110892  9.3903827  57.81392424 26.74991094 52.39671337  2.52304022\n",
      " 24.67973764 35.83060242 -3.00693347 23.80901218 68.36136702  6.16255375\n",
      "  5.70162334]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6809\n",
      "new_state: [ 1.65286788  0.0962711  -0.20154953 -0.21228216  2.0046116   0.43006331\n",
      " -0.48335918  1.30892011 -0.54387469 -0.37503809 -0.83339722  0.6900558\n",
      "  0.52870299]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "reward: -0.3621314083915881\n",
      "state: [[24.          8.94843217 57.99334798 25.74078881 53.          2.8\n",
      "  25.         36.         -3.         23.82301776 68.          6.50557733\n",
      "   6.19812444]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 41 * Reward is ==> -1.062070223671625\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:05\n",
      "Reset state: [[-0.45303286  0.35877997 -0.70763131  0.13907015 -0.17675716 -0.13461988\n",
      "   0.20620363  0.19014681 -0.39384985  0.09567932  0.02790564  0.16213961\n",
      "   1.22542808]]\n",
      "time step:  6810\n",
      "new_state: [21.91257213  9.41294514 56.91840291 26.14371027 50.85047957  2.64098676\n",
      " 25.69860394 36.01284373 -3.01287902 24.71816469 69.30118214  5.90582376\n",
      "  6.32539114]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6811\n",
      "new_state: [ 1.6546691   0.09948226 -0.19927965 -0.21034927  2.00453198  0.43004534\n",
      " -0.4826359   1.30891122 -0.54387471 -0.37257565 -0.83336125  0.69039129\n",
      "  0.52876802]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3622793094729989\n",
      "state: [[24.          8.95320929 58.00042553 25.74399691 53.          2.8\n",
      "  25.         36.         -3.         23.82648189 68.          6.50580917\n",
      "   6.19817729]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 42 * Reward is ==> -1.0622181247530358\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:06\n",
      "Reset state: [[-2.12220588e-01 -1.87164097e-04 -9.80420075e-01  1.00223619e+00\n",
      "   2.11721101e-01 -1.07489227e-01 -8.24098279e-03  1.05387030e-01\n",
      "  -3.93863323e-01  2.48478496e-01 -1.74636991e-02 -1.53200060e-01\n",
      "  -5.26032680e-01]]\n",
      "time step:  6812\n",
      "new_state: [21.26721053  9.29996588 55.61988722 26.85534442 53.22807337  2.77990661\n",
      " 24.68327587 34.38566128 -3.09464613 23.99522554 69.10407101  5.26847816\n",
      "  5.49883177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6813\n",
      "new_state: [ 1.66070899  0.10066549 -0.18648764 -0.208358    2.00445009  0.43002008\n",
      " -0.48192388  1.30890605 -0.54387471 -0.36866934 -0.83362254  0.69057053\n",
      "  0.52872784]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3630886997948918\n",
      "state: [[24.          8.95496954 58.04031138 25.74730192 53.          2.8\n",
      "  25.         36.         -3.         23.83197723 68.          6.50593303\n",
      "   6.19814464]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 43 * Reward is ==> -1.0630275150749287\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:07\n",
      "Reset state: [[-1.09747553 -0.12336639  0.33430981  0.18453292 -0.12574058 -0.23589453\n",
      "   0.01772485 -0.07267598 -0.39387384 -0.85544748 -0.37370389 -0.37397879\n",
      "  -0.48411962]]\n",
      "time step:  6814\n",
      "new_state: [22.27266621  9.12168444 58.70683901 24.96611677 51.82998541  2.66417258\n",
      " 24.5306151  35.49834572 -3.14574395 24.00641794 68.76419723  6.52025441\n",
      "  4.37623899]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6815\n",
      "new_state: [ 1.67593948  0.09953515 -0.17411328 -0.20841917  2.00441952  0.42999967\n",
      " -0.48171164  1.30891744 -0.54387471 -0.36575075 -0.83429095  0.69025804\n",
      "  0.5283798 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3637081335447302\n",
      "state: [[24.          8.95328798 58.07889495 25.74720038 53.          2.8\n",
      "  25.         36.         -3.         23.83608308 68.          6.50571709\n",
      "   6.19786182]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 44 * Reward is ==> -1.063646948824767\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:08\n",
      "Reset state: [[-1.08679376  0.1265864  -0.24880998  1.06274367  0.49888198 -0.20952507\n",
      "   0.42998817  0.28864289 -0.39384687 -0.91322322  0.05193733  0.56460774\n",
      "  -0.54261161]]\n",
      "time step:  6816\n",
      "new_state: [21.32285332  9.46735332 57.72123672 27.11629254 54.06663587  2.61643722\n",
      " 25.93744483 36.55822095 -3.00256273 23.30435169 69.79953519  6.86065684\n",
      "  4.78668066]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6817\n",
      "new_state: [ 1.69626064  0.09833312 -0.17170098 -0.21036262  2.00445029  0.42999184\n",
      " -0.4823924   1.3089434  -0.54387471 -0.36592695 -0.83505813  0.68952594\n",
      "  0.52782007]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3639323343743236\n",
      "state: [[24.          8.95149976 58.08641658 25.74397475 53.          2.8\n",
      "  25.         36.         -3.         23.83583519 68.          6.50521117\n",
      "   6.19740699]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 45 * Reward is ==> -1.0638711496543605\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:09\n",
      "Reset state: [[-0.71114322  0.07390652 -0.63597223  1.0110483   0.24184838 -0.33588303\n",
      "   0.07446668  0.02870241 -0.39382545 -0.18144042 -0.16969602  0.76168927\n",
      "   0.60789469]]\n",
      "time step:  6818\n",
      "new_state: [21.12656785  9.14400755 57.00200991 27.44181295 52.67158209  2.62519149\n",
      " 25.280443   35.13239569 -2.89827605 23.98989466 68.71002373  6.29634508\n",
      "  6.0420755 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6819\n",
      "new_state: [ 1.70078614  0.09918974 -0.16163059 -0.20937536  2.00436733  0.42996325\n",
      " -0.48141236  1.30893593 -0.5438747  -0.36148664 -0.83537546  0.68958258\n",
      "  0.52776148]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3645051024414556\n",
      "state: [[24.          8.95277413 58.11781632 25.74561336 53.          2.8\n",
      "  25.         36.         -3.         23.84208178 68.          6.50525031\n",
      "   6.19735937]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 46 * Reward is ==> -1.0644439177214924\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:09\n",
      "Reset state: [[-0.78383248  0.44186402 -0.69248402 -0.31670112 -0.06656911  0.08214758\n",
      "   0.29517617 -0.05185442 -0.39385976 -0.06753784 -0.34880122  1.12141073\n",
      "   0.91957563]]\n",
      "time step:  6820\n",
      "new_state: [21.57179104  9.44560756 57.12980226 25.48323983 51.30922178  2.68299336\n",
      " 25.9085284  35.21690735 -3.06977997 24.73628602 67.61910432  6.50780615\n",
      "  5.90663466]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6821\n",
      "new_state: [ 1.69582779  0.10108372 -0.15253054 -0.20775385  2.00426126  0.4299344\n",
      " -0.48010556  1.30891906 -0.54387471 -0.35663112 -0.83545099  0.68980546\n",
      "  0.52790338]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.36503758889639504\n",
      "state: [[24.          8.95559174 58.14619055 25.74830465 53.          2.8\n",
      "  25.         36.         -3.         23.84891246 68.          6.50540433\n",
      "   6.19747468]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 47 * Reward is ==> -1.064976404176432\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:10\n",
      "Reset state: [[-0.66967884  0.23982279 -1.06718599 -0.58167223 -0.07021691 -0.23803182\n",
      "   0.28268851 -0.09871717 -0.39382294 -0.92778638 -0.00818362  1.05749895\n",
      "   1.23060047]]\n",
      "time step:  6822\n",
      "new_state: [21.84120831  9.20468306 55.98904732 25.02106501 51.26977846  2.55725853\n",
      " 25.75409902 35.06077549 -2.89482587 23.5414212  68.86411619  6.42846957\n",
      "  6.13883004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6823\n",
      "new_state: [ 1.68491468  0.10288016 -0.14555248 -0.20557529  2.0041424   0.42991135\n",
      " -0.47817625  1.30889246 -0.5438747  -0.35211723 -0.8352787   0.69035727\n",
      "  0.52825593]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.36540839111878465\n",
      "state: [[24.          8.95826425 58.16794831 25.75192049 53.          2.8\n",
      "  25.         36.         -3.         23.85526255 68.          6.50578566\n",
      "   6.19776117]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 48 * Reward is ==> -1.0653472063988216\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:11\n",
      "Reset state: [[ 0.33832589  0.35463877 -0.46687239  0.11923633  0.42719324 -0.40372712\n",
      "  -0.10205467 -0.07265482 -0.39381703  0.4605408   0.01249686 -0.45039118\n",
      "   0.4108998 ]]\n",
      "time step:  6824\n",
      "new_state: [23.39833677  9.7845156  56.8212515  26.16869912 53.7363775   2.64027065\n",
      " 24.32070007 34.53140671 -2.86942329 24.49180531 69.32707209  5.20386402\n",
      "  5.91204585]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6825\n",
      "new_state: [ 1.6708273   0.10460397 -0.12965144 -0.1998665   2.00387226  0.42985617\n",
      " -0.47404616  1.30882912 -0.54387471 -0.34152499 -0.83480564  0.69191263\n",
      "  0.52903683]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3662866756955586\n",
      "state: [[24.          8.9608287  58.21752821 25.76139563 53.          2.8\n",
      "  25.         36.         -3.         23.8701636  68.          6.50686049\n",
      "   6.19839573]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 49 * Reward is ==> -1.0662254909755955\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:12\n",
      "Reset state: [[-0.12424565 -0.17482234 -0.91769313 -0.61308886  0.13714599 -0.08156168\n",
      "   0.39002522  0.303792   -0.39386827 -0.26792383 -0.36726173  0.90705631\n",
      "   0.07198394]]\n",
      "time step:  6826\n",
      "new_state: [22.71926009  8.82395519 56.08143353 24.80755036 52.11859438  2.71340437\n",
      " 26.09300392 36.20741189 -3.11390539 24.07574053 67.918725    6.33506584\n",
      "  5.49467981]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6827\n",
      "new_state: [ 1.67575604  0.1068201  -0.11360113 -0.19080968  2.00336575  0.42973855\n",
      " -0.46803668  1.30873255 -0.54387471 -0.32524419 -0.83423751  0.69471971\n",
      "  0.52998375]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3663936419649847\n",
      "state: [[24.          8.96412557 58.26757352 25.77642763 53.          2.8\n",
      "  25.         36.         -3.         23.89306723 68.          6.50880032\n",
      "   6.19916519]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 50 * Reward is ==> -1.0663324572450215\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:12\n",
      "Reset state: [[ 0.66035034 -0.10741275 -0.19736092  0.51603965  0.25091983 -0.2016162\n",
      "   0.4393037  -0.00520275 -0.39381855 -0.74290542 -0.31529926 -0.64100927\n",
      "   1.42284801]]\n",
      "time step:  6828\n",
      "new_state: [24.5715531   8.83043416 58.22257438 26.77717068 52.75086066  2.59179791\n",
      " 26.25274135 35.42743445 -2.86705562 23.76943931 67.66492719  5.59708313\n",
      "  6.21946635]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6829\n",
      "new_state: [ 1.69954683  0.10697908 -0.11326167 -0.18567965  2.00300313  0.4296507\n",
      " -0.46374066  1.30867656 -0.54387471 -0.31619143 -0.83405743  0.6967828\n",
      "  0.53033197]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.3648891677535617\n",
      "state: [[24.          8.96436207 58.26863196 25.78494218 53.          2.8\n",
      "  25.         36.         -3.         23.90580256 68.          6.51022602\n",
      "   6.19944816]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 51 * Reward is ==> -1.0648279830335987\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:13\n",
      "Reset state: [[-1.09641164  0.25649495 -0.91072548  0.26715128  0.35777983  0.26209466\n",
      "  -0.09252635 -0.07058105 -0.39387123 -0.77706486 -0.06333801 -0.73059842\n",
      "   1.08728554]]\n",
      "time step:  6830\n",
      "new_state: [21.4358251   8.81195936 56.95029878 26.74685238 53.89394666  2.94191793\n",
      " 25.57795476 35.51391699 -3.13310477 22.28163412 68.77473528  4.81114541\n",
      "  6.12032297]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6831\n",
      "new_state: [ 1.72118451  0.10780483 -0.1119441  -0.17927956  2.00252205  0.4295216\n",
      " -0.45793953  1.30859735 -0.54387471 -0.30328503 -0.83389165  0.69923775\n",
      "  0.53079568]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3625923054392499\n",
      "state: [[24.          8.96559052 58.27274019 25.79556469 53.          2.8\n",
      "  25.         36.         -3.         23.92395913 68.          6.51192251\n",
      "   6.19982497]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 52 * Reward is ==> -1.062531120719287\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:14\n",
      "Reset state: [[-0.85608729  0.44558754 -0.19381152 -0.62684811  0.16452831 -0.33182781\n",
      "   0.41845151 -0.0811823  -0.39385979 -0.42001727  0.14341342 -0.69990181\n",
      "   0.56119532]]\n",
      "time step:  6832\n",
      "new_state: [22.37566691  9.96443351 56.9167835  24.58052767 52.27054773  2.62254718\n",
      " 25.85505383 34.80924822 -3.0761499  24.08840047 70.01335445  6.19582383\n",
      "  5.45423757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6833\n",
      "new_state: [ 1.73466685  0.10443128 -0.09242998 -0.17509589  2.00229679  0.42948884\n",
      " -0.45312115  1.30854635 -0.54387471 -0.29997887 -0.83342724  0.7008508\n",
      "  0.53127825]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3644116239618782\n",
      "state: [[24.          8.9605718  58.33358575 25.80250851 53.          2.8\n",
      "  25.         36.         -3.         23.9286102  68.          6.51303721\n",
      "   6.2002171 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 53 * Reward is ==> -1.064350439241915\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:15\n",
      "Reset state: [[ 0.35524128  0.0040476  -0.37523009  1.14768817  0.36138235 -0.16155321\n",
      "   0.06462113  0.26164284 -0.39384655 -0.56639649 -0.09786106  0.22609947\n",
      "   0.44818651]]\n",
      "time step:  6834\n",
      "new_state: [23.62535147  8.81398212 57.8355817  27.82878508 52.97782207  2.59562976\n",
      " 25.33332122 36.2943958  -2.9852623  23.85363396 68.54613434  6.11197631\n",
      "  5.6238748 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6835\n",
      "new_state: [ 1.73249538  0.10034944 -0.06232268 -0.17083489  2.0021733   0.42951151\n",
      " -0.44806187  1.30849038 -0.54387469 -0.30141641 -0.83249135  0.702394\n",
      "  0.53212155]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3701872254756907\n",
      "state: [[24.          8.95449938 58.42746112 25.80958069 53.          2.8\n",
      "  25.         36.         -3.         23.92658788 68.          6.51410364\n",
      "   6.20090237]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 54 * Reward is ==> -1.0701260407557276\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:16\n",
      "Reset state: [[ 0.735751    0.00845098 -1.0107303   0.70973772 -0.20095572  0.26176241\n",
      "   0.43092975  0.260952   -0.39382555  0.30071446  0.02513052  0.17247675\n",
      "   1.05944329]]\n",
      "time step:  6836\n",
      "new_state: [24.26909958  8.94127873 55.92970601 27.05475811 50.78765395  2.83650573\n",
      " 26.43226459 35.97410788 -2.89179031 24.97871146 69.25264517  5.89525734\n",
      "  6.21217304]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6837\n",
      "new_state: [ 1.76152037  0.09430952 -0.06286302 -0.17495643  2.002501    0.4296238\n",
      " -0.44895338  1.30855831 -0.54387471 -0.31722437 -0.83244728  0.70181837\n",
      "  0.53160944]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3725405940338302\n",
      "state: [[24.          8.94551398 58.42577633 25.80273998 53.          2.8\n",
      "  25.         36.         -3.         23.90434943 68.          6.51370585\n",
      "   6.20048623]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 55 * Reward is ==> -1.0724794093138672\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:16\n",
      "Reset state: [[ 0.63395685  0.22509549 -0.54673128  1.06626617  0.33477269  0.04431391\n",
      "   0.02484866  0.11505851 -0.39382783  0.25879453 -0.11451325  0.1849304\n",
      "   0.48744124]]\n",
      "time step:  6838\n",
      "new_state: [24.04948412  9.15218304 57.38695945 27.67653027 52.83933988  2.71747161\n",
      " 25.20758565 35.55132413 -2.89522609 24.88997202 68.73362087  5.97195708\n",
      "  5.79796363]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6839\n",
      "new_state: [ 1.80575347  0.08645002 -0.06677446 -0.18023931  2.00287182  0.42972678\n",
      " -0.45176366  1.3086494  -0.5438747  -0.33361365 -0.83276977  0.70071884\n",
      "  0.53064937]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.37440471762057714\n",
      "state: [[24.          8.93382166 58.41358037 25.79397175 53.          2.8\n",
      "  25.         36.         -3.         23.88129318 68.          6.51294602\n",
      "   6.19970607]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 56 * Reward is ==> -1.0743435329006141\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:17\n",
      "Reset state: [[ 0.17930059  0.16753129 -0.02079212 -0.39824303  0.1975906  -0.11157164\n",
      "  -0.06809463  0.05888192 -0.3938239  -0.17978059 -0.11203422  0.83396389\n",
      "   0.76334404]]\n",
      "time step:  6840\n",
      "new_state: [23.20498773  8.9591962  59.04846497 25.38973746 52.28278469  2.59979535\n",
      " 25.11926718 35.54258477 -2.87349409 24.51149814 68.36912208  6.40953447\n",
      "  5.88463549]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6841\n",
      "new_state: [ 1.86549556  0.07822603 -0.07987255 -0.18738945  2.00328876  0.42982066\n",
      " -0.45639039  1.30876307 -0.54387471 -0.35098322 -0.83357276  0.69893406\n",
      "  0.52923549]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3736557226431044\n",
      "state: [[24.          8.9215871  58.37274014 25.78210434 53.          2.8\n",
      "  25.         36.         -3.         23.85685787 68.          6.51171265\n",
      "   6.19855716]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 57 * Reward is ==> -1.0735945379231413\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:18\n",
      "Reset state: [[ 0.66629363 -0.16299049 -0.78583844 -0.43450834 -0.23673362 -0.20508284\n",
      "   0.36376494 -0.18349706 -0.39382933 -0.00706816  0.10874761 -0.72319332\n",
      "  -0.22446512]]\n",
      "time step:  6842\n",
      "new_state: [24.35949838  8.86641476 55.80716986 25.6548548  50.82537954  2.70508349\n",
      " 25.87565609 34.451041   -2.92831159 24.01272402 69.6156357   5.10374745\n",
      "  5.27143004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6843\n",
      "new_state: [ 1.95532871  0.06801317 -0.1225087  -0.20251141  2.00400662  0.42995764\n",
      " -0.46624436  1.30894814 -0.54387471 -0.37825574 -0.8354734   0.6948314\n",
      "  0.52669702]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.368054900693657\n",
      "state: [[24.          8.90639377 58.23979947 25.75700575 53.          2.8\n",
      "  25.         36.         -3.         23.81849121 68.          6.5088775\n",
      "   6.1964944 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 58 * Reward is ==> -1.0679937159736939\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:19\n",
      "Reset state: [[-0.8844878  -0.09539343 -0.54088095  0.79363246  0.26247272 -0.32217701\n",
      "   0.0876011   0.09011002 -0.39381426 -0.1155721   0.06789386 -0.09840162\n",
      "   1.39164677]]\n",
      "time step:  6844\n",
      "new_state: [21.32761806  8.45356683 57.83243955 27.45708472 53.50878401  2.68627216\n",
      " 26.28210538 36.12839827 -2.85653077 23.20876693 69.1164385   5.26296624\n",
      "  6.54493996]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6845\n",
      "new_state: [ 2.03423228  0.06048867 -0.16079069 -0.2129322   2.00441455  0.43002639\n",
      " -0.47349218  1.3090609  -0.54387471 -0.39626731 -0.83698007  0.69207923\n",
      "  0.52485699]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.36423136954923696\n",
      "state: [[24.          8.89519982 58.12043515 25.7397099  53.          2.8\n",
      "  25.         36.         -3.         23.79315274 68.          6.50697562\n",
      "   6.1949992 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 59 * Reward is ==> -1.064170184829274\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:20\n",
      "Reset state: [[-0.05039033 -0.1450016   0.13117812 -0.35322984  0.37465595 -0.13479195\n",
      "   0.24227208 -0.19244633 -0.39385916 -0.32854885 -0.0042968   0.6637834\n",
      "  -0.92698251]]\n",
      "time step:  6846\n",
      "new_state: [22.72537788  8.60620145 59.34301543 25.47265024 53.0655771   2.60463\n",
      " 25.82961969 34.43877702 -3.0566599  24.11886366 68.96988787  6.25108721\n",
      "  4.55217549]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6847\n",
      "new_state: [ 2.09524907  0.05479871 -0.1969468  -0.22095451  2.00470375  0.43007388\n",
      " -0.47894098  1.30913214 -0.54387471 -0.40970758 -0.83810362  0.68995153\n",
      "  0.52355249]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3625415033483751\n",
      "state: [[24.          8.88673505 58.00769943 25.72639493 53.          2.8\n",
      "  25.         36.         -3.         23.77424511 68.          6.50550527\n",
      "   6.19393916]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 60 * Reward is ==> -1.062480318628412\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:20\n",
      "Reset state: [[-1.09479327 -0.06443226 -0.21863774  1.02077562  0.18203125 -0.32265702\n",
      "   0.45731777 -0.03896447 -0.39384011  0.38243652  0.0204493   0.26353695\n",
      "   0.31998277]]\n",
      "time step:  6848\n",
      "new_state: [20.32743541  8.83818894 58.60191833 27.52929992 53.10770858  2.68405719\n",
      " 26.92708912 35.47070367 -2.98200542 24.03050215 69.3783351   5.6271388\n",
      "  5.79947582]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6849\n",
      "new_state: [ 2.14240087  0.04946897 -0.23428559 -0.22866867  2.004974    0.43012086\n",
      " -0.48409856  1.3091863  -0.54387471 -0.42300426 -0.83892771  0.68789361\n",
      "  0.52251494]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "reward: -0.3629861821913287\n",
      "state: [[24.          8.87880617 57.89127603 25.7135914  53.          2.8\n",
      "  25.         36.         -3.         23.7555395  68.          6.50408315\n",
      "   6.19309604]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 61 * Reward is ==> -1.0629249974713657\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:21\n",
      "Reset state: [[-0.43395715  0.30447535 -0.78265051  0.3145454   0.33578     0.00106725\n",
      "   0.43279769  0.20319006 -0.39384536  0.22655557 -0.12605698 -0.6031187\n",
      "  -0.04167542]]\n",
      "time step:  6850\n",
      "new_state: [21.4907651   9.62158139 56.40559689 26.132496   53.30964276  2.81157892\n",
      " 26.38303458 35.35716636 -3.00252671 24.34207835 68.99348296  5.24426741\n",
      "  5.71550445]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6851\n",
      "new_state: [ 2.17201828  0.04683671 -0.26876999 -0.23331078  2.00512016  0.43014548\n",
      " -0.48727847  1.30921623 -0.54387469 -0.43189329 -0.83937602  0.68673906\n",
      "  0.52191577]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.36187689338602014\n",
      "state: [[24.          8.87489025 57.78375274 25.70588667 53.          2.8\n",
      "  25.         36.         -3.         23.74303451 68.          6.50328529\n",
      "   6.19260916]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 62 * Reward is ==> -1.0618157086660571\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:22\n",
      "Reset state: [[ 0.0095078   0.32242397 -0.50169109  0.49165336  0.03553029  0.2350286\n",
      "   0.36213035 -0.13276456 -0.39385846 -0.73564317  0.1137313   0.18814591\n",
      "   1.0170741 ]]\n",
      "time step:  6852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_state: [23.07744647  9.2096278  57.57866486 26.87450707 51.76867548  2.80462289\n",
      " 26.38625205 34.82297635 -3.05438394 23.48446068 69.51465296  5.98168362\n",
      "  6.07950143]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6853\n",
      "new_state: [ 2.19030467  0.04572614 -0.30946989 -0.23846111  2.00527249  0.4301733\n",
      " -0.49021867  1.30924098 -0.54387471 -0.44068886 -0.83975691  0.68553504\n",
      "  0.52143295]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.369209294058108\n",
      "state: [[24.          8.87323809 57.65684933 25.69733843 53.          2.8\n",
      "  25.         36.         -3.         23.730661   68.          6.50245326\n",
      "   6.19221682]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 63 * Reward is ==> -1.069148109338145\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:23\n",
      "Reset state: [[ 0.08133947  0.23488838 -1.02106102 -0.39094683  0.43212638 -0.06638032\n",
      "  -0.132365    0.30012005 -0.39383791 -0.46037845 -0.14142401 -0.48420074\n",
      "  -0.36070626]]\n",
      "time step:  6854\n",
      "new_state: [22.77883565  9.51468616 55.56545204 25.16783824 53.46568803  2.76868359\n",
      " 24.43218214 35.95704583 -2.96667201 23.45154559 68.90171088  5.37036214\n",
      "  5.30854458]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6855\n",
      "new_state: [ 2.1992115   0.04644554 -0.34510222 -0.24222624  2.00535916  0.43018899\n",
      " -0.49187687  1.30925564 -0.54387471 -0.44627727 -0.83998156  0.68474542\n",
      "  0.52115442]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.3769850135774184\n",
      "state: [[24.          8.87430831 57.54574675 25.69108929 53.          2.8\n",
      "  25.         36.         -3.         23.7227993  68.          6.50190759\n",
      "   6.19199048]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 64 * Reward is ==> -1.0769238288574554\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:24\n",
      "Reset state: [[-0.92886236  0.1425585   0.26818539 -0.33484669  0.24019522  0.27268728\n",
      "   0.46272264 -0.11004045 -0.39382734 -0.16951177 -0.35954944  1.19433466\n",
      "  -0.90413487]]\n",
      "time step:  6856\n",
      "new_state: [21.23102605  9.40924563 59.44955224 25.03462479 52.67414669  2.79831157\n",
      " 26.20211269 34.95783187 -2.90172696 24.44938856 67.8774332   7.10561364\n",
      "  4.71478392]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6857\n",
      "new_state: [ 2.20155766  0.04841921 -0.37721295 -0.24550852  2.00541948  0.43019893\n",
      " -0.49302818  1.30926588 -0.54387471 -0.45011711 -0.84019932  0.68407131\n",
      "  0.52096312]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3783886243856711\n",
      "state: [[24.          8.87724447 57.4456246  25.68564154 53.          2.8\n",
      "  25.         36.         -3.         23.71739746 68.          6.50144175\n",
      "   6.19183504]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 65 * Reward is ==> -1.078327439665708\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:25\n",
      "Reset state: [[ 0.31532871  0.36885497 -0.02240741 -0.41523132  0.02945406  0.03428308\n",
      "  -0.06344984  0.20687323 -0.39385798  0.45730301 -0.35807905  0.78242325\n",
      "   1.47654584]]\n",
      "time step:  6858\n",
      "new_state: [23.5249414   9.2374006  59.04452129 25.40864841 51.68062478  2.64479232\n",
      " 25.10834529 36.21363793 -3.04822429 25.51763787 67.35774621  6.31635117\n",
      "  6.39362536]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6859\n",
      "new_state: [ 2.2058888   0.04965135 -0.41740201 -0.25162527  2.00555837  0.43022283\n",
      " -0.49567076  1.30928423 -0.54387471 -0.45682007 -0.84064081  0.68257665\n",
      "  0.52059651]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3807591314052916\n",
      "state: [[24.          8.87907749 57.32031401 25.6754893  53.          2.8\n",
      "  25.         36.         -3.         23.70796781 68.          6.50040886\n",
      "   6.19153713]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 66 * Reward is ==> -1.0806979466853286\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:26\n",
      "Reset state: [[-1.20233172  0.19353124 -0.60760405 -0.23425636  0.12738786 -0.06367102\n",
      "   0.3030974   0.12210648 -0.39382752 -0.89342828 -0.38779253  0.14500693\n",
      "  -0.26649687]]\n",
      "time step:  6860\n",
      "new_state: [20.48694601  9.08021776 57.22884637 25.52405566 51.89931999  2.63412997\n",
      " 26.17153899 35.68326446 -2.8920666  23.41235058 67.62717211  5.97931919\n",
      "  5.13351888]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6861\n",
      "new_state: [ 2.21380843  0.05040437 -0.46230391 -0.2590097   2.00571795  0.43024885\n",
      " -0.49895525  1.30930398 -0.54387471 -0.46437211 -0.84128849  0.68073569\n",
      "  0.52012293]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.38307143961934254\n",
      "state: [[24.          8.88019773 57.18030865 25.66323304 53.          2.8\n",
      "  25.         36.         -3.         23.69734369 68.          6.49913667\n",
      "   6.1911523 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 67 * Reward is ==> -1.0830102548993794\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:26\n",
      "Reset state: [[-0.52133747 -0.12746159 -0.97340554  0.28305689  0.36678142 -0.30082516\n",
      "   0.18632497  0.24684434 -0.39384719 -0.50465909 -0.32297329  0.25502402\n",
      "   1.21652656]]\n",
      "time step:  6862\n",
      "new_state: [21.91010093  8.73743402 56.13372403 26.29968224 52.83728992  2.54819659\n",
      " 25.64903183 36.12166473 -3.00486798 23.99986297 67.92482273  5.96892992\n",
      "  6.3067406 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6863\n",
      "new_state: [ 2.22693885  0.05042467 -0.49710917 -0.26518736  2.005831    0.43026496\n",
      " -0.50165579  1.30931933 -0.54387471 -0.46969241 -0.84198502  0.67922013\n",
      "  0.51969408]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "reward: -0.3846152369294935\n",
      "state: [[24.          8.88022794 57.0717849  25.6529797  53.          2.8\n",
      "  25.         36.         -3.         23.68985915 68.          6.49808934\n",
      "   6.19080382]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 68 * Reward is ==> -1.0845540522095303\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:27\n",
      "Reset state: [[-1.13147428  0.01436172 -0.19099909  0.46528079 -0.22793096 -0.05756878\n",
      "   0.03824028 -0.0342289  -0.3938296   0.1594886  -0.23754513  0.46120648\n",
      "   0.04232675]]\n",
      "time step:  6864\n",
      "new_state: [20.12951355  8.89874778 58.78476108 26.57778139 51.42818377  2.80086893\n",
      " 25.66175936 35.55199041 -2.93097439 23.68056879 68.42972504  5.76477148\n",
      "  5.64217686]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6865\n",
      "new_state: [ 2.24151553  0.05018092 -0.52119105 -0.26965509  2.00590168  0.43027315\n",
      " -0.5035996   1.30932948 -0.54387471 -0.47287596 -0.84260246  0.67812177\n",
      "  0.51934284]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.38565227922073897\n",
      "state: [[24.          8.87986532 56.99669694 25.64556441 53.          2.8\n",
      "  25.         36.         -3.         23.68538058 68.          6.49733032\n",
      "   6.1905184 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 69 * Reward is ==> -1.0855910945007758\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:28\n",
      "Reset state: [[ 0.43147245  0.06765409 -0.84174734  1.11177577  0.30903704 -0.18415422\n",
      "   0.20647412  0.24560007 -0.39384794  0.07454783  0.05101137  0.27053969\n",
      "  -0.89694102]]\n",
      "time step:  6866\n",
      "new_state: [22.83905715  9.39538517 56.07375482 27.04937623 53.52958405  2.74407022\n",
      " 25.44407554 35.15581702 -3.01990012 23.83256374 69.49977471  5.65019292\n",
      "  5.32422393]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6867\n",
      "new_state: [ 2.25341584  0.04969465 -0.53510946 -0.27232884  2.00593816  0.43027704\n",
      " -0.50471212  1.30933497 -0.54387471 -0.47470491 -0.84300804  0.67754243\n",
      "  0.51912554]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.3862830726406986\n",
      "state: [[24.          8.87914192 56.95329896 25.64112667 53.          2.8\n",
      "  25.         36.         -3.         23.68280762 68.          6.49692997\n",
      "   6.19034182]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 70 * Reward is ==> -1.0862218879207355\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:29\n",
      "Reset state: [[-1.17604332e+00  3.60770842e-04 -3.08143194e-01  6.10404602e-01\n",
      "  -1.65434311e-01 -4.39865639e-02  4.54756597e-01  6.85067633e-02\n",
      "  -3.93854164e-01 -9.39647891e-01 -6.42436011e-02 -4.39076072e-02\n",
      "  -4.99504613e-01]]\n",
      "time step:  6868\n",
      "new_state: [20.71307107  8.9172988  58.19550611 26.62592009 51.67396296  2.79362931\n",
      " 26.39015883 35.91869989 -3.04957487 22.75451149 69.30321143  5.6301706\n",
      "  4.70586501]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6869\n",
      "new_state: [ 2.26057413  0.04946869 -0.53691328 -0.27297004  2.00593459  0.43027558\n",
      " -0.50475174  1.30933564 -0.54387471 -0.47457642 -0.84318956  0.67753658\n",
      "  0.51906594]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.38633958826269366\n",
      "state: [[24.          8.87880576 56.94767458 25.64006244 53.          2.8\n",
      "  25.         36.         -3.         23.68298838 68.          6.49692592\n",
      "   6.19029339]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 71 * Reward is ==> -1.0862784035427304\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:30\n",
      "Reset state: [[-0.3654427   0.02844878 -0.78713308  0.76557124 -0.22650607 -0.20511561\n",
      "   0.11913083  0.10298269 -0.39383702 -0.27261054 -0.17864851  1.13321749\n",
      "  -0.84785111]]\n",
      "time step:  6870\n",
      "new_state: [21.30513323  9.3340336  56.17409063 26.62398172 51.20563574  2.73284564\n",
      " 25.33618705 34.46909083 -2.96643184 23.38631128 68.57715468  6.31585529\n",
      "  5.38426774]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6871\n",
      "new_state: [ 2.26965799  0.04649592 -0.52637341 -0.27241716  2.00592138  0.43027429\n",
      " -0.50437828  1.30933446 -0.54387471 -0.47394808 -0.84323221  0.67778719\n",
      "  0.51907574]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.38587133185919276\n",
      "state: [[24.          8.87438327 56.98053819 25.64098008 53.          2.8\n",
      "  25.         36.         -3.         23.68387232 68.          6.49709911\n",
      "   6.19030136]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 72 * Reward is ==> -1.0858101471392296\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:31\n",
      "Reset state: [[-0.28275852  0.41272829 -0.17673255 -0.3425416  -0.00834801 -0.21583641\n",
      "   0.10957281 -0.16841312 -0.3938444   0.08590263 -0.37123146 -0.21015542\n",
      "  -0.24106765]]\n",
      "time step:  6872\n",
      "new_state: [22.10039076  9.64865402 58.13762219 25.39913623 51.59847762  2.67623598\n",
      " 25.27100398 34.45942955 -2.99318762 24.27402387 68.00881713  5.63985187\n",
      "  5.3166074 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6873\n",
      "new_state: [ 2.28068268  0.04132505 -0.51194719 -0.27181361  2.00592253  0.43027785\n",
      " -0.50420544  1.30933394 -0.54387471 -0.47443449 -0.84316017  0.67801502\n",
      "  0.51909566]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3853741479694597\n",
      "state: [[24.          8.86669073 57.02551955 25.64198182 53.          2.8\n",
      "  25.         36.         -3.         23.68318805 68.          6.49725655\n",
      "   6.19031754]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 73 * Reward is ==> -1.0853129632494967\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:32\n",
      "Reset state: [[-0.90523707  0.43464125 -1.1215144   0.4626587   0.06323927 -0.37178757\n",
      "  -0.11961701 -0.19494906 -0.39386721 -0.15485969  0.1199542   0.2214766\n",
      "   1.06920994]]\n",
      "time step:  6874\n",
      "new_state: [20.61990286  9.87000998 55.20869385 26.25067441 52.27588866  2.65579732\n",
      " 24.40042204 33.99618642 -3.11277427 23.59596673 69.85154706  5.68606685\n",
      "  6.59287737]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6875\n",
      "new_state: [ 2.29305936  0.03476338 -0.50009952 -0.27192613  2.0059496   0.43028731\n",
      " -0.50449076  1.30933496 -0.54387471 -0.47659618 -0.84303328  0.67808226\n",
      "  0.51909422]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.38511229627626264\n",
      "state: [[24.          8.85692915 57.0624609  25.64179506 53.          2.8\n",
      "  25.         36.         -3.         23.68014701 68.          6.49730302\n",
      "   6.19031637]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 74 * Reward is ==> -1.0850511115562995\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:32\n",
      "Reset state: [[ 0.27004334  0.09264668  0.02000681  0.84398444  0.18915746  0.26835613\n",
      "   0.42740075  0.29828803 -0.39386454 -0.51743947  0.09897878 -0.67926194\n",
      "   0.53333951]]\n",
      "time step:  6876\n",
      "new_state: [24.25416085  9.39777876 58.70706728 26.59025929 53.11140159  2.93980837\n",
      " 25.9353775  36.86240968 -3.10047051 23.93348931 69.29468463  5.75830081\n",
      "  5.32364016]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6877\n",
      "new_state: [ 2.30313828  0.02954303 -0.48801853 -0.27163886  2.00596846  0.43029468\n",
      " -0.50461581  1.30933555 -0.54387471 -0.47807748 -0.84285293  0.67818118\n",
      "  0.51911317]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3848587097820142\n",
      "state: [[24.          8.84916301 57.10012975 25.64227186 53.          2.8\n",
      "  25.         36.         -3.         23.67806313 68.          6.49737138\n",
      "   6.19033177]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 75 * Reward is ==> -1.0847975250620512\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:33\n",
      "Reset state: [[-0.00858102  0.31227082  0.18625774 -0.17334884  0.37319931  0.18991375\n",
      "  -0.14325379 -0.19188612 -0.39381394 -0.51859262  0.1049812   0.56659611\n",
      "  -0.83862088]]\n",
      "time step:  6878\n",
      "new_state: [23.19984801  9.65884418 59.34519462 25.22979061 53.46458054  2.72248437\n",
      " 24.19560986 34.76281057 -2.84220661 24.1708459  69.21723689  6.66716202\n",
      "  4.44932955]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6879\n",
      "new_state: [ 2.30783222  0.02630997 -0.47323111 -0.27032814  2.00596381  0.43029778\n",
      " -0.50443752  1.30933409 -0.54387471 -0.47835893 -0.84252833  0.67844533\n",
      "  0.51919388]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.38453800255993975\n",
      "state: [[24.          8.84435329 57.14623735 25.64444731 53.          2.8\n",
      "  25.         36.         -3.         23.6776672  68.          6.49755392\n",
      "   6.19039735]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 76 * Reward is ==> -1.0844768178399766\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:34\n",
      "Reset state: [[-8.51766130e-01  1.71637982e-01  2.97842161e-01  1.80797009e-04\n",
      "   1.49601800e-02  2.96229546e-03  3.02060122e-01  1.79674443e-01\n",
      "  -3.93874388e-01 -4.44019517e-01 -1.85251960e-01  1.02913595e-01\n",
      "   1.03225238e-01]]\n",
      "time step:  6880\n",
      "new_state: [21.92681906  9.54677029 59.30910764 25.31291435 52.15572757  2.69741418\n",
      " 25.49963815 36.18474129 -3.13546976 24.12961793 68.64794006  6.67094355\n",
      "  5.13362177]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6881\n",
      "new_state: [ 2.3095677   0.02402443 -0.45790565 -0.26868507  2.00594925  0.43029832\n",
      " -0.50424286  1.30933246 -0.5438747  -0.47792595 -0.84223919  0.67874536\n",
      "  0.51927292]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.3842188780168967\n",
      "state: [[24.          8.84095316 57.19402256 25.64717439 53.          2.8\n",
      "  25.         36.         -3.         23.67827631 68.          6.49776125\n",
      "   6.19046158]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 77 * Reward is ==> -1.0841576932969335\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:35\n",
      "Reset state: [[-0.6380619   0.01703148 -0.7118059   0.8976967   0.21126952  0.03872134\n",
      "  -0.04785224  0.13738579 -0.39382631 -0.32777866 -0.04336421 -0.46751898\n",
      "  -0.60226442]]\n",
      "time step:  6882\n",
      "new_state: [22.04187051  9.29847658 56.46378647 26.79066913 53.0758679   2.82178258\n",
      " 24.39429761 36.04163822 -2.91456203 23.74204474 69.57114402  5.78307302\n",
      "  4.75474135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6883\n",
      "new_state: [ 2.30496239  0.02361332 -0.44066771 -0.26581272  2.00589131  0.43029003\n",
      " -0.50325534  1.30932786 -0.54387471 -0.4748414  -0.8420637   0.6794231\n",
      "  0.51942814]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.38368830618869565\n",
      "state: [[24.          8.84034158 57.24777091 25.65194176 53.          2.8\n",
      "  25.         36.         -3.         23.68261562 68.          6.4982296\n",
      "   6.19058771]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 78 * Reward is ==> -1.0836271214687325\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:36\n",
      "Reset state: [[-0.19530419  0.36471746 -0.78581581 -0.23695826  0.3797441  -0.20149411\n",
      "   0.22755678  0.21357665 -0.39385924 -0.08836106 -0.14226799  0.30742122\n",
      "  -0.32716611]]\n",
      "time step:  6884\n",
      "new_state: [22.47162153  9.54427107 56.59859675 25.35837626 52.96503474  2.61585008\n",
      " 25.78997729 35.84329723 -3.05757544 24.39752434 68.78885671  6.04413805\n",
      "  5.1638834 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6885\n",
      "new_state: [ 2.29476167  0.02487859 -0.41977311 -0.26097963  2.00576832  0.43026856\n",
      " -0.50111132  1.30931875 -0.54387471 -0.4681765  -0.84197189  0.68061692\n",
      "  0.51968681]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.38270491133096274\n",
      "state: [[24.          8.84222388 57.31292086 25.65996346 53.          2.8\n",
      "  25.         36.         -3.         23.69199172 68.          6.49905459\n",
      "   6.19079791]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 79 * Reward is ==> -1.0826437266109996\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:37\n",
      "Reset state: [[-1.06291241 -0.06992514 -0.11505584  0.3219122  -0.16561158  0.09205389\n",
      "   0.12862733 -0.05355767 -0.39387366  0.37004085 -0.09058638  1.18628165\n",
      "   0.17920704]]\n",
      "time step:  6886\n",
      "new_state: [20.28350489  8.87795077 58.72253545 26.31332845 51.37630384  2.85672126\n",
      " 25.51968934 35.19712139 -3.14449672 24.1461089  69.00486054  6.4129527\n",
      "  5.87036307]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6887\n",
      "new_state: [ 2.28626131  0.02634514 -0.39979675 -0.25601182  2.00563047  0.43024123\n",
      " -0.49881281  1.30930865 -0.54387471 -0.46060884 -0.84194704  0.68177066\n",
      "  0.51992078]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.3814283676452279\n",
      "state: [[24.          8.84440562 57.37520769 25.66820875 53.          2.8\n",
      "  25.         36.         -3.         23.70263781 68.          6.49985189\n",
      "   6.19098803]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 80 * Reward is ==> -1.081367182925265\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:37\n",
      "Reset state: [[ 0.2357523   0.29447512 -0.92080486 -0.58992467  0.38246968 -0.10634187\n",
      "   0.06198515 -0.03302531 -0.39382821  0.27457015  0.13089352  1.0510722\n",
      "   1.5144145 ]]\n",
      "time step:  6888\n",
      "new_state: [23.53680758  9.3255673  56.30136158 24.90238203 52.97132929  2.61160259\n",
      " 25.23056718 35.08158622 -2.91280621 25.13201935 69.49317598  6.52118455\n",
      "  6.47752261]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6889\n",
      "new_state: [ 2.27630653  0.028045   -0.37594915 -0.25030101  2.0054654   0.43020796\n",
      " -0.4961507   1.30929578 -0.54387471 -0.45211335 -0.84181437  0.68308697\n",
      "  0.52020414]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "reward: -0.379570754558997\n",
      "state: [[24.          8.84693443 57.44956518 25.67768723 53.          2.8\n",
      "  25.         36.         -3.         23.71458917 68.          6.50076152\n",
      "   6.19121829]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 81 * Reward is ==> -1.079509569839034\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:38\n",
      "Reset state: [[-0.81219199  0.43843401 -0.03716587  0.42044661  0.40148201  0.26472907\n",
      "   0.22975547 -0.16404003 -0.39387374 -0.54051061 -0.11433299  0.98679932\n",
      "   0.28898265]]\n",
      "time step:  6890\n",
      "new_state: [21.51668894  9.34448326 59.13319509 26.75790264 53.40647949  2.85854474\n",
      " 26.15226844 34.81862264 -3.13762845 23.54801581 68.66047837  6.48593963\n",
      "  5.45892439]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6891\n",
      "new_state: [ 2.26222504  0.03029661 -0.3460133  -0.24289985  2.00523196  0.43016349\n",
      " -0.49257533  1.30927585 -0.54387471 -0.44175633 -0.84145682  0.6850104\n",
      "  0.52065273]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.3769138712974951\n",
      "state: [[24.          8.85028409 57.54290599 25.68997126 53.          2.8\n",
      "  25.         36.         -3.         23.72915931 68.          6.5020907\n",
      "   6.19158281]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 82 * Reward is ==> -1.0768526865775319\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:39\n",
      "Reset state: [[ 6.68966471e-01  3.09133337e-02  3.04664189e-01 -3.53853317e-01\n",
      "  -8.11393843e-03 -7.58709218e-02 -8.34668000e-02 -1.58130211e-01\n",
      "  -3.93873516e-01  4.01570990e-01 -1.55710522e-04 -6.68444704e-01\n",
      "   6.24266507e-01]]\n",
      "time step:  6892\n",
      "new_state: [24.12401888  9.25824413 59.2164026  25.41112677 52.01412101  2.77509842\n",
      " 24.35664185 34.61104334 -3.14366046 24.44676243 69.29552889  5.0291963\n",
      "  5.81901135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6893\n",
      "new_state: [ 2.24384573  0.03320804 -0.31111587 -0.2338756   2.00492071  0.43010721\n",
      " -0.48802429  1.30924608 -0.54387471 -0.42969712 -0.84086139  0.68747494\n",
      "  0.52129506]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.3633539176655126\n",
      "state: [[24.          8.85461533 57.65171711 25.70494921 53.          2.8\n",
      "  25.         36.         -3.         23.74612406 68.          6.50379383\n",
      "   6.19210477]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 83 * Reward is ==> -1.0632927329455495\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:40\n",
      "Reset state: [[-0.21499668 -0.02651823 -0.57386002  0.13090447  0.01465934 -0.34068341\n",
      "   0.46421444 -0.02209433 -0.39387065 -0.3766997   0.14847197  1.38748251\n",
      "  -0.15050641]]\n",
      "time step:  6894\n",
      "new_state: [22.39742736  8.91167007 57.24065487 26.02362943 51.47253353  2.55611369\n",
      " 26.64432026 34.9301048  -3.1036344  23.98087667 69.79288007  6.82150307\n",
      "  5.29660467]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6895\n",
      "new_state: [ 2.22087956  0.03639664 -0.27575251 -0.22371503  2.00454412  0.43004563\n",
      " -0.48271659  1.30920461 -0.54387471 -0.41744154 -0.83993377  0.69039955\n",
      "  0.52215933]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.3626702629389127\n",
      "state: [[24.          8.85935889 57.76198105 25.72181316 53.          2.8\n",
      "  25.         36.         -3.         23.76336508 68.          6.50581487\n",
      "   6.19280707]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 84 * Reward is ==> -1.0626090782189497\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:41\n",
      "Reset state: [[-1.05951468 -0.01555782 -0.99579757 -0.17857077  0.2500358  -0.21237061\n",
      "   0.45874255 -0.11765298 -0.39386832 -0.15100167  0.06021422  0.40833411\n",
      "  -0.04958437]]\n",
      "time step:  6896\n",
      "new_state: [20.62281086  9.10739696 55.84489369 25.43549422 52.56969151  2.65405296\n",
      " 26.48142189 34.3702819  -3.10837278 24.21825573 69.55833274  6.08326556\n",
      "  5.48466948]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6897\n",
      "new_state: [ 2.19425216  0.03983779 -0.24798729 -0.2132331   2.0041226   0.42998124\n",
      " -0.47718215  1.30915388 -0.54387471 -0.40620738 -0.8388222   0.69356368\n",
      "  0.52318173]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.36057355603962393\n",
      "state: [[24.          8.86447818 57.84855377 25.73921049 53.          2.8\n",
      "  25.         36.         -3.         23.77916916 68.          6.50800145\n",
      "   6.19363787]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 85 * Reward is ==> -1.060512371319661\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:42\n",
      "Reset state: [[-0.2239926  -0.11812821 -1.06748918 -0.22671358  0.43043525 -0.37579668\n",
      "   0.2305034   0.12913155 -0.39387117 -0.50851095 -0.28366668  0.94451029\n",
      "  -0.31249118]]\n",
      "time step:  6898\n",
      "new_state: [22.17674804  9.08567381 55.26764433 25.38648737 53.6505861   2.64968088\n",
      " 25.46075998 34.94014199 -3.13239582 23.24336665 68.10504937  6.17897853\n",
      "  5.53158845]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6899\n",
      "new_state: [ 2.16471457  0.04399249 -0.2294903  -0.20227274  2.00362944  0.42990551\n",
      " -0.47130142  1.30909096 -0.54387471 -0.39517163 -0.83757189  0.69695894\n",
      "  0.52434327]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.36064619431860967\n",
      "state: [[24.          8.87065899 57.9062279  25.75740189 53.          2.8\n",
      "  25.         36.         -3.         23.79469412 68.          6.51034774\n",
      "   6.19458175]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 86 * Reward is ==> -1.0605850095986464\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:43\n",
      "Reset state: [[-1.00793945  0.38602192 -0.48947179  0.50275072  0.41570213  0.27700047\n",
      "   0.26626036  0.10472003 -0.39386972 -0.18890394 -0.0124666   0.27260443\n",
      "   0.07826552]]\n",
      "time step:  6900\n",
      "new_state: [21.53930057  9.04170246 57.97343866 26.94269902 53.97894455  2.94125362\n",
      " 26.61823914 36.16176277 -3.12571763 23.31550571 69.14671178  5.76857803\n",
      "  5.16202237]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6901\n",
      "new_state: [ 2.13041429  0.04902107 -0.21929162 -0.19124195  2.00307832  0.42982218\n",
      " -0.4655999   1.30901643 -0.54387471 -0.38501108 -0.8361411   0.70049953\n",
      "  0.52563063]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.36092409158715777\n",
      "state: [[24.          8.87813985 57.93802767 25.77571017 53.          2.8\n",
      "  25.         36.         -3.         23.80898787 68.          6.51279446\n",
      "   6.19562785]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 87 * Reward is ==> -1.0608629068671946\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:44\n",
      "Reset state: [[-0.47837527 -0.04483968 -0.34298784  0.71777954  0.33319294  0.01628577\n",
      "   0.20929779 -0.15668933 -0.39385757  0.36927254 -0.2691737  -0.70183816\n",
      "   0.30063255]]\n",
      "time step:  6902\n",
      "new_state: [21.05551676  8.97768222 58.00328384 26.72706626 53.63610549  2.83272708\n",
      " 25.58036314 34.79344256 -3.06667366 24.20652411 68.10317475  4.94614593\n",
      "  6.00603366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6903\n",
      "new_state: [ 2.08833123  0.05663665 -0.20646327 -0.17613301  2.00218559  0.42967284\n",
      " -0.4569758   1.30889217 -0.54387471 -0.3686828  -0.83437451  0.70547305\n",
      "  0.52744577]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.36128148937870885\n",
      "state: [[24.          8.88946929 57.9780268  25.80078716 53.          2.8\n",
      "  25.         36.         -3.         23.8319583  68.          6.51623142\n",
      "   6.19710284]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 88 * Reward is ==> -1.0612203046587458\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:44\n",
      "Reset state: [[-0.92626943  0.21804822 -0.93321542  0.81614379  0.21229986  0.20866338\n",
      "   0.35475232  0.22476716 -0.39382789 -0.38917755 -0.1391932   0.15378516\n",
      "   0.72447826]]\n",
      "time step:  6904\n",
      "new_state: [21.83170982  8.78115732 56.75459351 27.53773364 53.25189852  2.91690446\n",
      " 27.01456085 36.65347717 -2.92267462 22.89575327 68.78182198  5.56341449\n",
      "  5.65658131]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6905\n",
      "new_state: [ 2.04573344  0.06606791 -0.19714113 -0.1591371   2.00098181  0.42944534\n",
      " -0.44652814  1.30872172 -0.54387471 -0.34735043 -0.83270798  0.7110032\n",
      "  0.52950793]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "reward: -0.3607297448859599\n",
      "state: [[24.          8.90349987 58.00709349 25.82899603 53.          2.8\n",
      "  25.         36.         -3.         23.86196843 68.          6.52005302\n",
      "   6.19877854]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 89 * Reward is ==> -1.0606685601659969\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:45\n",
      "Reset state: [[ 0.16331468  0.2171006   0.41298581 -0.27225193  0.20720688  0.20397042\n",
      "   0.34313231  0.10335959 -0.39387448  0.1338958  -0.11198165 -0.00332752\n",
      "   0.22024456]]\n",
      "time step:  6906\n",
      "new_state: [23.13390584  9.09158582 60.26739858 25.55681605 52.45082597  2.73110455\n",
      " 26.46963839 35.75551951 -3.12716488 25.03934185 68.26492643  5.77930068\n",
      "  5.38428313]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6907\n",
      "new_state: [ 2.00276517  0.07744697 -0.18864135 -0.13997898  1.99938271  0.42910747\n",
      " -0.43420982  1.30848692 -0.54387468 -0.32065662 -0.83109293  0.71715139\n",
      "  0.53186139]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "reward: -0.35747997448410773\n",
      "state: [[24.          8.92042812 58.03359604 25.8607936  53.          2.8\n",
      "  25.         36.         -3.         23.89952097 68.          6.52430173\n",
      "   6.20069096]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 90 * Reward is ==> -1.0574187897641445\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:46\n",
      "Reset state: [[-0.23004323 -0.15245061  0.3887444  -0.35496359  0.39829252 -0.04121408\n",
      "   0.026878   -0.19527623 -0.39386008 -0.62913051  0.14117575 -0.60744893\n",
      "  -0.8246634 ]]\n",
      "time step:  6908\n",
      "new_state: [23.73860195  9.07714199 59.26638703 24.44027139 53.59288589  2.72534581\n",
      " 24.5651481  34.66206798 -3.07771335 23.7954206  70.51966289  6.33094233\n",
      "  4.26209257]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6909\n",
      "new_state: [ 1.97313988  0.08668116 -0.17596521 -0.12174055  1.99763741  0.42869267\n",
      " -0.4232539   1.3082359  -0.54387467 -0.29252083 -0.8299633   0.72265573\n",
      "  0.53393434]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.35301985680228243\n",
      "state: [[24.          8.93416552 58.07312059 25.89106475 53.          2.8\n",
      "  25.         36.         -3.         23.93910208 68.          6.5281055\n",
      "   6.20237544]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 91 * Reward is ==> -1.0529586720823194\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:47\n",
      "Reset state: [[ 0.12787153 -0.15440255 -0.37264646  0.26321502  0.06707295 -0.12320041\n",
      "  -0.12924309 -0.00178268 -0.39386794  0.15148416 -0.21045581  0.15760635\n",
      "   0.74250689]]\n",
      "time step:  6910\n",
      "new_state: [22.98549181  8.8588412  57.64810573 26.20419086 52.00640681  2.72593431\n",
      " 24.45011914 34.84440107 -3.10958073 24.57822299 68.41550653  5.76728398\n",
      "  5.99126946]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6911\n",
      "new_state: [ 1.94762743  0.09500578 -0.14970276 -0.09943019  1.99523629  0.42807796\n",
      " -0.41155245  1.3078963  -0.54387459 -0.25728846 -0.82869926  0.72901342\n",
      "  0.53633266]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.35159518863296524\n",
      "state: [[24.          8.94654979 58.15500763 25.92809424 53.          2.8\n",
      "  25.         36.         -3.         23.98866657 68.          6.53249898\n",
      "   6.20432431]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 92 * Reward is ==> -1.0515340039130021\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:48\n",
      "Reset state: [[ 0.09934376 -0.01694558  0.06515238 -0.31355324  0.05051565 -0.31061322\n",
      "  -0.02118645 -0.03894665 -0.39384826 -0.69307065 -0.251714    0.47777769\n",
      "  -0.62143915]]\n",
      "time step:  6912\n",
      "new_state: [22.77756501  9.02702342 58.97119696 25.3823623  51.8616103   2.64580452\n",
      " 24.91122435 34.70853869 -3.00780547 23.19070859 68.40505856  6.09241291\n",
      "  5.09048043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6913\n",
      "new_state: [ 1.92243409  0.10143933 -0.11571711 -0.07540521  1.99243304  0.42734286\n",
      " -0.40008881  1.30748465 -0.54387456 -0.22186263 -0.8270807   0.73592882\n",
      "  0.53905391]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3541845361180964\n",
      "state: [[24.          8.95612077 58.26097583 25.96796955 53.          2.8\n",
      "  25.         36.         -3.         24.03850321 68.          6.53727787\n",
      "   6.2065356 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 93 * Reward is ==> -1.0541233513981334\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:49\n",
      "Reset state: [[-0.66248957 -0.14684678  0.22469918 -0.29126729  0.04444911 -0.34505439\n",
      "  -0.08423946 -0.04349669 -0.39382478 -0.86740189  0.06011544  1.36481714\n",
      "   0.04348395]]\n",
      "time step:  6914\n",
      "new_state: [22.11937396  9.05459241 59.12435948 24.92643079 52.29409143  2.49704039\n",
      " 24.2419078  35.37913853 -2.90270645 23.61517212 69.28914586  7.35625086\n",
      "  5.16489274]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6915\n",
      "new_state: [ 1.89962615  0.10668372 -0.07923575 -0.05054199  1.98920227  0.42644802\n",
      " -0.38856334  1.3070017  -0.54387442 -0.1854378  -0.82533577  0.74309638\n",
      "  0.54192908]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.3608126272245764\n",
      "state: [[24.          8.96392268 58.37472572 26.00923615 53.          2.8\n",
      "  25.         36.         -3.         24.08974525 68.          6.542231\n",
      "   6.20887196]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 94 * Reward is ==> -1.0607514425046132\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:49\n",
      "Reset state: [[ 0.56449518  0.08832778 -0.81147769  0.70534707  0.07909816  0.03932884\n",
      "  -0.10412328 -0.01286113 -0.39386709 -0.43593905  0.05951697  0.13107786\n",
      "  -0.62065762]]\n",
      "time step:  6916\n",
      "new_state: [24.02843214  8.89501084 56.59645086 27.14187789 51.80420831  2.69625227\n",
      " 24.84093709 35.15639611 -3.09078004 24.09394223 69.1342316   5.92493375\n",
      "  4.78948913]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6917\n",
      "new_state: [ 1.87749278  0.11098585 -0.0408444  -0.02409299  1.98551798  0.42538914\n",
      " -0.37718674  1.30642484 -0.54387428 -0.14924286 -0.82324894  0.75068556\n",
      "  0.54510034]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.37212159101230335\n",
      "state: [[24.          8.97032282 58.49443101 26.05313473 53.          2.8\n",
      "  25.         36.         -3.         24.14066386 68.          6.54747551\n",
      "   6.21144892]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 95 * Reward is ==> -1.0720604062923402\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:50\n",
      "Reset state: [[ 0.01610889 -0.12176991 -0.24017933 -0.64229061  0.11257384  0.02913731\n",
      "   0.46013355  0.16495485 -0.39382248  0.26469387  0.14717561  0.86993222\n",
      "  -0.04229961]]\n",
      "time step:  6918\n",
      "new_state: [22.8128626   8.56850113 58.25754103 24.95530702 51.9023903   2.69221009\n",
      " 26.85801279 35.81244186 -2.84548249 25.0071288  69.51605344  6.4983142\n",
      "  5.31908067]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6919\n",
      "new_state: [ 1.86483775  0.11059302 -0.00687481 -0.00585694  1.98332011  0.42487779\n",
      " -0.37341882  1.30604719 -0.54387413 -0.13196231 -0.82126601  0.75546941\n",
      "  0.54751233]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "reward: -0.38376175042926297\n",
      "state: [[24.          8.9697384  58.6003491  26.08340191 53.          2.8\n",
      "  25.         36.         -3.         24.16497394 68.          6.55078138\n",
      "   6.2134089 ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 96 * Reward is ==> -1.0837005657092997\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:51\n",
      "Reset state: [[ 0.30281305  0.17895411 -1.01761759  0.54929934  0.5008153  -0.25153965\n",
      "  -0.09705684 -0.06398094 -0.39386662 -0.45879676 -0.27867931 -0.63565325\n",
      "   1.18231113]]\n",
      "time step:  6920\n",
      "new_state: [23.4508755   9.43298778 55.78705146 26.54191886 53.91276984  2.68841095\n",
      " 24.44885514 34.72017606 -3.10904437 23.785802   68.20982482  5.12585358\n",
      "  6.312455  ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6921\n",
      "new_state: [ 1.86016929  0.1084406   0.02154168  0.00714113  1.98215043  0.42475462\n",
      " -0.37466368  1.30581281 -0.54387404 -0.12770456 -0.81925657  0.75871733\n",
      "  0.54932396]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.39430832767208346\n",
      "state: [[24.          8.96653633 58.6889525  26.10497539 53.          2.8\n",
      "  25.         36.         -3.         24.1709637  68.          6.55302586\n",
      "   6.21488103]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 97 * Reward is ==> -1.0942471429521203\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:52\n",
      "Reset state: [[ 0.02047069  0.30657393 -0.38317439  0.03665888 -0.14772729  0.02407503\n",
      "   0.21136471  0.21471164 -0.39386767  0.34898291  0.07768851  0.36559499\n",
      "  -0.16559234]]\n",
      "time step:  6922\n",
      "new_state: [22.84416312  9.28343149 57.86880813 25.95728448 50.88331748  2.70723988\n",
      " 25.85682233 35.98817907 -3.0831112  25.03018609 69.41903563  6.1188775\n",
      "  5.25018186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6923\n",
      "new_state: [ 1.86816765  0.10765238  0.0327511   0.01379694  1.98200534  0.42482116\n",
      " -0.38255289  1.30579548 -0.54387405 -0.13366157 -0.81803272  0.75948174\n",
      "  0.5494709 ]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.39856561186102024\n",
      "state: [[24.          8.96536371 58.7239038  26.11602232 53.          2.8\n",
      "  25.         36.         -3.         24.16258345 68.          6.5535541\n",
      "   6.21500043]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 98 * Reward is ==> -1.0985044271410571\n",
      "designs_fitness_scores: {}\n",
      "Using GPU:  []\n",
      "Current Time - New test episode is just started = 08:52:53\n",
      "Reset state: [[-0.30915646 -0.14495916 -1.0110817  -0.0648796   0.41653608  0.10815224\n",
      "   0.20678702  0.1893716  -0.39382448  0.16960491 -0.14194209  0.34508494\n",
      "   0.92538744]]\n",
      "time step:  6924\n",
      "new_state: [22.44089515  8.66542298 56.06848908 25.79733192 53.09243953  2.7164353\n",
      " 25.74662084 35.91000917 -2.8941025  24.99260507 68.49868739  6.01532638\n",
      "  6.01817623]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "reward: -0.6999388152800369\n",
      "state: [[24.   9.5 60.  28.  53.   2.8 27.  36.  -3.  25.  70.   7.   7. ]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "time step:  6925\n",
      "new_state: [ 1.89132154  0.1104967   0.02525666  0.01670124  1.98181032  0.42474433\n",
      " -0.39319755  1.30586432 -0.54387411 -0.14035854 -0.81791732  0.75936839\n",
      "  0.54821611]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "reward: -0.394358690692181\n",
      "state: [[24.          8.96959511 58.70053594 26.12084273 53.          2.8\n",
      "  25.         36.         -3.         24.15316223 68.          6.55347577\n",
      "   6.21398079]]\n",
      "Learning process is done....\n",
      "Updating the target networks is done....\n",
      "Episode * 99 * Reward is ==> -1.094297505972218\n",
      "designs_fitness_scores: {}\n",
      "Starting Time = 08:51:10\n",
      "Ending Time = 08:52:54\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import warnings\n",
    "# alpha = random.uniform(alpha_low, alpha_high)\n",
    "# fx = random.uniform(fx_low, fx_high)\n",
    "# fy = random.uniform(fy_low, fy_high)\n",
    "# l = random.uniform(l_low, l_high)\n",
    "# lextension = random.uniform(lextension_low, lextension_high)\n",
    "# lh = random.uniform(lh_low, lh_high)\n",
    "# lr = random.uniform(lr_low, lr_high)\n",
    "# lv = random.uniform(lv_low, lv_high)\n",
    "# offset1 = random.uniform(offset1_low, offset1_high)        \n",
    "# pr = random.uniform(pr_low, pr_high)\n",
    "# pr2 = random.uniform(pr2_low, pr2_high)\n",
    "# w = random.uniform(w_low, w_high)        \n",
    "# wr = random.uniform(wr_low, wr_high)\n",
    "# wu = random.uniform(wu_low, wu_high)  \n",
    "total_episodes=100\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "state = scaler_x1.transform([np.array([random.uniform(*bounds) for bounds in [\n",
    "            (fx_low, fx_high), (fy_low, fy_high), \n",
    "            (l_low, l_high), (lextension_low, lextension_high), (lh_low, lh_high),\n",
    "            (lr_low, lr_high), (lv_low, lv_high), (offset1_low, offset1_high), \n",
    "            (pr_low, pr_high), (pr2_low, pr2_high), (w_low, w_high), \n",
    "            (wr_low, wr_high), (wu_low, wu_high)]])]).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "# state = scaler_x1.transform([x_data1[508]]).reshape(-1,1)\n",
    "# env = env_hfss(state)\n",
    "# designs_fitness_scores = {}\n",
    "start = datetime.now()\n",
    "start_time = start.strftime(\"%H:%M:%S\")\n",
    "# print(\"Training the Agent.......\")\n",
    "for ep in range(total_episodes):\n",
    "    print(\"Using GPU: \", tf.config.list_physical_devices('GPU'))\n",
    "    # objectives_fitness_scores = {}\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time - New test episode is just started =\", current_time)\n",
    "    prev_state = env.reset()\n",
    "    print(\"Reset state: {}\".format(prev_state))\n",
    "    episodic_reward = 0\n",
    "    timestep_counter_episode = 0\n",
    "    while True:\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        # print(\"Current Time - New step is just started =\", current_time)\n",
    "        timestep_counter += 1\n",
    "        print(\"time step: \", timestep_counter)\n",
    "\n",
    "        if timestep_counter_episode > max_timesteps_episode:\n",
    "            print(\"The timesteps per episode reached the max.....\")\n",
    "            break\n",
    "        timestep_counter_episode += 1\n",
    "        learn_counter += 1\n",
    "        target_update_counter += 1\n",
    "\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(np.squeeze([prev_state])), 0)\n",
    "        # print(\"ou_noise: \", ou_noise())\n",
    "        action = np.array(policy(tf_prev_state, ou_noise))\n",
    "        # print(\"action: {}\".format(action))\n",
    "        state, reward, done = env.step(action)\n",
    "\n",
    "        # print(\"prev_state: {}\".format(prev_state))\n",
    "        # print(\"action: {}\".format(action))\n",
    "        print(\"reward: {}\".format(reward))\n",
    "        # print(\"done: {}\".format(done))\n",
    "        print(\"state: {}\".format(scaler_x1.inverse_transform(state)))\n",
    "        if done == True and env.final_validation=='valid':\n",
    "            designs_fitness_scores= env.get_scores()\n",
    "#             print(\"designs_fitness_scores: {}\".format((designs_fitness_scores)))\n",
    "#             print(\"objectives_fitness_scores: {}\".format((objectives_fitness_scores)))\n",
    "            \n",
    "\n",
    "        buffer.record(([prev_state], action, reward, [state]))\n",
    "        episodic_reward += reward\n",
    "        if timestep_counter > batch_size:\n",
    "            if learn_counter % learn_freq == 0:\n",
    "                buffer.learn()\n",
    "                print(\"Learning process is done....\")\n",
    "\n",
    "            if target_update_counter % target_update_freq == 0:\n",
    "                # update_target(target_actor.variables, actor_model.variables, tau)\n",
    "                # update_target(target_critic.variables, critic_model.variables, tau)\n",
    "                \n",
    "                # Update target network weights directly\n",
    "                target_actor.set_weights([tau * weight + (1 - tau) * target_weight \n",
    "                          for target_weight, weight in zip(target_actor.get_weights(), actor_model.get_weights())])\n",
    "\n",
    "                target_critic.set_weights([tau * weight + (1 - tau) * target_weight \n",
    "                           for target_weight, weight in zip(target_critic.get_weights(), critic_model.get_weights())])\n",
    "\n",
    "                print(\"Updating the target networks is done....\")\n",
    "\n",
    "        # End this episode when `done` is True\n",
    "        if done:\n",
    "            break\n",
    "        prev_state = state\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "\n",
    "    avg_reward = np.mean(ep_reward_list[-1:])\n",
    "    print(\"Episode * {} * Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "    print('designs_fitness_scores:', designs_fitness_scores)\n",
    "    \n",
    "end = datetime.now()\n",
    "end_time = end.strftime(\"%H:%M:%S\")\n",
    "print(\"Starting Time =\", start_time)\n",
    "print(\"Ending Time =\", end_time)\n",
    "\n",
    "# Plotting graph\n",
    "# Episodes versus Rewards\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Epsiodic Reward\")\n",
    "# plt.savefig(\"EpisodicReward.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b30246d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting graph\n",
    "# # Episodes versus Rewards\n",
    "# plt.plot(avg_reward_list)\n",
    "# plt.xlabel(\"Episode\")\n",
    "# plt.ylabel(\"Epsiodic Reward\")\n",
    "# plt.savefig(\"EpisodicReward-500ep.svg\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "0f0ed087-6f4f-4462-898f-ed4e87e61be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Initialize moving average deque\n",
    "moving_avg_window = 150\n",
    "moving_avg = deque(maxlen=moving_avg_window)\n",
    "\n",
    "# Main reward processing loop (assume part of a larger loop)\n",
    "ep_reward_list.append(episodic_reward)\n",
    "\n",
    "# Compute average reward for this episode\n",
    "avg_reward = np.mean(ep_reward_list[-1:])\n",
    "# print(\"Episode * {} * Reward is ==> {}\".format(ep, avg_reward))\n",
    "avg_reward_list.append(avg_reward)\n",
    "\n",
    "# Update moving average\n",
    "moving_avg.append(avg_reward)\n",
    "moving_avg_reward = np.mean(moving_avg)\n",
    "\n",
    "# Debug outputs\n",
    "# print(\"Moving Average Reward (Last 20 Episodes):\", moving_avg_reward)\n",
    "# print('designs_fitness_scores:', designs_fitness_scores)\n",
    "\n",
    "\n",
    "# Plotting graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_reward_list, label=\"Episodic Reward\")\n",
    "plt.plot(\n",
    "    range(len(avg_reward_list)),\n",
    "    [np.mean(avg_reward_list[max(0, i - moving_avg_window):i + 1]) for i in range(len(avg_reward_list))],\n",
    "    label=f\"Moving Average (Last {moving_avg_window} Episodes)\",\n",
    "    linestyle=\"--\",\n",
    "    color=\"orange\",\n",
    ")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Episode vs Reward with Moving Average\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"EpisodicReward-600ep-limited.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238ef41-02f4-42d3-bca7-b6d636625dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# from datetime import datetime\n",
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set up logging\n",
    "# log_file = f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "# logging.basicConfig(\n",
    "#     filename=log_file,\n",
    "#     filemode=\"w\",\n",
    "#     format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "#     level=logging.INFO,\n",
    "# )\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "# # Example logging messages\n",
    "# logger.info(\"Starting the program...\")\n",
    "# logger.debug(\"Debug level is active.\")\n",
    "\n",
    "# # Suppress TensorFlow warnings\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "# state = scaler_x1.transform([np.array([random.uniform(*bounds) for bounds in [\n",
    "#     (alpha_low, alpha_high), (fx_low, fx_high), (fy_low, fy_high),\n",
    "#     (l_low, l_high), (lextension_low, lextension_high), (lh_low, lh_high),\n",
    "#     (lr_low, lr_high), (lv_low, lv_high), (offset1_low, offset1_high),\n",
    "#     (pr_low, pr_high), (pr2_low, pr2_high), (w_low, w_high),\n",
    "#     (wr_low, wr_high), (wu_low, wu_high)]])]).reshape(-1, 1)\n",
    "\n",
    "# state = scaler_x1.transform([x_data1[508]]).reshape(-1, 1)\n",
    "# env = env_hfss(state)\n",
    "\n",
    "# start = datetime.now()\n",
    "# start_time = start.strftime(\"%H:%M:%S\")\n",
    "# logger.info(f\"Training the Agent... Start Time: {start_time}\")\n",
    "\n",
    "# designs_fitness_scores = {}\n",
    "# for ep in range(total_episodes):\n",
    "#     logger.info(f\"Episode {ep} started using GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     logger.info(f\"Current Time - New test episode started: {current_time}\")\n",
    "    \n",
    "#     prev_state = env.reset()\n",
    "#     logger.info(f\"Reset state: {prev_state}\")\n",
    "#     episodic_reward = 0\n",
    "#     timestep_counter_episode = 0\n",
    "\n",
    "#     while True:\n",
    "#         now = datetime.now()\n",
    "#         current_time = now.strftime(\"%H:%M:%S\")\n",
    "#         timestep_counter += 1\n",
    "#         logger.debug(f\"Time step: {timestep_counter}\")\n",
    "\n",
    "#         if timestep_counter_episode > max_timesteps_episode:\n",
    "#             logger.info(\"The timesteps per episode reached the max.\")\n",
    "#             break\n",
    "\n",
    "#         timestep_counter_episode += 1\n",
    "#         learn_counter += 1\n",
    "#         target_update_counter += 1\n",
    "\n",
    "#         tf_prev_state = tf.expand_dims(tf.convert_to_tensor(np.squeeze([prev_state])), 0)\n",
    "#         action = np.array(policy(tf_prev_state, ou_noise))\n",
    "#         logger.debug(f\"Action taken: {action}\")\n",
    "        \n",
    "#         state, reward, done = env.step(action)\n",
    "#         logger.info(f\"Reward: {reward}\")\n",
    "#         logger.info(f\"State: {scaler_x1.inverse_transform(state)}\")\n",
    "\n",
    "#         if done and env.final_validation == 'valid':\n",
    "#             designs_fitness_scores = env.get_scores()\n",
    "#             logger.info(f\"Designs Fitness Scores: {designs_fitness_scores}\")\n",
    "\n",
    "#         buffer.record(([prev_state], action, reward, [state]))\n",
    "#         episodic_reward += reward\n",
    "\n",
    "#         if timestep_counter > batch_size:\n",
    "#             if learn_counter % learn_freq == 0:\n",
    "#                 buffer.learn()\n",
    "#                 logger.info(\"Learning process completed.\")\n",
    "\n",
    "#             if target_update_counter % target_update_freq == 0:\n",
    "#                 target_actor.set_weights([tau * weight + (1 - tau) * target_weight\n",
    "#                     for target_weight, weight in zip(target_actor.get_weights(), actor_model.get_weights())])\n",
    "#                 target_critic.set_weights([tau * weight + (1 - tau) * target_weight\n",
    "#                     for target_weight, weight in zip(target_critic.get_weights(), critic_model.get_weights())])\n",
    "#                 logger.info(\"Target networks updated.\")\n",
    "\n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "#         prev_state = state\n",
    "\n",
    "#     ep_reward_list.append(episodic_reward)\n",
    "#     avg_reward = np.mean(ep_reward_list[-1:])\n",
    "#     logger.info(f\"Episode {ep} - Reward: {avg_reward}\")\n",
    "#     avg_reward_list.append(avg_reward)\n",
    "#     logger.info(f\"Designs Fitness Scores: {designs_fitness_scores}\")\n",
    "\n",
    "# end = datetime.now()\n",
    "# end_time = end.strftime(\"%H:%M:%S\")\n",
    "# logger.info(f\"Training completed. Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "# # Plotting graph\n",
    "# plt.plot(avg_reward_list)\n",
    "# plt.xlabel(\"Episode\")\n",
    "# plt.ylabel(\"Episodic Reward\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "c9d3b34d-b2cb-4ed7-aa01-783188a62cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_fitness_scores = env.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "8af819ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 designs with scores: dict_values([-0.31798190325933784, -0.31798885319388326, -0.3183502078868852])\n"
     ]
    }
   ],
   "source": [
    "top_3_designs = sorted(designs_fitness_scores, key=designs_fitness_scores.get, reverse=True)[:3]\n",
    "top_3_scores = {design: designs_fitness_scores[design] for design in top_3_designs}\n",
    "print(\"Top 3 designs with scores:\", top_3_scores.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "d6d36af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 designs with scores: {(0.7490764976177171, 0.3422457464391194, -0.23648231145972975, 0.23301122605677393, 0.5067644021366162, 0.28039428950487133, -0.1443703179428037, 0.3093868294501958, -0.39387471137933067, -0.3775513606593572, -0.39031258704401217, 0.9785997784224603, 0.6154875754216516): -0.31798190325933784, (0.7490764976177171, 0.4670313657176588, -0.2719082401554789, 0.20652384667733015, 0.5067644021366162, 0.28039428950487133, -0.1443703179428037, 0.3093868294501958, -0.39387471137933067, -0.40900061383227904, -0.39031258704401217, 1.0989705822259719, 1.0854028587046236): -0.31798885319388326, (0.7490764976177171, 0.4670313657176588, -0.33998324985173844, 0.20385714479302408, 0.5067644021366162, 0.28039428950487133, -0.1443703179428037, 0.3093868294501958, -0.39387471137933067, -0.44739240482398185, -0.39031258704401217, 0.8862866530890049, 0.4655544072061198): -0.3183502078868852}\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 3 designs with scores:\", top_3_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "880a4e87-9356-4ca6-8859-fc132dc930cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_design = max(designs_fitness_scores, key=designs_fitness_scores.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "9cfc3632-3e9a-410f-8ee0-0bc41fddd959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7490764976177171,\n",
       " 0.3422457464391194,\n",
       " -0.23648231145972975,\n",
       " 0.23301122605677393,\n",
       " 0.5067644021366162,\n",
       " 0.28039428950487133,\n",
       " -0.1443703179428037,\n",
       " 0.3093868294501958,\n",
       " -0.39387471137933067,\n",
       " -0.3775513606593572,\n",
       " -0.39031258704401217,\n",
       " 0.9785997784224603,\n",
       " 0.6154875754216516)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "5ca88334-48a4-4699-a4a6-31e4dcb860a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31798190325933784"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designs_fitness_scores[best_design]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "eba93b58-8e3f-4ac4-97d5-de15084d1197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.        ,  9.31436054, 57.88442661, 26.47986201, 53.        ,\n",
       "         2.8       , 25.        , 36.        , -3.        , 23.81948211,\n",
       "        68.        ,  6.70497556,  6.26864553]])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_x1.inverse_transform([best_design])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "7999fe0c-89cb-47fe-86cb-643ad97c5044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7490765   0.34224575 -0.23648231  0.23301123  0.5067644   0.28039429\n",
      "  -0.14437032  0.30938683 -0.39387471 -0.37755136 -0.39031259  0.97859978\n",
      "   0.61548758]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([np.array(best_design)])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "aae8ec9f-a527-4455-9585-9200edcacc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: array([[  2.44578313, -32.96530533,   0.05893935]]),\n",
       " 2: array([[  1.90361446, -22.96375275,   0.03533282]]),\n",
       " 3: array([], dtype=float64),\n",
       " 4: array([[ 1.89156627e+00, -3.15306797e+01,  3.77488177e-02],\n",
       "        [ 2.42168675e+00, -1.61167660e+01,  2.41327937e-02]])}"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576890c6-1649-4926-803a-17bf1fe2041a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e9337-af6e-4ae2-b701-bb5c880d99ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c6b7e0f6-cb09-4928-8510-c3ee652cf993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class env_hfss:\n",
    "#     def __init__(self, data):\n",
    "#         self.center_frequency = intended_frequency\n",
    "#         self.bandwidth = [0.034, 0.034]\n",
    "#         self.s11 = -10\n",
    "#         self.reward = 0\n",
    "#         self.done = True               # target reached\n",
    "#         self.designs_scores = {}\n",
    "#         self.objectives_scores = {}\n",
    "#         self.outputs = {}\n",
    "        \n",
    "#         self.alpha = data[0]\n",
    "#         self.fx = data[1]\n",
    "#         self.fy = data[2]\n",
    "#         self.l = data[3]\n",
    "#         self.lextension = data[4]\n",
    "#         self.lh = data[5]\n",
    "#         self.lr = data[6]\n",
    "#         self.lv = data[7]\n",
    "#         self.offset1 = data[8]\n",
    "#         self.pr = data[9]\n",
    "#         self.pr2 = data[10]\n",
    "#         self.w = data[11]\n",
    "#         self.wr = data[12]\n",
    "#         self.wu = data[13]\n",
    "\n",
    "\n",
    "#         # self.state = np.array([self.alpha, self.fx, self.fy, self.l, self.lextension,self.lh, \n",
    "#         #                        self.lr, self.lv, self.offset1, self.pr, self.pr2, self.w, self.wr, self.wu])\n",
    "\n",
    "#         self.state = data\n",
    "#         print(\"self.state: \", self.state)\n",
    "\n",
    "#         #self.state_print = np.array([self._diameter, self._offset, self._substrate])\n",
    "\n",
    "#         # State space boundaries for each dimension\n",
    "#         self.state_low = lower_bound_state\n",
    "#         self.state_high = upper_bound_state\n",
    "\n",
    "#         # Action space boundaries\n",
    "#         self.action_low = lower_bound_action\n",
    "#         self.action_high = upper_bound_action\n",
    "\n",
    "#     def step(self, action):\n",
    "#         clipped_action = np.clip(np.squeeze(action), self.action_low, self.action_high)\n",
    "#         # clipped_action = np.round(clipped_action, decimals=3)\n",
    "#         new_state = np.squeeze(self.state) + np.squeeze(clipped_action)\n",
    "#         # new_state = np.round(np.squeeze(self.state) + np.squeeze(clipped_action),4)\n",
    "\n",
    "#         # Check if the state is within 3D bounds\n",
    "#         if not self._is_valid_state(new_state):\n",
    "#             new_state = np.clip(new_state, self.state_low, self.state_high)\n",
    "\n",
    "#         if np.array_equal(new_state, self.state):\n",
    "# #             self.reward = -10\n",
    "#             self.reward = -5\n",
    "#             self.done = False\n",
    "#             return self.state, self.reward, self.done\n",
    "#         else:\n",
    "#             self.state = np.squeeze(new_state)\n",
    "\n",
    "#             # print(\"self.state: \",self.state)\n",
    "            \n",
    "#             self.outputs = big_model(self.state)\n",
    "            \n",
    "#             # print(\"self.outputs: \", self.outputs)\n",
    "            \n",
    "#             self.reward, self.done = self._check_objective()\n",
    "#             return self.state, self.reward, self.done\n",
    "    \n",
    "\n",
    "                \n",
    "\n",
    "#     def _is_valid_state(self, stat):\n",
    "#         return np.all(self.state_low <= stat) and np.all(stat <= self.state_high)\n",
    "\n",
    "    \n",
    "# #     def _check_objective(self):\n",
    "# #         if math.isclose(self.center_frequency, intended_frequency, rel_tol= relative_frequency_tolerance):\n",
    "# #             if self.s11 <= -15:\n",
    "# #                 self.reward = max_reward\n",
    "# #                 self.done = True\n",
    "# #             else:\n",
    "# # #                 self.reward = -(self.s11+15)/5\n",
    "# #                 self.reward = -1\n",
    "# #                 self.done = False\n",
    "# #         else:\n",
    "# #             self.reward = -1\n",
    "# # #             self.reward = -pow(20*abs(self.center_frequency-intended_frequency), 2) - 2.5644\n",
    "# #             self.done = False\n",
    "# #         return self.reward, self.done\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def _check_objective(self):\n",
    "#         reward_min = -0.4 \n",
    "#         # Right band\n",
    "#         right_band_check =  len(self.outputs[1])==3\n",
    "        \n",
    "#         # Left band\n",
    "#         left_band_check =   len(self.outputs[2])==3\n",
    "        \n",
    "#         # None band\n",
    "#         none_band_check =   len(self.outputs[3])==0\n",
    "\n",
    "#         # Dual band\n",
    "#         dual_band_check =   len(self.outputs[4])==6\n",
    "        \n",
    "        \n",
    "#         # Right band\n",
    "#         if right_band_check:\n",
    "#             if math.isclose(self.outputs[1][0], intended_frequency[1], rel_tol= relative_frequency_tolerance):\n",
    "#                 self.s11 = self.outputs[1][1]\n",
    "#                 self.bandwidth = self.outputs[1][2]\n",
    "#                 fitness_score_right = self.scores()\n",
    "#             else:\n",
    "#                 print(\"Right band is not in range.\")\n",
    "#                 fitness_score_right = 0\n",
    "                \n",
    "#         else:\n",
    "#             print(\"Right band does not fit.\")\n",
    "#             fitness_score_right = 0\n",
    "\n",
    "        \n",
    "#         # Left band\n",
    "#         if left_band_check:\n",
    "#             if math.isclose(self.outputs[2][0], intended_frequency[0], rel_tol= relative_frequency_tolerance):\n",
    "#                 self.s11 = self.outputs[2][1]\n",
    "#                 self.bandwidth = self.outputs[2][2]\n",
    "#                 fitness_score_left = self.scores()\n",
    "#             else:\n",
    "#                 print(\"Left band is not in range.\")\n",
    "#                 fitness_score_left = 0\n",
    "#         else:\n",
    "#             print(\"Left band does not fit.\")\n",
    "#             fitness_score_left = 0\n",
    "\n",
    "\n",
    "        \n",
    "#         # None band\n",
    "#         if none_band_check:\n",
    "#             self.s11 = 0\n",
    "#             self.bandwidth = 0\n",
    "#             fitness_score_none = 1\n",
    "#         else:\n",
    "#             print(\"None band does not fit.\")\n",
    "#             fitness_score_none = 0\n",
    "\n",
    "\n",
    "#         # Dual band\n",
    "#         if dual_band_check:\n",
    "#             if math.isclose(self.outputs[4][0], intended_frequency[0], rel_tol= relative_frequency_tolerance) & math.isclose(self.outputs[4][3], intended_frequency[1], rel_tol= relative_frequency_tolerance):   \n",
    "                \n",
    "#                 self.s11 = self.outputs[4][1]\n",
    "#                 self.bandwidth = self.outputs[4][2]\n",
    "#                 fitness_score_daul1 = self.scores()\n",
    "    \n",
    "#                 self.s11 = self.outputs[4][4]\n",
    "#                 self.bandwidth = self.outputs[4][5]\n",
    "#                 fitness_score_daul2 = self.scores()\n",
    "#             else:\n",
    "#                 print(\"Dual band is not in range.\")\n",
    "#                 fitness_score_daul1 = 0\n",
    "#                 fitness_score_daul2 = 0\n",
    "#         else:\n",
    "#             print(\"Dual band does not fit.\")\n",
    "#             fitness_score_daul1 = 0\n",
    "#             fitness_score_daul2 = 0\n",
    "\n",
    "\n",
    "            \n",
    "#         self.reward = (fitness_score_right+fitness_score_left+fitness_score_none+fitness_score_daul1+fitness_score_daul2)/5 - 1\n",
    "        \n",
    "#         self.done = True if self.reward > reward_min else False\n",
    "#         if self.reward > reward_min:\n",
    "#             self.designs_scores[tuple(self.state)] = self.reward\n",
    "#         # self.designs_scores[tuple(self.state)] = fitness_score if self.reward > reward_min else continue\n",
    "        \n",
    "#         # self.reward = -pow(20*abs(self.center_frequency-intended_frequency), 2) - 2.5644\n",
    "    \n",
    "#         return self.reward, self.done\n",
    "\n",
    "#     def get_score(self):\n",
    "#         return self.designs_scores\n",
    "    \n",
    "#     def scores(self):\n",
    "#         s11_min = -30\n",
    "#         s11_max = 0\n",
    "#         bandwidth_min = 0\n",
    "#         bandwidth_max = 0.05 # GHz\n",
    "#         weights = [0.5, 0.5]        \n",
    "#         normalized_s11 = (s11_max - self.s11) / (s11_max - s11_min)\n",
    "#         normalized_bandwidth = (self.bandwidth - bandwidth_min) / (bandwidth_max - bandwidth_min)\n",
    "#         fitness_score = weights[0] * normalized_s11 + weights[1] * normalized_bandwidth\n",
    "        \n",
    "#         # self.designs_scores[tuple(self.state_real)] = fitness_score\n",
    "#         # self.objectives_scores[tuple(np.array([self.s11, self.gain, self.bandwidth]))] = fitness_score  \n",
    "        \n",
    "#         return fitness_score\n",
    "    \n",
    "#     def reset(self):\n",
    "#         self.alpha = random.uniform(alpha_low, alpha_high)\n",
    "#         self.fx = random.uniform(fx_low, fx_high)\n",
    "#         self.fy = random.uniform(fy_low, fy_high)\n",
    "#         self.l = random.uniform(l_low, l_high)\n",
    "#         self.lextension = random.uniform(lextension_low, lextension_high)\n",
    "#         self.lh = random.uniform(lh_low, lh_high)\n",
    "#         self.lr = random.uniform(lr_low, lr_high)\n",
    "#         self.lv = random.uniform(lv_low, lv_high)\n",
    "#         self.offset1 = random.uniform(offset1_low, offset1_high)        \n",
    "#         self.pr = random.uniform(pr_low, pr_high)\n",
    "#         self.pr2 = random.uniform(pr2_low, pr2_high)\n",
    "#         self.w = random.uniform(w_low, w_high)        \n",
    "#         self.wr = random.uniform(wr_low, wr_high)\n",
    "#         self.wu = random.uniform(wu_low, wu_high)  \n",
    "        \n",
    "        \n",
    "\n",
    "#         self.state = np.array([self.alpha, self.fx, self.fy, self.l, self.lextension, self.lh, self.lr, self.lv, self.offset1, self.pr,\n",
    "#                               self.pr2, self.w, self.wr, self.wu])\n",
    "#         return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "15922674-41fa-4eaa-a0f3-27ca7b5324ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:  [[-0.08011137]\n",
      " [ 0.02744725]\n",
      " [ 0.19633504]\n",
      " [-0.04356378]\n",
      " [-0.06501528]\n",
      " [ 0.02894801]\n",
      " [ 0.00900521]\n",
      " [ 0.13544766]\n",
      " [ 0.16432861]\n",
      " [-0.22667576]\n",
      " [ 0.10332176]\n",
      " [-0.27270791]\n",
      " [ 0.10657895]\n",
      " [ 1.12952959]]\n"
     ]
    }
   ],
   "source": [
    "state1 = scaler_x1.transform([0.998*x_data1[508]]).reshape(-1,1)\n",
    "env_test = env_hfss(state1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "21aa554c-05ed-495b-b9ad-2eeef6d4a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
      "  0.001 0.001]]\n"
     ]
    }
   ],
   "source": [
    "action = np.array([0.001 for i in range(len(x_data1[508]))]).reshape(1,-1)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "1a80e2dc-020d-4f2d-9075-eada1569cb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_state: [-0.079  0.028  0.197 -0.043 -0.064  0.03   0.01   0.136  0.165 -0.226\n",
      "  0.104 -0.272  0.108  1.131]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.079,  0.028,  0.197, -0.043, -0.064,  0.03 ,  0.01 ,  0.136,\n",
       "          0.165, -0.226,  0.104, -0.272,  0.108,  1.131]]),\n",
       " -0.31981402124999025,\n",
       " True)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_test.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abdc59-d901-4fc3-ac3a-dbaf08bc94ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
